{"config":{"lang":["en","ko"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Curve","text":"<p>Declarative Event Publishing Library for Spring Boot Microservices</p> <p>Curve is a production-ready library that simplifies event-driven architecture in Spring Boot applications. With a single annotation, you get automatic Kafka publishing, PII masking, DLQ handling, and comprehensive observability.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"GradleMaven <pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'\n}\n</code></pre> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.1.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":"application.yml<pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9092\n\ncurve:\n  enabled: true\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n</code></pre>"},{"location":"#usage","title":"Usage","text":"OrderService.java<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(eventType = \"ORDER_CREATED\")\n    public Order createOrder(OrderRequest request) {\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre> <p>That's it!  Curve automatically handles:</p> <ul> <li> Event ID generation (Snowflake)</li> <li> Metadata extraction (trace ID, user, IP)</li> <li> PII masking/encryption</li> <li> Kafka publishing with retries</li> <li> Dead Letter Queue (DLQ)</li> <li> Metrics collection</li> </ul> <p>Get Started \u2192 View on GitHub \u2192</p>"},{"location":"#why-curve","title":"Why Curve?","text":""},{"location":"#before-vs-after","title":"Before vs After","text":"<ul> <li> <p> Before (50+ lines)</p> <pre><code>@Service\npublic class UserService {\n    @Autowired KafkaTemplate kafka;\n\n    public User createUser(UserRequest req) {\n        User user = repo.save(new User(req));\n\n        try {\n            // Manual event creation\n            EventEnvelope event = EventEnvelope.builder()\n                .eventId(UUID.randomUUID().toString())\n                .eventType(\"USER_CREATED\")\n                .occurredAt(Instant.now())\n                .metadata(/* ... */)\n                .payload(/* ... */)\n                .build();\n\n            // Manual PII masking\n            String json = maskPii(\n                objectMapper.writeValueAsString(event)\n            );\n\n            // Manual Kafka send\n            kafka.send(\"user-events\", json)\n                .get(30, TimeUnit.SECONDS);\n\n        } catch (Exception e) {\n            log.error(\"Failed\", e);\n            sendToDlq(event);\n        }\n\n        return user;\n    }\n}\n</code></pre> </li> <li> <p> After (1 annotation)</p> <pre><code>@Service\npublic class UserService {\n\n    @PublishEvent(eventType = \"USER_CREATED\")\n    public User createUser(UserRequest req) {\n        return repo.save(new User(req));\n    }\n}\n</code></pre> <p>90% less code </p> </li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p> Declarative Publishing</p> <p>No Kafka boilerplate - just add <code>@PublishEvent</code> annotation. Supports SpEL for flexible payload extraction.</p> <p> Learn more</p> </li> <li> <p> Standardized Events</p> <p>All events follow a unified schema with metadata (source, actor, trace, tags).</p> <p> Event Structure</p> </li> <li> <p> 3-Tier Failure Recovery</p> <p>Main Topic \u2192 DLQ \u2192 Local File Backup</p> <p>Zero event loss even when Kafka is down.</p> <p> Failure Recovery</p> </li> <li> <p> Automatic PII Protection</p> <p><code>@PiiField</code> annotation automatically masks/encrypts sensitive data.</p> <p> PII Protection</p> </li> <li> <p> High Performance</p> <ul> <li>Sync: ~500 TPS</li> <li>Async: ~10,000+ TPS</li> <li>Transactional Outbox: Atomicity guaranteed</li> </ul> <p> Performance</p> </li> <li> <p> Built-in Observability</p> <p>Health checks, custom metrics, and detailed event tracking out of the box.</p> <p> Observability</p> </li> </ul>"},{"location":"#comparison","title":"Comparison","text":"Feature Spring Events Spring Cloud Stream Curve Kafka Integration Declarative Usage  Partial Standardized Schema PII Protection DLQ Support Local File Backup Health Check Transactional Outbox Boilerplate Code Medium High Minimal"},{"location":"#architecture","title":"Architecture","text":"<p>Curve follows Hexagonal Architecture (Ports &amp; Adapters) for maximum flexibility:</p> <pre><code>graph TB\n    A[Domain Layer Core] --&gt; B[Spring Adapter]\n    A --&gt; C[Kafka Adapter]\n    B --&gt; D[AOP / Context]\n    C --&gt; E[Producer / DLQ]\n\n    style A fill:#4051b5\n    style B fill:#00897b\n    style C fill:#00897b\n</code></pre> <p>Core Principles:</p> <ul> <li> Framework-independent domain model</li> <li> Dependency Inversion (DIP)</li> <li> Easy to test and extend</li> </ul> <p> Architecture Details</p>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#1-audit-logging","title":"1. Audit Logging","text":"<pre><code>@PublishEvent(eventType = \"USER_LOGIN\", severity = INFO)\npublic User login(String username, String password) {\n    return authService.authenticate(username, password);\n}\n</code></pre>"},{"location":"#2-event-driven-architecture","title":"2. Event-Driven Architecture","text":"<pre><code>@PublishEvent(eventType = \"ORDER_COMPLETED\")\npublic Order completeOrder(Long orderId) {\n    Order order = orderRepository.findById(orderId);\n    order.setStatus(OrderStatus.COMPLETED);\n    return orderRepository.save(order);\n}\n</code></pre>"},{"location":"#3-data-pipeline","title":"3. Data Pipeline","text":"<pre><code>@PublishEvent(eventType = \"CUSTOMER_REGISTERED\")\npublic Customer registerCustomer(CustomerRequest request) {\n    // Event automatically flows to data lake/warehouse\n    return customerRepository.save(new Customer(request));\n}\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> <p> Getting Started</p> <p>Quick setup guide and your first event in 5 minutes</p> <p> Quick Start</p> </li> <li> <p> Configuration</p> <p>Comprehensive configuration guide for production</p> <p> Configuration</p> </li> <li> <p> Operations</p> <p>Production deployment and best practices</p> <p> Operations</p> </li> <li> <p> Troubleshooting</p> <p>Common issues and solutions</p> <p> Troubleshooting</p> </li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub: closeup1202/curve</li> <li>Issues: Report a bug</li> <li>Email: closeup1202@gmail.com</li> </ul> <p> Contributing Guide</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#ready-to-simplify-your-event-driven-architecture","title":"Ready to simplify your event-driven architecture?","text":"<p>Get Started Now \u2192 View Examples \u2192</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#012-2026-02-20","title":"0.1.2 - 2026-02-20","text":""},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>JavaTimeModule not applied to ObjectMapper (Critical): <code>Jackson2ObjectMapperBuilder.modules()</code> replaces its internal module map on each call rather than appending, so <code>JavaTimeModule</code> registered by the Curve Jackson customizer was silently wiped out when the <code>PiiModule</code> customizer ran afterward<ul> <li>Effect: Fields of type <code>java.time.Instant</code> (and other <code>java.time</code> types) in event payloads caused <code>InvalidDefinitionException</code> at serialization time</li> <li>Fix: <code>JavaTimeModule</code> is now registered directly on the <code>ObjectMapper</code> in <code>CurveEventSerializerAutoConfiguration</code> at serializer construction time, independent of customizer ordering</li> <li>Also registered <code>JavaTimeModule</code> as a Spring bean in <code>CurveJacksonAutoConfiguration</code> to align with Spring Boot's module detection convention</li> </ul> </li> <li>Sample app PII configuration: Added <code>curve.pii.crypto.default-key</code> to sample application configuration to demonstrate PII encryption setup</li> </ul>"},{"location":"CHANGELOG/#011-2026-02-19","title":"0.1.1 - 2026-02-19","text":""},{"location":"CHANGELOG/#fixed_1","title":"Fixed","text":"<ul> <li>PII Processing (Critical): Replace direct <code>ObjectMapper</code> bean creation with <code>Jackson2ObjectMapperBuilderCustomizer</code> in <code>CurveJacksonAutoConfiguration</code><ul> <li>Root cause: <code>@Primary</code> ObjectMapper was created by bypassing Spring Boot's builder pipeline, so <code>PiiModule</code> registered via <code>Jackson2ObjectMapperBuilderCustomizer</code> was never applied to it</li> <li>Effect: <code>@PiiField</code> annotations were silently ignored during event serialization \u2014 fields were published unmasked/unencrypted/unhashed</li> <li>Fix: Curve now contributes to Spring Boot's single managed <code>ObjectMapper</code> via the builder customizer, ensuring <code>JavaTimeModule</code> and <code>PiiModule</code> are both applied</li> <li>No API changes required; existing <code>@PiiField</code> annotations will now work as intended</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#010-2026-02-07","title":"0.1.0 - 2026-02-07","text":""},{"location":"CHANGELOG/#security","title":"Security","text":"<ul> <li>AES Key Validation Enhancement: Enforce exactly 32-byte keys; reject shorter keys instead of zero-padding to prevent weak encryption<ul> <li>Previous behavior: Keys &lt; 32 bytes were silently padded with zeros (security risk)</li> <li>New behavior: Keys must be exactly 32 bytes; throws <code>IllegalArgumentException</code> otherwise</li> <li>Migration: Generate proper key with <code>openssl rand -base64 32</code></li> </ul> </li> <li>HMAC Salt Security Warning: Add prominent warning when PII HMAC salt is not configured<ul> <li>Non-breaking: Uses default salt with clear security warning in logs</li> <li>Production deployments should configure <code>curve.pii.crypto.salt</code></li> </ul> </li> <li>Envelope Encryption Boundary Validation: Add minimum IV length validation (12 bytes) in envelope decryption<ul> <li>Prevents <code>IndexOutOfBoundsException</code> with corrupted ciphertext</li> <li>Provides clear error messages for invalid envelope format</li> </ul> </li> <li>SpEL Parameter Safety: Handle missing parameter names gracefully in SpEL expressions<ul> <li>Provides fallback parameter names (<code>p0</code>, <code>p1</code>, ...) when debug info unavailable</li> <li>Prevents <code>NullPointerException</code> in builds without parameter name retention</li> </ul> </li> <li>Vault Path Traversal Protection: Add regex validation for Vault keyId to prevent path traversal attacks<ul> <li>Only allows alphanumeric characters, underscores, and hyphens</li> <li>Blocks malicious keyIds like <code>../../admin-key</code></li> </ul> </li> </ul>"},{"location":"CHANGELOG/#performance","title":"Performance","text":"<ul> <li>Outbox Query Caching: Cache pending event count with 5-second TTL<ul> <li>Reduces database queries from 86,400/day to 17,280/day (80% reduction)</li> <li>Significantly decreases DB load in high-throughput scenarios</li> </ul> </li> <li>Regex Pre-compilation: Pre-compile regex patterns in <code>PhoneMasker</code> for ~30% performance improvement<ul> <li>Eliminates per-call compilation overhead</li> <li>Improves PII masking throughput</li> </ul> </li> <li>Circuit Breaker Thread Safety: Synchronize circuit breaker state transitions<ul> <li>Prevents race conditions in multi-threaded environments</li> <li>Ensures reliable circuit breaker operation under concurrent load</li> </ul> </li> <li>Enhanced Debug Logging: Add debug logging to <code>EventEnvelopeFactory</code><ul> <li>Improves event creation traceability</li> <li>Aids in debugging event publication issues</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Code Quality: Refactored <code>SchemaRegistry.findMigrationPath()</code> to improve maintainability<ul> <li>Split 111-instruction method into 6 smaller, focused methods</li> <li>Added 5 edge case tests for migration path scenarios</li> </ul> </li> <li>Documentation Structure: Consolidated <code>CHANGELOG.md</code> to single source in <code>docs/</code><ul> <li>Removed duplicate from project root</li> <li>Updated README references</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#fixed_2","title":"Fixed","text":"<ul> <li>Test Compatibility: Updated <code>AesUtilTest</code> to expect key length validation<ul> <li>Test now validates security improvement (key rejection)</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#005-2026-02-05","title":"0.0.5 - 2026-02-05","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>KMS Module: New <code>kms</code> module for external key management service integration<ul> <li><code>KeyProvider</code> interface in core with envelope encryption support (<code>generateDataKey</code>, <code>decryptDataKey</code>, <code>supportsEnvelopeEncryption</code>)</li> <li><code>EnvelopeDataKey</code> record for carrying both plaintext and encrypted DEK</li> <li><code>KeyProviderException</code> domain exception for KMS-related errors</li> </ul> </li> <li>AWS KMS Provider: <code>AwsKmsProvider</code> with full envelope encryption<ul> <li>Generates DEK via KMS <code>GenerateDataKey</code> and stores encrypted DEK alongside ciphertext</li> <li>TTL-based dual cache (generate + decrypt) with configurable max size and oldest-entry eviction</li> <li><code>invalidateAll()</code> for key rotation support</li> </ul> </li> <li>HashiCorp Vault Provider: <code>VaultKeyProvider</code> for Vault K/V secret engine<ul> <li>Fetches pre-existing encryption keys from Vault paths</li> </ul> </li> <li>KMS PII Crypto Provider: <code>KmsPiiCryptoProvider</code> supporting both modes<ul> <li>Envelope encryption mode (AWS KMS): ciphertext format <code>Base64([2-byte encDEK len][encDEK][IV + AES-GCM ciphertext])</code></li> <li>Static key mode (Vault K/V): fetches key and encrypts locally</li> </ul> </li> <li>KMS Auto-Configuration: <code>CurveKmsAutoConfiguration</code> with conditional beans<ul> <li><code>AwsKmsConfiguration</code> (<code>@ConditionalOnClass(KmsClient.class)</code>, <code>@ConditionalOnProperty(type=aws)</code>)</li> <li><code>VaultConfiguration</code> (<code>@ConditionalOnClass(VaultTemplate.class)</code>, <code>@ConditionalOnProperty(type=vault)</code>)</li> <li><code>KmsProperties</code> with separate <code>Aws</code> and <code>Vault</code> configuration sections</li> </ul> </li> <li>AES Utility: Extracted <code>AesUtil</code> from <code>DefaultPiiCryptoProvider</code> for shared AES-256-GCM logic<ul> <li><code>encryptWithKey</code>/<code>decryptWithKey</code> methods accepting <code>SecretKey</code> directly (eliminates Base64 roundtrip)</li> <li><code>encryptToBytes</code>/<code>decryptFromBytes</code> for envelope encryption byte packing</li> </ul> </li> <li>Comprehensive Tests: Full test coverage for all new components<ul> <li><code>AwsKmsProviderTest</code> (9 tests): envelope encryption, caching, TTL expiry, eviction, invalidation</li> <li><code>KmsPiiCryptoProviderTest</code> (12 tests): static key mode, envelope mode, hash operations</li> <li><code>AesUtilTest</code> (21 tests): round-trip, null safety, Unicode/emoji, key handling</li> <li><code>KeyProviderTest</code>, <code>KeyProviderExceptionTest</code>, <code>EnvelopeDataKeyTest</code> in core</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#changed_1","title":"Changed","text":"<ul> <li>deps: Bump SonarQube Gradle plugin from 4.4.1.3373 to 7.2.2.6593 (#14)<ul> <li>Resolves deprecation warning for compile task dependency</li> <li>Adds Gradle 9 and configuration-cache support</li> </ul> </li> <li>deps: Unify AWS SDK BOM to 2.41.21 across all modules (#2)<ul> <li>Fixes version mismatch between <code>kafka</code>, <code>kms</code>, and <code>spring-boot-autoconfigure</code> modules</li> <li>Includes 20+ months of security patches and performance improvements</li> </ul> </li> <li>deps: Bump Confluent Kafka Avro Serializer from 7.5.0 to 8.1.1 (#11)</li> <li>deps: Bump TestContainers from 1.20.4 to 1.21.4 (#6)</li> <li>deps: Bump Release Plugin from 3.0.2 to 3.1.0 (#10)</li> <li>deps: Bump Spring Cloud from 2023.0.0 to 2024.0.1 (Spring Boot 3.5.x compatibility)</li> <li>DefaultPiiCryptoProvider: Refactored to use <code>AesUtil</code> with direct <code>SecretKey</code> methods, eliminating <code>SecretKey \u2192 Base64 \u2192 SecretKey</code> conversion overhead</li> <li>CurveProperties: Simplified <code>Pii.Kms</code> to only <code>enabled</code> and <code>type</code> fields; provider-specific settings moved to <code>KmsProperties</code> in kms module</li> <li>Build: Added <code>kms</code> module to <code>publishableProjects</code>, SonarQube coverage paths, and JaCoCo configuration</li> <li>Tests: Translated all test <code>@DisplayName</code> annotations from Korean to English across core, kafka, and autoconfigure modules</li> </ul>"},{"location":"CHANGELOG/#security_1","title":"Security","text":"<ul> <li>Replace <code>StandardEvaluationContext</code> with <code>SimpleEvaluationContext</code> in SpEL evaluation<ul> <li>Blocks type references, constructor calls, and static method access</li> <li>Applies least-privilege principle with <code>forReadOnlyDataBinding().withInstanceMethods()</code></li> </ul> </li> </ul>"},{"location":"CHANGELOG/#ci","title":"CI","text":"<ul> <li>Bump actions/checkout from 4 to 6 (#5)</li> <li>Bump actions/upload-artifact from 4 to 6 (#3)</li> <li>Bump codecov/codecov-action from 4 to 5 (#4)</li> <li>Bump softprops/action-gh-release from 1 to 2 (#7)</li> <li>Bump stefanzweifel/git-auto-commit-action from 5 to 7 (#1)</li> </ul>"},{"location":"CHANGELOG/#004-2026-02-04","title":"0.0.4 - 2026-02-04","text":""},{"location":"CHANGELOG/#fixed_3","title":"Fixed","text":"<ul> <li>ci: Fix git-cliff installation path</li> </ul>"},{"location":"CHANGELOG/#ci_1","title":"Ci","text":"<ul> <li>Add workflow_dispatch to release-docs for manual execution</li> </ul>"},{"location":"CHANGELOG/#003-2026-02-04","title":"0.0.3 - 2026-02-04","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>S3 Backup Strategy: Added support for backing up failed events to AWS S3 or MinIO.<ul> <li>Ideal for Kubernetes/Cloud environments where local storage is ephemeral.</li> <li>Configurable via <code>curve.kafka.backup.s3-enabled=true</code>.</li> </ul> </li> <li>Composite Backup Strategy: Support for multiple backup strategies (e.g., try S3 first, then fallback to local file).</li> </ul>"},{"location":"CHANGELOG/#changed_2","title":"Changed","text":"<ul> <li>Refactored Backup Logic: Extracted backup logic into <code>EventBackupStrategy</code> interface for better extensibility.</li> <li>Documentation Update:<ul> <li>Updated all documentation to use standard Kafka port <code>9092</code> instead of <code>9094</code>.</li> <li>Added detailed configuration guide for S3 backup.</li> <li>Translated Javadoc and test display names to English for better internationalization.</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#002-2026-02-03","title":"0.0.2 - 2026-02-03","text":""},{"location":"CHANGELOG/#changed_3","title":"Changed","text":"<ul> <li>Avro dependencies (<code>avro</code>, <code>kafka-avro-serializer</code>) are now optional<ul> <li>JSON serialization works out of the box without additional repositories</li> <li>Users who need Avro must explicitly add Confluent repository and dependencies</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#fixed_4","title":"Fixed","text":"<ul> <li>Fixed GPG signing configuration for Maven Central publishing</li> <li>Fixed Sonatype Central Portal URL compatibility</li> </ul>"},{"location":"CHANGELOG/#001-2026-02-03","title":"0.0.1 - 2026-02-03","text":""},{"location":"CHANGELOG/#added_2","title":"Added","text":""},{"location":"CHANGELOG/#core-features","title":"Core Features","text":"<ul> <li>Declarative event publishing with <code>@PublishEvent</code> annotation</li> <li>Hexagonal architecture with framework-independent core module</li> <li>Automatic PII protection with <code>@PiiField</code> annotation<ul> <li>MASK strategy for pattern-based masking</li> <li>ENCRYPT strategy using AES-256-GCM</li> <li>HASH strategy using SHA-256 (later upgraded to HMAC-SHA256 in Unreleased)</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#event-infrastructure","title":"Event Infrastructure","text":"<ul> <li>Snowflake ID generator for distributed unique IDs (1024 workers, 4096 IDs/ms/worker)</li> <li>3-tier failure recovery system (Main Topic \u2192 DLQ \u2192 Local File Backup)</li> <li>Transactional Outbox Pattern support with circuit breaker and exponential backoff</li> <li>Dynamic batch sizing based on queue depth</li> <li>Automatic cleanup job for old outbox events</li> </ul>"},{"location":"CHANGELOG/#spring-integration","title":"Spring Integration","text":"<ul> <li>Spring Boot auto-configuration</li> <li>AOP-based event publishing aspect</li> <li>Context providers for automatic metadata extraction<ul> <li>Actor context (Spring Security integration)</li> <li>Trace context (MDC-based distributed tracing)</li> <li>Correlation ID propagation</li> <li>Client IP extraction</li> </ul> </li> </ul>"},{"location":"CHANGELOG/#kafka-integration","title":"Kafka Integration","text":"<ul> <li>KafkaEventProducer with sync/async modes</li> <li>Dead Letter Queue (DLQ) support</li> <li>Configurable retry with exponential backoff</li> <li>Local file backup for complete Kafka failure scenarios</li> </ul>"},{"location":"CHANGELOG/#observability","title":"Observability","text":"<ul> <li>Health indicator (<code>/actuator/health/curve</code>)</li> <li>Custom metrics endpoint (<code>/actuator/curve-metrics</code>)</li> <li>Micrometer integration for metrics collection</li> </ul>"},{"location":"CHANGELOG/#serialization","title":"Serialization","text":"<ul> <li>JSON serialization (default)</li> <li>Apache Avro serialization support</li> <li>Schema Registry integration</li> </ul>"},{"location":"CHANGELOG/#documentation","title":"Documentation","text":"<ul> <li>README in English and Korean</li> <li>Comprehensive configuration guide</li> <li>Quick start guide for sample application</li> </ul>"},{"location":"CHANGELOG/#security_2","title":"Security","text":"<ul> <li>Local backup files created with restricted permissions (600 on POSIX, ACL on Windows)</li> <li>PII encryption key required via environment variable</li> <li>Sensitive data automatically masked/encrypted in events</li> </ul>"},{"location":"CHANGELOG/#infrastructure","title":"Infrastructure","text":"<ul> <li>JaCoCo coverage verification (70% minimum threshold)</li> <li>GitHub Actions CI/CD pipeline</li> <li>Release workflow for tag-based releases</li> <li>Multi-module Gradle project structure</li> </ul>"},{"location":"CHANGELOG/#version-history","title":"Version History","text":"Version Date Description 0.1.2 2026-02-20 Fix JavaTimeModule silently removed by PiiModule customizer ordering 0.1.1 2026-02-19 Fix PII silent failure due to Jackson ObjectMapper builder pipeline bypass 0.1.0 2026-02-07 Security &amp; performance improvements (AES key validation, HMAC salt warning, etc.) 0.0.5 2026-02-05 Add KMS module (AWS KMS / HashiCorp Vault) with envelope encryption 0.0.4 2026-02-04 Add workflow_dispatch to release-docs for manual execution 0.0.3 2026-02-04 Add S3 Backup Strategy &amp; Doc Updates 0.0.2 2026-02-03 Make Avro dependencies optional 0.0.1 2026-02-03 Initial release"},{"location":"CHANGELOG/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"CHANGELOG/#from-00x-to-01x-future","title":"From 0.0.x to 0.1.x (Future)","text":"<p>No breaking changes documented yet.</p>"},{"location":"CHANGELOG/#contributing","title":"Contributing","text":"<p>When contributing, please update this changelog:</p> <ol> <li>Add your changes under <code>[Unreleased]</code> section</li> <li>Use appropriate category:<ul> <li>Added for new features</li> <li>Changed for changes in existing functionality</li> <li>Deprecated for soon-to-be removed features</li> <li>Removed for now removed features</li> <li>Fixed for any bug fixes</li> <li>Security for vulnerability fixes</li> </ul> </li> <li>Include issue/PR references where applicable</li> </ol>"},{"location":"CONFIGURATION/","title":"Curve Configuration Guide","text":"<p>This document describes the detailed configuration methods for the Curve event publishing library.</p>"},{"location":"CONFIGURATION/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Basic Configuration</li> <li>Configuration Validation</li> <li>Worker ID Configuration</li> <li>Kafka Transmission Mode Configuration</li> <li>DLQ Configuration</li> <li>Backup Strategy Configuration</li> <li>Retry Configuration</li> <li>AOP Configuration</li> <li>PII Protection Configuration</li> <li>Outbox Configuration</li> <li>Serialization Configuration</li> <li>Avro Serialization Configuration</li> <li>Logging Configuration</li> </ul>"},{"location":"CONFIGURATION/#basic-configuration","title":"Basic Configuration","text":""},{"location":"CONFIGURATION/#applicationyml","title":"application.yml","text":"<pre><code>curve:\n  enabled: true  # Enable Curve (default: true)\n\n  kafka:\n    topic: event.audit.v1  # Main topic name\n    dlq-topic: event.audit.dlq.v1  # DLQ topic (optional)\n\n  id-generator:\n    worker-id: 1  # Snowflake Worker ID (0~1023)\n    auto-generate: false  # Auto-generate based on MAC address\n</code></pre>"},{"location":"CONFIGURATION/#configuration-validation","title":"Configuration Validation","text":"<p>Curve automatically validates configuration values at application startup using <code>@Validated</code>. If invalid configuration values are entered, the application will fail to start with a clear error message.</p>"},{"location":"CONFIGURATION/#validation-rules","title":"Validation Rules","text":"Configuration Item Validation Rule Error Message <code>curve.kafka.topic</code> Required (non-empty string) \"Kafka topic is required\" <code>curve.kafka.retries</code> 0 or greater \"retries must be 0 or greater\" <code>curve.kafka.retry-backoff-ms</code> Positive number \"retryBackoffMs must be positive\" <code>curve.kafka.request-timeout-ms</code> Positive number \"requestTimeoutMs must be positive\" <code>curve.kafka.async-timeout-ms</code> Positive number \"asyncTimeoutMs must be positive\" <code>curve.kafka.sync-timeout-seconds</code> Positive number \"syncTimeoutSeconds must be positive\" <code>curve.kafka.dlq-executor-threads</code> 1 or greater \"dlqExecutorThreads must be 1 or greater\" <code>curve.id-generator.worker-id</code> 0 ~ 1023 \"workerId must be between 0 and 1023\" <code>curve.retry.max-attempts</code> 1 or greater \"maxAttempts must be 1 or greater\" <code>curve.retry.initial-interval</code> Positive number \"initialInterval must be positive\" <code>curve.retry.multiplier</code> 1 or greater \"multiplier must be 1 or greater\" <code>curve.retry.max-interval</code> Positive number \"maxInterval must be positive\" <code>curve.outbox.poll-interval-ms</code> Positive number \"pollIntervalMs must be positive\" <code>curve.outbox.batch-size</code> 1 ~ 1000 \"batchSize must be between 1 and 1000\" <code>curve.outbox.max-retries</code> 1 or greater \"maxRetries must be 1 or greater\" <code>curve.outbox.send-timeout-seconds</code> Positive number \"sendTimeoutSeconds must be positive\" <code>curve.outbox.retention-days</code> 1 or greater \"retentionDays must be 1 or greater\" <code>curve.async.core-pool-size</code> 1 or greater \"corePoolSize must be at least 1\" <code>curve.async.max-pool-size</code> 1 or greater \"maxPoolSize must be at least 1\" <code>curve.async.queue-capacity</code> 0 or greater \"queueCapacity must be at least 0\" <code>curve.kafka.backup.s3-bucket</code> Required when s3Enabled=true \"s3Bucket is required when s3Enabled=true\" <code>curve.serde.schema-registry-url</code> Required when type=AVRO \"schemaRegistryUrl is required when serde type is AVRO\""},{"location":"CONFIGURATION/#validation-error-example","title":"Validation Error Example","text":"<pre><code>***************************\nAPPLICATION FAILED TO START\n***************************\n\nDescription:\n\nBinding to target org.springframework.boot.context.properties.bind.BindException:\nFailed to bind properties under 'curve' to com.project.curve.autoconfigure.CurveProperties failed:\n\n    Property: curve.id-generator.worker-id\n    Value: \"2000\"\n    Reason: workerId must be 1023 or less\n</code></pre>"},{"location":"CONFIGURATION/#worker-id-configuration","title":"Worker ID Configuration","text":"<p>The Snowflake ID Generator uses a Worker ID to generate unique IDs in a distributed environment.</p>"},{"location":"CONFIGURATION/#method-1-explicit-worker-id-configuration-recommended","title":"Method 1: Explicit Worker ID Configuration (Recommended)","text":"<p>Assign a unique Worker ID to each instance.</p> <pre><code>curve:\n  id-generator:\n    worker-id: 1  # Instance 1\n    auto-generate: false\n</code></pre> <p>Kubernetes Environment Example:</p> <pre><code># deployment.yaml\nenv:\n  - name: CURVE_ID_GENERATOR_WORKER_ID\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.uid  # Use hashed Pod UID\n</code></pre> <p>Docker Compose Example:</p> <pre><code># docker-compose.yml\nservices:\n  app-1:\n    environment:\n      - CURVE_ID_GENERATOR_WORKER_ID=1\n  app-2:\n    environment:\n      - CURVE_ID_GENERATOR_WORKER_ID=2\n</code></pre>"},{"location":"CONFIGURATION/#method-2-auto-generation-caution","title":"Method 2: Auto-Generation (Caution)","text":"<p>Auto-generate Worker ID based on MAC address.</p> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre> <p>\u26a0\ufe0f Caution: - In virtual environments, MAC addresses may be identical, leading to conflicts - MAC addresses may change when containers restart - Explicit configuration is recommended for production environments</p>"},{"location":"CONFIGURATION/#worker-id-range","title":"Worker ID Range","text":"<ul> <li>Minimum value: 0</li> <li>Maximum value: 1023</li> <li>Recommended: Manage using environment variables or configuration management systems (Consul, etcd)</li> </ul>"},{"location":"CONFIGURATION/#kafka-transmission-mode-configuration","title":"Kafka Transmission Mode Configuration","text":"<p>Curve supports both synchronous and asynchronous transmission modes.</p>"},{"location":"CONFIGURATION/#synchronous-transmission-default","title":"Synchronous Transmission (Default)","text":"<pre><code>curve:\n  kafka:\n    async-mode: false  # Synchronous transmission\n    request-timeout-ms: 30000  # 30 seconds\n</code></pre> <p>Characteristics: - \u2705 Guaranteed transmission (clear success/failure confirmation) - \u2705 Easy error handling - \u274c Performance degradation (blocking) - \u274c Limited throughput</p> <p>Suitable for: - Financial transactions, payments, etc. where accuracy is critical - Cases where event loss is not acceptable - Low throughput (tens to hundreds of TPS)</p>"},{"location":"CONFIGURATION/#asynchronous-transmission","title":"Asynchronous Transmission","text":"<pre><code>curve:\n  kafka:\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000  # 5 seconds timeout\n</code></pre> <p>Characteristics: - \u2705 High performance (non-blocking) - \u2705 High throughput capability - \u26a0\ufe0f Callback-based error handling - \u26a0\ufe0f Relies on DLQ in case of transmission failure</p> <p>Suitable for: - Logs, analytics events, etc. where some loss is acceptable - High throughput required (thousands to tens of thousands of TPS) - Cases where latency is critical</p>"},{"location":"CONFIGURATION/#performance-comparison","title":"Performance Comparison","text":"Item Synchronous Transmission Asynchronous Transmission Throughput (TPS) ~500 ~10,000+ Latency High (10-50ms) Low (1-5ms) Transmission Guarantee Strong Moderate (DLQ dependent) Resource Usage High Low"},{"location":"CONFIGURATION/#dlq-configuration","title":"DLQ Configuration","text":"<p>The Dead Letter Queue stores events that fail to be transmitted.</p>"},{"location":"CONFIGURATION/#enable-dlq","title":"Enable DLQ","text":"<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # Enable DLQ\n</code></pre>"},{"location":"CONFIGURATION/#disable-dlq","title":"Disable DLQ","text":"<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic:  # Empty value or not configured\n</code></pre> <p>\u26a0\ufe0f Caution: Disabling DLQ may result in event loss in case of transmission failure.</p>"},{"location":"CONFIGURATION/#dlq-message-structure","title":"DLQ Message Structure","text":"<pre><code>{\n  \"eventId\": \"123456789\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"originalPayload\": \"{...}\",\n  \"exceptionType\": \"org.apache.kafka.common.errors.TimeoutException\",\n  \"exceptionMessage\": \"Failed to send message after 3 retries\",\n  \"failedAt\": 1704067200000\n}\n</code></pre>"},{"location":"CONFIGURATION/#backup-strategy-configuration","title":"Backup Strategy Configuration","text":"<p>Configure backup strategies for events that fail to be sent to DLQ.</p>"},{"location":"CONFIGURATION/#s3-backup-recommended-for-cloud","title":"S3 Backup (Recommended for Cloud)","text":"<pre><code>curve:\n  kafka:\n    backup:\n      s3-enabled: true\n      s3-bucket: \"my-event-backup-bucket\"\n      s3-prefix: \"dlq-backup\"\n</code></pre> <p>Requirements: - <code>software.amazon.awssdk:s3</code> dependency - <code>S3Client</code> bean in Spring Context</p>"},{"location":"CONFIGURATION/#local-file-backup","title":"Local File Backup","text":"<pre><code>curve:\n  kafka:\n    backup:\n      local-enabled: true\n    dlq-backup-path: \"./dlq-backup\"\n</code></pre>"},{"location":"CONFIGURATION/#retry-configuration","title":"Retry Configuration","text":"<p>Automatic retry configuration in case of transmission failure.</p>"},{"location":"CONFIGURATION/#basic-configuration_1","title":"Basic Configuration","text":"<pre><code>curve:\n  retry:\n    enabled: true  # Enable retry\n    max-attempts: 3  # Maximum 3 attempts\n    initial-interval: 1000  # Initial 1 second wait\n    multiplier: 2.0  # Increase by 2x (1s -&gt; 2s -&gt; 4s)\n    max-interval: 10000  # Maximum 10 seconds\n</code></pre>"},{"location":"CONFIGURATION/#exponential-backoff-example","title":"Exponential Backoff Example","text":"Attempt Wait Time 1st 0ms (immediate) 2nd 1,000ms (1 second) 3rd 2,000ms (2 seconds) 4th 4,000ms (4 seconds)"},{"location":"CONFIGURATION/#disable-retry","title":"Disable Retry","text":"<pre><code>curve:\n  retry:\n    enabled: false\n</code></pre>"},{"location":"CONFIGURATION/#aop-configuration","title":"AOP Configuration","text":"<p>AOP configuration based on <code>@PublishEvent</code> annotation.</p>"},{"location":"CONFIGURATION/#enable-aop-default","title":"Enable AOP (Default)","text":"<pre><code>curve:\n  aop:\n    enabled: true\n</code></pre>"},{"location":"CONFIGURATION/#disable-aop","title":"Disable AOP","text":"<pre><code>curve:\n  aop:\n    enabled: false\n</code></pre>"},{"location":"CONFIGURATION/#async-executor-configuration","title":"Async Executor Configuration","text":"<p>Curve can register a dedicated <code>curveAsyncExecutor</code> bean for async event processing.</p> <p>Note: This does NOT force <code>@EnableAsync</code> on the application. If you need <code>@EnableAsync</code>, enable it in your own configuration.</p>"},{"location":"CONFIGURATION/#enable-async-executor","title":"Enable Async Executor","text":"<pre><code>curve:\n  async:\n    enabled: true  # Register curveAsyncExecutor bean\n    core-pool-size: 2  # Core thread pool size (default: 2)\n    max-pool-size: 10  # Maximum thread pool size (default: 10)\n    queue-capacity: 500  # Task queue capacity (default: 500)\n</code></pre>"},{"location":"CONFIGURATION/#disable-async-executor-default","title":"Disable Async Executor (Default)","text":"<pre><code>curve:\n  async:\n    enabled: false\n</code></pre>"},{"location":"CONFIGURATION/#pii-protection-configuration","title":"PII Protection Configuration","text":"<p>Through PII (Personally Identifiable Information) protection features, sensitive data can be automatically masked, encrypted, or hashed.</p>"},{"location":"CONFIGURATION/#basic-configuration_2","title":"Basic Configuration","text":"<pre><code>curve:\n  pii:\n    enabled: true  # Enable PII protection (default: true)\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Encryption key (environment variable required)\n      salt: ${PII_HASH_SALT}              # Hashing salt (environment variable recommended)\n</code></pre>"},{"location":"CONFIGURATION/#encryption-key-configuration-required","title":"Encryption Key Configuration (Required)","text":"<p>When using <code>@PiiField(strategy = PiiStrategy.ENCRYPT)</code>, an encryption key is mandatory.</p> <p>1. Generate Key <pre><code># Generate 32-byte AES-256 key\nopenssl rand -base64 32\n# Output example: K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\n</code></pre></p> <p>2. Set Environment Variable (Recommended) <pre><code># Linux/macOS\nexport PII_ENCRYPTION_KEY=K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\nexport PII_HASH_SALT=your-random-salt-value\n\n# Windows PowerShell\n$env:PII_ENCRYPTION_KEY=\"K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\"\n$env:PII_HASH_SALT=\"your-random-salt-value\"\n</code></pre></p> <p>3. application.yml Configuration <pre><code>curve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n      salt: ${PII_HASH_SALT}\n</code></pre></p> <p>\u26a0\ufe0f Caution: - Do not hardcode the encryption key directly in application.yml - For production environments, use environment variables or external secret management systems (Vault, AWS Secrets Manager) - If the key is not configured, an exception will occur when using the ENCRYPT strategy</p>"},{"location":"CONFIGURATION/#pii-strategies","title":"PII Strategies","text":"Strategy Description Reversible Example <code>MASK</code> Pattern-based masking Not possible <code>John Doe</code> \u2192 <code>John **</code> <code>ENCRYPT</code> AES-256-GCM encryption Possible (key required) Encrypted Base64 string <code>HASH</code> HMAC-SHA256 hashing Not possible Hashed Base64 string"},{"location":"CONFIGURATION/#masking-patterns-by-pii-type","title":"Masking Patterns by PII Type","text":"Type Masking Pattern Example <code>NAME</code> Keep first character, mask rest <code>John Doe</code> \u2192 <code>J*** ***</code> <code>EMAIL</code> Keep local part, mask domain <code>user@example.com</code> \u2192 <code>user@***.com</code> <code>PHONE</code> Keep first 3 and last 4 digits only <code>010-1234-5678</code> \u2192 <code>010****5678</code> <code>DEFAULT</code> Keep first 30%, mask rest <code>Seoul Gangnam</code> \u2192 <code>Seou***</code>"},{"location":"CONFIGURATION/#usage-example","title":"Usage Example","text":"<pre><code>public class CustomerInfo {\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.MASK)\n    private String name;\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(strategy = PiiStrategy.HASH)\n    private String ssn;  // Social Security Number\n}\n</code></pre>"},{"location":"CONFIGURATION/#kubernetes-environment-configuration","title":"Kubernetes Environment Configuration","text":"<pre><code># deployment.yaml\nenv:\n  - name: PII_ENCRYPTION_KEY\n    valueFrom:\n      secretKeyRef:\n        name: curve-secrets\n        key: pii-encryption-key\n  - name: PII_HASH_SALT\n    valueFrom:\n      secretKeyRef:\n        name: curve-secrets\n        key: pii-hash-salt\n</code></pre> <pre><code># Create Secret\nkubectl create secret generic curve-secrets \\\n  --from-literal=pii-encryption-key=$(openssl rand -base64 32) \\\n  --from-literal=pii-hash-salt=$(openssl rand -base64 16)\n</code></pre>"},{"location":"CONFIGURATION/#outbox-configuration","title":"Outbox Configuration","text":"<p>Use the Transactional Outbox Pattern to ensure atomicity between DB transactions and event publishing.</p>"},{"location":"CONFIGURATION/#basic-configuration_3","title":"Basic Configuration","text":"<pre><code>curve:\n  outbox:\n    enabled: true  # Enable Outbox\n    poll-interval-ms: 1000  # Polling interval (1 second)\n    batch-size: 100  # Batch size\n    max-retries: 3  # Maximum retry count\n    send-timeout-seconds: 10  # Send timeout\n    cleanup-enabled: true  # Enable old event cleanup\n    retention-days: 7  # Retention period (7 days)\n    cleanup-cron: \"0 0 2 * * *\"  # Cleanup job execution time (2 AM daily)\n    initialize-schema: embedded  # Schema initialization mode (embedded, always, never)\n</code></pre>"},{"location":"CONFIGURATION/#schema-initialization-modes","title":"Schema Initialization Modes","text":"<ul> <li><code>embedded</code>: Automatically create tables only for embedded DBs like H2, HSQLDB (default)</li> <li><code>always</code>: Always attempt to create tables (if they don't exist)</li> <li><code>never</code>: No automatic creation (recommended when using Flyway/Liquibase)</li> </ul>"},{"location":"CONFIGURATION/#serialization-configuration","title":"Serialization Configuration","text":"<p>Configure the event payload serialization method.</p> <pre><code>curve:\n  serde:\n    type: JSON  # JSON (default), AVRO, PROTOBUF\n</code></pre>"},{"location":"CONFIGURATION/#avro-serialization-configuration","title":"Avro Serialization Configuration","text":"<p>Additional configuration is required to serialize events using Avro.</p>"},{"location":"CONFIGURATION/#1-curve-configuration","title":"1. Curve Configuration","text":"<pre><code>curve:\n  serde:\n    type: AVRO\n    schema-registry-url: http://localhost:8081  # Schema Registry address\n</code></pre>"},{"location":"CONFIGURATION/#2-spring-kafka-configuration-required","title":"2. Spring Kafka Configuration (Required)","text":"<p>You must explicitly specify the <code>value-serializer</code> in Spring Kafka's Producer configuration.</p> <pre><code>spring:\n  kafka:\n    producer:\n      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer\n    properties:\n      schema.registry.url: http://localhost:8081\n</code></pre> <p>\u26a0\ufe0f Caution: - When <code>curve.serde.type=AVRO</code> is configured, Curve internally creates a <code>GenericRecord</code> object and passes it to KafkaTemplate. - Therefore, you must use <code>KafkaAvroSerializer</code> so that KafkaTemplate can serialize <code>GenericRecord</code>. - <code>schema.registry.url</code> may need to be configured in both <code>curve.serde</code> and <code>spring.kafka.properties</code> (for Curve internal logic and Kafka Serializer).</p>"},{"location":"CONFIGURATION/#avro-schema-structure","title":"Avro Schema Structure","text":"<p>Curve internally uses the following fixed Avro schema. Some fields in <code>payload</code> and <code>metadata</code> are stored as JSON strings for flexibility.</p> <pre><code>{\n  \"type\": \"record\",\n  \"name\": \"EventEnvelope\",\n  \"namespace\": \"com.project.curve.core.envelope\",\n  \"fields\": [\n    {\"name\": \"eventId\", \"type\": \"string\"},\n    {\"name\": \"eventType\", \"type\": \"string\"},\n    {\"name\": \"severity\", \"type\": \"string\"},\n    {\"name\": \"metadata\", \"type\": { ... }},\n    {\"name\": \"payload\", \"type\": \"string\"}, // JSON String\n    {\"name\": \"occurredAt\", \"type\": \"long\", \"logicalType\": \"timestamp-millis\"},\n    {\"name\": \"publishedAt\", \"type\": \"long\", \"logicalType\": \"timestamp-millis\"}\n  ]\n}\n</code></pre>"},{"location":"CONFIGURATION/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"CONFIGURATION/#production-environment-stability-focused","title":"Production Environment (Stability-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${INSTANCE_ID}  # Injected from environment variable\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # Synchronous transmission\n    retries: 5\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n    # Backup Strategy\n    backup:\n      s3-enabled: true\n      s3-bucket: \"prod-event-backups\"\n      local-enabled: false\n\n  retry:\n    enabled: true\n    max-attempts: 5\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  aop:\n    enabled: true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Environment variable required\n      salt: ${PII_HASH_SALT}\n\n  async:\n    enabled: true\n    core-pool-size: 4\n    max-pool-size: 20\n    queue-capacity: 1000\n\n  outbox:\n    enabled: true\n    initialize-schema: never  # Use Flyway\n    cleanup-enabled: true\n    retention-days: 14\n</code></pre>"},{"location":"CONFIGURATION/#developmenttest-environment-performance-focused","title":"Development/Test Environment (Performance-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.dev.v1\n    dlq-topic: event.audit.dlq.dev.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 3000\n    retries: 3\n\n    backup:\n      local-enabled: true\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 500\n    multiplier: 1.5\n\n  aop:\n    enabled: true\n\n  outbox:\n    enabled: true\n    initialize-schema: always\n\n  async:\n    enabled: true\n</code></pre>"},{"location":"CONFIGURATION/#high-performance-environment","title":"High-Performance Environment","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${WORKER_ID}\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000\n    retries: 1  # Minimum retry\n\n  retry:\n    enabled: false  # Disable retry (performance priority)\n\n  aop:\n    enabled: true\n\n  async:\n    enabled: true\n    core-pool-size: 8\n    max-pool-size: 32\n    queue-capacity: 2000\n</code></pre>"},{"location":"CONFIGURATION/#environment-specific-configuration-recommendations","title":"Environment-specific Configuration Recommendations","text":""},{"location":"CONFIGURATION/#local-development","title":"Local Development","text":"<ul> <li>Worker ID: 1 (fixed)</li> <li>Transmission Mode: Synchronous (debugging convenience)</li> <li>DLQ: Enabled</li> <li>Retry: Minimum (fast failure)</li> <li>Outbox: Enabled (auto schema generation)</li> <li>Backup: Local File</li> </ul>"},{"location":"CONFIGURATION/#staging","title":"Staging","text":"<ul> <li>Worker ID: Environment variable</li> <li>Transmission Mode: Asynchronous</li> <li>DLQ: Enabled</li> <li>Retry: Medium level</li> <li>Outbox: Enabled</li> <li>Backup: S3 (if available) or Local</li> </ul>"},{"location":"CONFIGURATION/#production","title":"Production","text":"<ul> <li>Worker ID: Centrally managed (Consul/etcd)</li> <li>Transmission Mode: Based on business requirements</li> <li>DLQ: Mandatory enabled</li> <li>Retry: High level</li> <li>Outbox: Mandatory enabled (data consistency)</li> <li>Backup: S3 (Mandatory for K8s)</li> </ul>"},{"location":"CONFIGURATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"CONFIGURATION/#worker-id-conflict","title":"Worker ID Conflict","text":"<p>Symptom: Identical IDs are being generated</p> <p>Solution: <pre><code>curve:\n  id-generator:\n    worker-id: ${UNIQUE_INSTANCE_ID}\n</code></pre></p>"},{"location":"CONFIGURATION/#transmission-timeout","title":"Transmission Timeout","text":"<p>Symptom: <code>TimeoutException</code> occurs</p> <p>Solution: <pre><code>curve:\n  kafka:\n    request-timeout-ms: 60000  # Increase timeout\n</code></pre></p>"},{"location":"CONFIGURATION/#high-latency","title":"High Latency","text":"<p>Symptom: Event publishing is slow</p> <p>Solution: <pre><code>curve:\n  kafka:\n    async-mode: true  # Switch to asynchronous mode\n</code></pre></p>"},{"location":"CONFIGURATION/#pii-encryption-key-not-configured","title":"PII Encryption Key Not Configured","text":"<p>Symptom: <pre><code>ERROR: PII encryption key is not configured!\nERROR: An exception will occur when using @PiiField(strategy = PiiStrategy.ENCRYPT).\n</code></pre></p> <p>Solution: <pre><code># 1. Generate key\nopenssl rand -base64 32\n\n# 2. Set environment variable\nexport PII_ENCRYPTION_KEY=generated_key_value\n\n# 3. Configure application.yml\ncurve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n</code></pre></p>"},{"location":"CONFIGURATION/#configuration-validation-failure","title":"Configuration Validation Failure","text":"<p>Symptom: <pre><code>APPLICATION FAILED TO START\nReason: workerId must be 1023 or less\n</code></pre></p> <p>Solution: - Check if configuration values meet validation rules - Refer to validation rules in the Configuration Validation section</p>"},{"location":"CONFIGURATION/#logging-configuration","title":"Logging Configuration","text":"<p>By default, Curve outputs minimal logs. To see detailed configuration information or internal operations, enable the DEBUG level.</p>"},{"location":"CONFIGURATION/#basic-logging-info","title":"Basic Logging (INFO)","text":"<p>In the default configuration, only the following log is output:</p> <pre><code>INFO  c.p.c.a.CurveAutoConfiguration : Curve auto-configuration enabled (disable with curve.enabled=false)\n</code></pre>"},{"location":"CONFIGURATION/#enable-debug-logging","title":"Enable DEBUG Logging","text":"<pre><code>logging:\n  level:\n    com.project.curve: DEBUG\n</code></pre>"},{"location":"CONFIGURATION/#information-available-at-debug-level","title":"Information Available at DEBUG Level","text":"Item Description Kafka Producer Configuration Detailed configuration such as retries, timeout, async-mode RetryTemplate Configuration max-attempts, detailed backoff policy SnowflakeIdGenerator Worker ID and initialization information DLQ ExecutorService Thread pool size, shutdown timeout PII Module Encryption/salt configuration status, module registration Event Transmission Transmission details per event (eventId, topic, partition, offset) Outbox Publisher Polling, publishing, cleanup job logs"},{"location":"CONFIGURATION/#enable-debug-for-specific-modules-only","title":"Enable DEBUG for Specific Modules Only","text":"<pre><code>logging:\n  level:\n    # DEBUG for Kafka transmission only\n    com.project.curve.kafka: DEBUG\n\n    # DEBUG for Auto-Configuration only\n    com.project.curve.autoconfigure: DEBUG\n\n    # DEBUG for PII processing only\n    com.project.curve.spring.pii: DEBUG\n\n    # DEBUG for Outbox only\n    com.project.curve.spring.outbox: DEBUG\n</code></pre>"},{"location":"CONFIGURATION/#additional-information","title":"Additional Information","text":"<ul> <li>Snowflake ID Algorithm</li> <li>Kafka Producer Configuration</li> <li>Spring Retry</li> <li>Transactional Outbox Pattern</li> </ul>"},{"location":"MIGRATION/","title":"Migration Guide","text":"<p>This guide helps you upgrade between Curve versions safely.</p>"},{"location":"MIGRATION/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Versioning Strategy</li> <li>Version Compatibility Matrix</li> <li>Upgrade Checklist</li> <li>Migration: 0.0.x to 0.1.x</li> <li>Configuration Changes</li> <li>Breaking Changes Log</li> <li>Rollback Procedures</li> </ul>"},{"location":"MIGRATION/#versioning-strategy","title":"Versioning Strategy","text":"<p>Curve follows Semantic Versioning 2.0.0:</p> <pre><code>MAJOR.MINOR.PATCH\n\nExample: 1.2.3\n         \u2502 \u2502 \u2514\u2500\u2500 Patch: Bug fixes, no API changes\n         \u2502 \u2514\u2500\u2500\u2500\u2500 Minor: New features, backward compatible\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500 Major: Breaking changes\n</code></pre>"},{"location":"MIGRATION/#version-guidelines","title":"Version Guidelines","text":"Version Type Changes Action Required Patch (x.x.1) Bug fixes only Safe to upgrade immediately Minor (x.1.x) New features, deprecations Review changelog, test in staging Major (1.x.x) Breaking changes Follow migration guide carefully"},{"location":"MIGRATION/#pre-release-versions","title":"Pre-release Versions","text":"<ul> <li><code>0.x.x</code>: Initial development, API may change</li> <li><code>x.x.x-alpha</code>: Early testing, unstable</li> <li><code>x.x.x-beta</code>: Feature complete, testing phase</li> <li><code>x.x.x-rc.1</code>: Release candidate</li> </ul>"},{"location":"MIGRATION/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"Curve Version Spring Boot Java Kafka Client 0.1.2 3.5.x 17, 21 3.8+ 0.1.1 3.5.x 17, 21 3.8+ 0.1.0 3.5.x 17, 21 3.8+ 0.0.5 3.5.x 17, 21 3.8+ 0.0.1 - 0.0.4 3.4.x - 3.5.x 17, 21 3.0+"},{"location":"MIGRATION/#dependency-compatibility","title":"Dependency Compatibility","text":"<pre><code>// build.gradle\ndependencies {\n    // Curve 0.1.0 compatible versions\n    implementation 'org.springframework.boot:spring-boot-starter:3.5.9'\n    implementation 'org.springframework.kafka:spring-kafka:3.3.0'\n}\n</code></pre>"},{"location":"MIGRATION/#upgrade-checklist","title":"Upgrade Checklist","text":"<p>Before upgrading to a new version:</p>"},{"location":"MIGRATION/#pre-upgrade","title":"Pre-Upgrade","text":"<ul> <li>[ ] Read the CHANGELOG for the target version</li> <li>[ ] Check for breaking changes</li> <li>[ ] Review deprecated features you're using</li> <li>[ ] Backup database (especially outbox table)</li> <li>[ ] Test upgrade in staging environment</li> </ul>"},{"location":"MIGRATION/#during-upgrade","title":"During Upgrade","text":"<ul> <li>[ ] Update dependency version</li> <li>[ ] Update configuration if required</li> <li>[ ] Update code for any API changes</li> <li>[ ] Run tests</li> </ul>"},{"location":"MIGRATION/#post-upgrade","title":"Post-Upgrade","text":"<ul> <li>[ ] Verify application starts successfully</li> <li>[ ] Check <code>/actuator/health/curve</code> endpoint</li> <li>[ ] Monitor metrics for anomalies</li> <li>[ ] Verify events are being published</li> <li>[ ] Check outbox table processing (if enabled)</li> </ul>"},{"location":"MIGRATION/#migration-00x-to-010","title":"Migration: 0.0.x to 0.1.0","text":"<p>Version 0.1.0 includes important security enhancements and performance optimizations. Most changes are backward compatible, but please review the following:</p>"},{"location":"MIGRATION/#changes-in-010","title":"Changes in 0.1.0","text":"<ol> <li>Security Improvements (Non-Breaking)</li> <li> <p>AES Key Validation: Keys must be exactly 32 bytes (Base64-encoded)</p> <ul> <li>Previous: Keys &lt; 32 bytes were padded with zeros (insecure)</li> <li>Now: Keys must be exactly 32 bytes; throws <code>IllegalArgumentException</code> otherwise</li> <li>Action: Regenerate keys with <code>openssl rand -base64 32</code></li> </ul> </li> <li> <p>HMAC Salt Warning: Warns if PII HMAC salt not configured</p> <ul> <li>Action: Set <code>curve.pii.crypto.salt</code> for production</li> </ul> </li> <li> <p>Vault Path Traversal Protection: Added validation for Vault keyId</p> <ul> <li>Only alphanumeric, underscores, and hyphens allowed</li> <li>Action: No action needed unless using invalid keyId patterns</li> </ul> </li> <li> <p>Performance Improvements (Transparent)</p> </li> <li>Outbox query caching (5-second TTL)</li> <li>Regex pre-compilation in PhoneMasker</li> <li>Circuit breaker thread safety</li> <li> <p>All improvements are automatic</p> </li> <li> <p>API Changes</p> </li> <li>No breaking API changes</li> <li>All existing code continues to work</li> </ol>"},{"location":"MIGRATION/#upgrade-steps","title":"Upgrade Steps","text":"<pre><code>// Update dependency version\ndependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'\n}\n</code></pre> <pre><code># Recommended: Configure HMAC salt (if not already set)\ncurve:\n  pii:\n    crypto:\n      salt: ${PII_HASH_SALT}  # Generate with: openssl rand -base64 32\n</code></pre>"},{"location":"MIGRATION/#configuration-changes","title":"Configuration Changes","text":""},{"location":"MIGRATION/#configuration-changelog","title":"Configuration Changelog","text":""},{"location":"MIGRATION/#version-001-initial","title":"Version 0.0.1 (Initial)","text":"<p>All configurations introduced. See CONFIGURATION.md.</p>"},{"location":"MIGRATION/#version-005","title":"Version 0.0.5","text":"<ul> <li>Added <code>curve.async.*</code> properties (enabled, core-pool-size, max-pool-size, queue-capacity)</li> <li>Added <code>curve.kafka.backup.s3-*</code> properties for S3 backup</li> <li>Added <code>curve.kafka.sync-timeout-seconds</code></li> <li>Added <code>curve.outbox.send-timeout-seconds</code></li> <li>Added KMS properties (<code>curve.pii.kms.*</code>)</li> </ul>"},{"location":"MIGRATION/#unreleased-security-improvements","title":"Unreleased (Security Improvements)","text":"<ul> <li>PII HASH strategy: Changed from SHA-256 to HMAC-SHA256. Existing hashed values will differ after upgrade.</li> <li>AES encryption key: Must be exactly 32 bytes (Base64-encoded). Keys of incorrect length are now rejected.</li> <li>Health check: Now uses <code>AdminClient.describeCluster()</code> instead of <code>KafkaTemplate.metrics()</code>. Health response format changed (<code>clusterId</code> and <code>nodeCount</code> instead of <code>producerMetrics</code>).</li> <li>Async executor: <code>@EnableAsync</code> is no longer automatically applied. Set <code>curve.async.enabled=true</code> to register the <code>curveAsyncExecutor</code> bean.</li> </ul>"},{"location":"MIGRATION/#version-010","title":"Version 0.1.0","text":"<p>No configuration property changes. All changes are backward compatible.</p>"},{"location":"MIGRATION/#deprecated-properties","title":"Deprecated Properties","text":"<p>Currently, no properties are deprecated.</p> <p>When properties are deprecated: <pre><code># Deprecated in 0.2.0, removed in 1.0.0\ncurve:\n  kafka:\n    old-property: value  # DEPRECATED: Use 'new-property' instead\n    new-property: value\n</code></pre></p>"},{"location":"MIGRATION/#breaking-changes-log","title":"Breaking Changes Log","text":""},{"location":"MIGRATION/#version-010_1","title":"Version 0.1.0","text":"<p>No breaking changes. All improvements are backward compatible with proper warnings.</p>"},{"location":"MIGRATION/#version-001","title":"Version 0.0.1","text":"<p>Initial release - no breaking changes (baseline).</p>"},{"location":"MIGRATION/#future-versions","title":"Future Versions","text":"<p>Breaking changes will be documented here with: - What changed - Why it changed - How to migrate</p>"},{"location":"MIGRATION/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"MIGRATION/#quick-rollback","title":"Quick Rollback","text":"<ol> <li> <p>Revert dependency version <pre><code>// build.gradle\nimplementation 'io.github.closeup1202:curve:0.0.5'  // Previous version\n</code></pre></p> </li> <li> <p>Revert configuration changes (if any)</p> </li> <li> <p>Redeploy application</p> </li> </ol>"},{"location":"MIGRATION/#database-rollback-outbox","title":"Database Rollback (Outbox)","text":"<p>If schema changed, you may need to rollback database:</p> <pre><code>-- Example rollback script (adjust based on actual changes)\n-- WARNING: This may cause data loss\n\n-- Backup first\nCREATE TABLE curve_outbox_events_backup AS\nSELECT * FROM curve_outbox_events;\n\n-- Rollback schema (example)\nALTER TABLE curve_outbox_events DROP COLUMN IF EXISTS new_column;\n</code></pre>"},{"location":"MIGRATION/#rollback-checklist","title":"Rollback Checklist","text":"<ul> <li>[ ] Revert application version</li> <li>[ ] Revert configuration</li> <li>[ ] Revert database schema (if changed)</li> <li>[ ] Clear any cached data</li> <li>[ ] Restart all instances</li> <li>[ ] Verify health checks</li> <li>[ ] Monitor for issues</li> </ul>"},{"location":"MIGRATION/#upgrading-dependencies","title":"Upgrading Dependencies","text":""},{"location":"MIGRATION/#spring-boot-upgrade","title":"Spring Boot Upgrade","text":"<p>When upgrading Spring Boot:</p> <ol> <li>Check Curve compatibility in the matrix above</li> <li>Upgrade Spring Boot first</li> <li>Test thoroughly</li> <li>Then upgrade Curve if needed</li> </ol> <pre><code>// Upgrade order\nplugins {\n    id 'org.springframework.boot' version '3.5.9'  // Step 1\n}\n\ndependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'  // Step 2\n}\n</code></pre>"},{"location":"MIGRATION/#kafka-client-upgrade","title":"Kafka Client Upgrade","text":"<p>Curve is compatible with Kafka Client 3.0+. When upgrading:</p> <ol> <li>Check Spring Kafka compatibility</li> <li>Test producer functionality</li> <li>Verify serialization works correctly</li> </ol>"},{"location":"MIGRATION/#getting-help","title":"Getting Help","text":"<p>If you encounter issues during migration:</p> <ol> <li>Check TROUBLESHOOTING.md</li> <li>Search existing issues</li> <li>Open a new issue with:</li> <li>Source version</li> <li>Target version</li> <li>Error messages</li> <li>Configuration (sanitized)</li> </ol>"},{"location":"MIGRATION/#version-history","title":"Version History","text":"<p>See CHANGELOG.md for complete version history.</p>"},{"location":"MONITORING/","title":"Monitoring &amp; Dashboard Guide","text":"<p>This guide explains how to monitor Curve event publishing and set up dashboards for failed event tracking.</p>"},{"location":"MONITORING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Available Metrics</li> <li>Health Indicators</li> <li>Prometheus Integration</li> <li>Grafana Dashboards</li> <li>Alerting Rules</li> <li>Log Monitoring</li> </ul>"},{"location":"MONITORING/#available-metrics","title":"Available Metrics","text":""},{"location":"MONITORING/#curve-custom-endpoint","title":"Curve Custom Endpoint","text":"<p>Access Curve-specific metrics: <pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre></p> <p>Response: <pre><code>{\n  \"eventsPublished\": 1523,\n  \"eventsFailed\": 12,\n  \"dlqEvents\": 8,\n  \"outboxPending\": 3,\n  \"lastPublishTime\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre></p>"},{"location":"MONITORING/#micrometer-metrics","title":"Micrometer Metrics","text":"<p>Curve exposes the following metrics via Micrometer:</p> Metric Name Type Description <code>curve.events.published</code> Counter Total successfully published events <code>curve.events.failed</code> Counter Total failed event publications <code>curve.events.dlq</code> Counter Events sent to DLQ <code>curve.events.publish.duration</code> Timer Event publishing duration <code>curve.outbox.pending</code> Gauge Current pending outbox events <code>curve.outbox.processed</code> Counter Processed outbox events <code>curve.circuit.state</code> Gauge Circuit breaker state (0=closed, 1=open, 2=half-open)"},{"location":"MONITORING/#enabling-metrics","title":"Enabling Metrics","text":"<pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,prometheus,curve-metrics\n  metrics:\n    tags:\n      application: ${spring.application.name}\n</code></pre>"},{"location":"MONITORING/#health-indicators","title":"Health Indicators","text":""},{"location":"MONITORING/#curve-health-check","title":"Curve Health Check","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <p>Healthy Response: <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"clusterId\": \"lkc-abc123\",\n    \"nodeCount\": 3,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre></p> <p>Unhealthy Response: <pre><code>{\n  \"status\": \"DOWN\",\n  \"details\": {\n    \"error\": \"Kafka broker unreachable: Connection refused\"\n  }\n}\n</code></pre></p>"},{"location":"MONITORING/#health-configuration","title":"Health Configuration","text":"<pre><code>management:\n  health:\n    curve:\n      enabled: true\n  endpoint:\n    health:\n      show-details: always\n</code></pre>"},{"location":"MONITORING/#prometheus-integration","title":"Prometheus Integration","text":""},{"location":"MONITORING/#configuration","title":"Configuration","text":"<p>Add to your <code>application.yml</code>: <pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: prometheus\n  prometheus:\n    metrics:\n      export:\n        enabled: true\n</code></pre></p>"},{"location":"MONITORING/#scrape-configuration","title":"Scrape Configuration","text":"<p>Add to <code>prometheus.yml</code>: <pre><code>scrape_configs:\n  - job_name: 'curve-app'\n    metrics_path: '/actuator/prometheus'\n    static_configs:\n      - targets: ['app-host:8080']\n    scrape_interval: 15s\n</code></pre></p>"},{"location":"MONITORING/#key-prometheus-queries","title":"Key Prometheus Queries","text":"<p>Event Publishing Rate: <pre><code>rate(curve_events_published_total[5m])\n</code></pre></p> <p>Error Rate: <pre><code>rate(curve_events_failed_total[5m]) / rate(curve_events_published_total[5m]) * 100\n</code></pre></p> <p>Publishing Latency (p99): <pre><code>histogram_quantile(0.99, rate(curve_events_publish_duration_seconds_bucket[5m]))\n</code></pre></p> <p>Outbox Queue Depth: <pre><code>curve_outbox_pending\n</code></pre></p> <p>Circuit Breaker State: <pre><code>curve_circuit_state\n</code></pre></p>"},{"location":"MONITORING/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"MONITORING/#dashboard-json","title":"Dashboard JSON","text":"<p>Import this dashboard into Grafana:</p> <pre><code>{\n  \"title\": \"Curve Event Publishing\",\n  \"panels\": [\n    {\n      \"title\": \"Events Published per Second\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(curve_events_published_total[1m])\",\n          \"legendFormat\": \"{{instance}}\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Failed Events\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(curve_events_failed_total[1h])\"\n        }\n      ],\n      \"thresholds\": {\n        \"steps\": [\n          {\"color\": \"green\", \"value\": 0},\n          {\"color\": \"yellow\", \"value\": 10},\n          {\"color\": \"red\", \"value\": 50}\n        ]\n      }\n    },\n    {\n      \"title\": \"Publishing Latency\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.50, rate(curve_events_publish_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p50\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.95, rate(curve_events_publish_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p95\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.99, rate(curve_events_publish_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p99\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Outbox Queue Depth\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"curve_outbox_pending\",\n          \"legendFormat\": \"{{instance}}\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Circuit Breaker State\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"curve_circuit_state\"\n        }\n      ],\n      \"mappings\": [\n        {\"value\": 0, \"text\": \"CLOSED\"},\n        {\"value\": 1, \"text\": \"OPEN\"},\n        {\"value\": 2, \"text\": \"HALF-OPEN\"}\n      ]\n    },\n    {\n      \"title\": \"DLQ Events (Last 24h)\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(curve_events_dlq_total[24h])\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"MONITORING/#dashboard-panels-explained","title":"Dashboard Panels Explained","text":"Panel Purpose Action When High Events/sec Publishing throughput Normal operation Failed Events Publication failures Check Kafka connectivity Latency Publishing performance Enable async mode Queue Depth Outbox backlog Scale up or fix Kafka Circuit State Failure protection Check underlying issue DLQ Events Unrecoverable failures Manual review required"},{"location":"MONITORING/#alerting-rules","title":"Alerting Rules","text":""},{"location":"MONITORING/#prometheus-alerting-rules","title":"Prometheus Alerting Rules","text":"<p>Create <code>curve-alerts.yml</code>:</p> <pre><code>groups:\n  - name: curve\n    rules:\n      # High error rate\n      - alert: CurveHighErrorRate\n        expr: |\n          rate(curve_events_failed_total[5m]) /\n          rate(curve_events_published_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event publishing error rate\"\n          description: \"Error rate is {{ $value | humanizePercentage }} over last 5 minutes\"\n\n      # Circuit breaker open\n      - alert: CurveCircuitBreakerOpen\n        expr: curve_circuit_state == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Curve circuit breaker is OPEN\"\n          description: \"Event publishing circuit breaker has opened due to failures\"\n\n      # Outbox queue growing\n      - alert: CurveOutboxQueueGrowing\n        expr: curve_outbox_pending &gt; 1000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Outbox queue is growing\"\n          description: \"{{ $value }} events pending in outbox\"\n\n      # High latency\n      - alert: CurveHighLatency\n        expr: |\n          histogram_quantile(0.99, rate(curve_events_publish_duration_seconds_bucket[5m])) &gt; 1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event publishing latency\"\n          description: \"p99 latency is {{ $value }}s\"\n\n      # No events published\n      - alert: CurveNoEventsPublished\n        expr: |\n          increase(curve_events_published_total[15m]) == 0\n          and increase(curve_events_failed_total[15m]) == 0\n        for: 15m\n        labels:\n          severity: info\n        annotations:\n          summary: \"No events published\"\n          description: \"No events have been published in the last 15 minutes\"\n\n      # DLQ spike\n      - alert: CurveDLQSpike\n        expr: increase(curve_events_dlq_total[1h]) &gt; 100\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High number of DLQ events\"\n          description: \"{{ $value }} events sent to DLQ in the last hour\"\n</code></pre>"},{"location":"MONITORING/#slack-alert-example","title":"Slack Alert Example","text":"<p>Configure Alertmanager for Slack: <pre><code>receivers:\n  - name: 'curve-alerts'\n    slack_configs:\n      - channel: '#alerts'\n        send_resolved: true\n        title: '{{ .Status | toUpper }}: {{ .CommonAnnotations.summary }}'\n        text: '{{ .CommonAnnotations.description }}'\n</code></pre></p>"},{"location":"MONITORING/#log-monitoring","title":"Log Monitoring","text":""},{"location":"MONITORING/#important-log-patterns","title":"Important Log Patterns","text":"<p>Event Published Successfully: <pre><code>INFO  c.p.c.k.producer.KafkaEventProducer - Event published: id=1234567890, topic=event.audit.v1\n</code></pre></p> <p>Event Failed: <pre><code>ERROR c.p.c.k.producer.KafkaEventProducer - Failed to publish event: id=1234567890, error=Connection refused\n</code></pre></p> <p>DLQ Event: <pre><code>WARN  c.p.c.k.producer.KafkaEventProducer - Event sent to DLQ: id=1234567890, originalError=Timeout\n</code></pre></p> <p>Circuit Breaker State Change: <pre><code>WARN  c.p.c.s.outbox.publisher.OutboxEventPublisher - Circuit breaker state changed: CLOSED -&gt; OPEN\n</code></pre></p>"},{"location":"MONITORING/#elk-stack-integration","title":"ELK Stack Integration","text":"<p>Logstash Filter: <pre><code>filter {\n  if [logger_name] =~ /curve/ {\n    grok {\n      match =&gt; {\n        \"message\" =&gt; \"Event %{WORD:event_action}: id=%{NUMBER:event_id}\"\n      }\n    }\n    if [event_action] == \"published\" {\n      mutate { add_tag =&gt; [\"curve_success\"] }\n    } else if [event_action] == \"failed\" {\n      mutate { add_tag =&gt; [\"curve_failure\"] }\n    }\n  }\n}\n</code></pre></p> <p>Kibana Saved Searches:</p> <ol> <li> <p>Failed Events: <pre><code>logger_name:*curve* AND level:ERROR\n</code></pre></p> </li> <li> <p>DLQ Events: <pre><code>message:\"sent to DLQ\"\n</code></pre></p> </li> <li> <p>Circuit Breaker Events: <pre><code>message:\"Circuit breaker\"\n</code></pre></p> </li> </ol>"},{"location":"MONITORING/#structured-logging","title":"Structured Logging","text":"<p>Enable JSON logging for better parsing:</p> <pre><code>logging:\n  pattern:\n    console: '{\"timestamp\":\"%d\",\"level\":\"%level\",\"logger\":\"%logger\",\"message\":\"%msg\"}%n'\n</code></pre> <p>Or use Logback with JSON encoder: <pre><code>&lt;appender name=\"JSON\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;\n    &lt;encoder class=\"net.logstash.logback.encoder.LogstashEncoder\"/&gt;\n&lt;/appender&gt;\n</code></pre></p>"},{"location":"MONITORING/#quick-reference","title":"Quick Reference","text":""},{"location":"MONITORING/#endpoints","title":"Endpoints","text":"Endpoint Description <code>/actuator/health/curve</code> Curve health status <code>/actuator/curve-metrics</code> Curve-specific metrics <code>/actuator/prometheus</code> Prometheus metrics"},{"location":"MONITORING/#key-metrics-to-watch","title":"Key Metrics to Watch","text":"Metric Normal Warning Critical Error Rate &lt; 1% 1-5% &gt; 5% Latency (p99) &lt; 100ms 100-500ms &gt; 500ms Outbox Queue &lt; 100 100-1000 &gt; 1000 Circuit State CLOSED HALF-OPEN OPEN"},{"location":"MONITORING/#emergency-commands","title":"Emergency Commands","text":"<pre><code># Check Kafka connectivity\nnc -zv kafka-host 9092\n\n# View recent DLQ events\nkafka-console-consumer --bootstrap-server localhost:9092 \\\n  --topic event.audit.dlq.v1 --from-beginning --max-messages 10\n\n# Check outbox table\npsql -c \"SELECT status, COUNT(*) FROM curve_outbox_events GROUP BY status;\"\n\n# Force close circuit breaker (if supported)\ncurl -X POST http://localhost:8080/actuator/curve/circuit-breaker/reset\n</code></pre>"},{"location":"OPERATIONS/","title":"Curve Operations Guide","text":"<p>This document describes operational procedures for monitoring, troubleshooting, and recovery in the Curve event publishing system.</p>"},{"location":"OPERATIONS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>DLQ Monitoring</li> <li>Metrics Interpretation</li> <li>Troubleshooting Matrix</li> <li>Recovery Procedures</li> <li>Alert Configuration</li> <li>Runbook Checklist</li> </ul>"},{"location":"OPERATIONS/#dlq-monitoring","title":"DLQ Monitoring","text":""},{"location":"OPERATIONS/#understanding-the-3-tier-failure-recovery","title":"Understanding the 3-Tier Failure Recovery","text":"<p>Curve implements a 3-tier failure recovery system to prevent event loss:</p> <pre><code>Event Send Attempt\n        \u2502\n        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 1: Main   \u2502\u2500\u2500\u2500\u2500 Success \u2500\u2500\u2500\u25b6 Event Published\n\u2502     Topic       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 Failure\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 2: DLQ    \u2502\u2500\u2500\u2500\u2500 Success \u2500\u2500\u2500\u25b6 Event in DLQ Topic\n\u2502     Topic       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 Failure\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Tier 3: Local   \u2502\u2500\u2500\u2500\u2500 Success \u2500\u2500\u2500\u25b6 JSON File Backup\n\u2502     Backup      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 Failure\n         \u25bc\n    Event Lost + Alert\n</code></pre> Tier Component Trigger Description 1 Main Topic Normal operation Events published to configured Kafka topic 2 DLQ Topic Main topic failure Failed events sent to Dead Letter Queue 3 Local File DLQ failure Events backed up to <code>./dlq-backup/</code> directory"},{"location":"OPERATIONS/#monitoring-dlq-events","title":"Monitoring DLQ Events","text":""},{"location":"OPERATIONS/#via-kafka-ui","title":"Via Kafka UI","text":"<ol> <li>Navigate to Kafka UI (default: http://localhost:8080)</li> <li>Select Topics from the menu</li> <li>Find <code>event.audit.dlq.v1</code> (or your configured DLQ topic)</li> <li>View Messages tab for failed events</li> </ol>"},{"location":"OPERATIONS/#via-actuator-endpoint","title":"Via Actuator Endpoint","text":"<pre><code># Get DLQ metrics\ncurl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n</code></pre> <p>Response: <pre><code>{\n  \"totalEventsPublished\": 1523,\n  \"successfulEvents\": 1520,\n  \"failedEvents\": 3,\n  \"successRate\": \"99.80%\",\n  \"totalDlqEvents\": 3,\n  \"totalKafkaErrors\": 0\n}\n</code></pre></p>"},{"location":"OPERATIONS/#via-kafka-cli","title":"Via Kafka CLI","text":"<pre><code># Count messages in DLQ topic\nkafka-run-class.sh kafka.tools.GetOffsetShell \\\n  --broker-list localhost:9092 \\\n  --topic event.audit.dlq.v1\n\n# Consume DLQ messages\nkafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic event.audit.dlq.v1 \\\n  --from-beginning\n</code></pre>"},{"location":"OPERATIONS/#dlq-message-structure","title":"DLQ Message Structure","text":"<pre><code>{\n  \"eventId\": \"123456789012345678\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"originalPayload\": \"{\\\"eventType\\\":\\\"ORDER_CREATED\\\",...}\",\n  \"exceptionType\": \"org.apache.kafka.common.errors.TimeoutException\",\n  \"exceptionMessage\": \"Failed to send message after 3 retries\",\n  \"failedAt\": 1704067200000\n}\n</code></pre> Field Description <code>eventId</code> Unique event identifier (Snowflake ID) <code>originalTopic</code> Topic where the event was supposed to be sent <code>originalPayload</code> Complete event payload as JSON string <code>exceptionType</code> Java exception class that caused the failure <code>exceptionMessage</code> Human-readable error message <code>failedAt</code> Timestamp (epoch milliseconds) when failure occurred"},{"location":"OPERATIONS/#local-backup-files","title":"Local Backup Files","text":"<p>Location: <code>./dlq-backup/</code> (configurable via <code>curve.kafka.dlq-backup-path</code>)</p> <pre><code># List backup files\nls -la ./dlq-backup/\n\n# Example output:\n# -rw------- 1 user user 2048 Jan 20 10:30 123456789012345678.json\n# -rw------- 1 user user 1856 Jan 20 10:31 123456789012345679.json\n</code></pre> <p>File naming: <code>{eventId}.json</code></p> <p>File permissions: - POSIX systems: <code>600</code> (rw-------) - Windows: ACL restricted to owner only</p>"},{"location":"OPERATIONS/#metrics-interpretation","title":"Metrics Interpretation","text":""},{"location":"OPERATIONS/#accessing-metrics","title":"Accessing Metrics","text":"<pre><code># Full metrics report\ncurl http://localhost:8081/actuator/curve-metrics\n\n# Summary only\ncurl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n\n# Specific metric\ncurl http://localhost:8081/actuator/curve-metrics | jq '.events.published'\n</code></pre>"},{"location":"OPERATIONS/#key-metrics-reference","title":"Key Metrics Reference","text":"Metric Description Warning Threshold Critical Threshold <code>successRate</code> Event publishing success percentage &lt; 99% &lt; 95% <code>totalDlqEvents</code> Events sent to DLQ &gt; 0 &gt; 10 (increasing) <code>totalKafkaErrors</code> Kafka producer errors &gt; 0 &gt; 5 <code>curve.events.retry.count</code> Retry attempts Increasing Rapidly increasing <code>curve.events.publish.duration</code> Publishing latency &gt; 100ms avg &gt; 500ms avg"},{"location":"OPERATIONS/#health-status-interpretation","title":"Health Status Interpretation","text":"Status Indicators Meaning Action Healthy successRate &gt;= 99.5%, totalDlqEvents = 0 Normal operation Monitor Warning successRate 95-99.5%, totalDlqEvents &gt; 0 stable Intermittent issues Investigate Critical successRate &lt; 95%, totalDlqEvents increasing System failure Immediate action"},{"location":"OPERATIONS/#outbox-publisher-metrics","title":"Outbox Publisher Metrics","text":"<p>For Transactional Outbox Pattern users:</p> Metric Description Action if Abnormal <code>circuitBreakerState</code> CLOSED/OPEN/HALF-OPEN OPEN = Kafka connectivity issue <code>consecutiveFailures</code> Consecutive failure count &gt; 3 = circuit breaker may open <code>timeSinceLastSuccessMs</code> Time since last success &gt; 60000 = check Kafka <code>totalPending</code> Pending outbox events Should trend toward 0 <code>totalFailed</code> Permanently failed events Requires manual intervention"},{"location":"OPERATIONS/#circuit-breaker-states","title":"Circuit Breaker States","text":"State Behavior Duration Transition CLOSED Normal operation - Opens after 5 consecutive failures OPEN All requests blocked 60 seconds Transitions to HALF-OPEN HALF-OPEN Allows test requests Until success/failure Success\u2192CLOSED, Failure\u2192OPEN"},{"location":"OPERATIONS/#troubleshooting-matrix","title":"Troubleshooting Matrix","text":""},{"location":"OPERATIONS/#symptoms-and-solutions","title":"Symptoms and Solutions","text":"Symptom Possible Cause Verification Solution Events not published AOP disabled Check <code>curve.aop.enabled</code> in config Set to <code>true</code> Events not published Method not public Review method signature Make method <code>public</code> <code>TimeoutException</code> Kafka unresponsive <code>docker-compose ps kafka</code> Restart Kafka <code>TimeoutException</code> Network latency Ping broker Increase <code>request-timeout-ms</code> High DLQ count Kafka broker down Check broker logs Restore Kafka, recover DLQ Circuit breaker OPEN 5+ consecutive failures Check Kafka health Wait 60s or fix Kafka Local backup files exist Both main and DLQ failed Check all Kafka connectivity Manual recovery required PII encryption error Missing encryption key Check <code>PII_ENCRYPTION_KEY</code> env Set environment variable Worker ID conflict Duplicate worker IDs Check instance configurations Assign unique IDs Outbox events stuck PENDING Kafka unreachable Check circuit breaker state Fix Kafka connectivity Slow event publishing Sync mode under high load Check <code>async-mode</code> Enable async mode <code>ClockMovedBackwardsException</code> System time changed Check NTP sync Restart application"},{"location":"OPERATIONS/#common-error-messages","title":"Common Error Messages","text":"Error Message Cause Solution <code>Kafka topic is required</code> Missing topic configuration Set <code>curve.kafka.topic</code> <code>workerId must be between 0 and 1023</code> Invalid worker ID Use valid range <code>PII encryption key is not configured</code> Missing encryption key Set <code>PII_ENCRYPTION_KEY</code> env var <code>Failed to send message after N retries</code> Kafka connectivity issue Check broker status <code>Circuit breaker is OPEN</code> Too many consecutive failures Wait for half-open or fix Kafka"},{"location":"OPERATIONS/#health-check-responses","title":"Health Check Responses","text":"<pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre> Status Details Meaning Action UP <code>clusterId</code>, <code>nodeCount</code> present Healthy, broker connected None DOWN error message Broker unreachable or connectivity issue Check Kafka configuration and network"},{"location":"OPERATIONS/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"OPERATIONS/#procedure-1-dlq-event-recovery","title":"Procedure 1: DLQ Event Recovery","text":"<p>When to use: Events accumulated in DLQ topic after temporary Kafka issues have been resolved.</p> <p>Prerequisites: - Kafka is now healthy - <code>kafka-console-producer.sh</code> available in PATH - Access to DLQ topic</p> <p>Steps:</p> <ol> <li> <p>Verify Kafka is healthy: <pre><code># Check Kafka container\ndocker-compose ps kafka\n\n# Check Curve health\ncurl http://localhost:8081/actuator/health/curve\n</code></pre></p> </li> <li> <p>List DLQ events to recover: <pre><code>./scripts/dlq-recovery.sh --list\n</code></pre></p> </li> <li> <p>Execute recovery: <pre><code>./scripts/dlq-recovery.sh \\\n  --topic event.audit.v1 \\\n  --broker localhost:9092 \\\n  --dir ./dlq-backup\n</code></pre></p> </li> <li> <p>Recover specific file: <pre><code>./scripts/dlq-recovery.sh \\\n  --file 123456789012345678.json \\\n  --topic event.audit.v1 \\\n  --broker localhost:9092\n</code></pre></p> </li> <li> <p>Verify recovery:</p> </li> <li>Check Kafka UI for recovered events</li> <li>Verify backup files are processed (moved to <code>recovered/</code> subdirectory)</li> </ol>"},{"location":"OPERATIONS/#procedure-2-local-backup-file-recovery","title":"Procedure 2: Local Backup File Recovery","text":"<p>When to use: Both main topic and DLQ failed, events backed up to local files.</p> <p>Steps:</p> <ol> <li> <p>List backup files: <pre><code>ls -la ./dlq-backup/*.json\n</code></pre></p> </li> <li> <p>Validate JSON format: <pre><code># Check all files\nfor f in ./dlq-backup/*.json; do\n  jq empty \"$f\" 2&gt;/dev/null || echo \"Invalid: $f\"\ndone\n</code></pre></p> </li> <li> <p>Use recovery script: <pre><code>./scripts/dlq-recovery.sh \\\n  --dir ./dlq-backup \\\n  --topic event.audit.v1 \\\n  --broker localhost:9092\n</code></pre></p> </li> <li> <p>Manual recovery (if script fails): <pre><code># For each backup file\nEVENT_ID=\"123456789012345678\"\n\ncat ./dlq-backup/${EVENT_ID}.json | \\\n  kafka-console-producer.sh \\\n  --broker-list localhost:9092 \\\n  --topic event.audit.v1\n</code></pre></p> </li> <li> <p>Archive recovered files: <pre><code>mkdir -p ./dlq-backup/recovered\nmv ./dlq-backup/*.json ./dlq-backup/recovered/\n</code></pre></p> </li> </ol>"},{"location":"OPERATIONS/#procedure-3-outbox-event-recovery","title":"Procedure 3: Outbox Event Recovery","text":"<p>When to use: Outbox events stuck in FAILED status after circuit breaker issues.</p> <p>Steps:</p> <ol> <li> <p>Check outbox statistics: <pre><code>curl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n</code></pre></p> </li> <li> <p>Query failed events (requires database access): <pre><code>-- List failed events\nSELECT id, event_id, aggregate_type, aggregate_id, status, retry_count, last_error\nFROM curve_outbox_event\nWHERE status = 'FAILED'\nORDER BY occurred_at DESC\nLIMIT 100;\n\n-- Count by status\nSELECT status, COUNT(*) as count\nFROM curve_outbox_event\nGROUP BY status;\n</code></pre></p> </li> <li> <p>Reset failed events for retry: <pre><code>-- Reset specific event\nUPDATE curve_outbox_event\nSET status = 'PENDING', retry_count = 0, last_error = NULL, next_retry_at = NOW()\nWHERE id = 'specific-event-id';\n\n-- Reset all failed events (use with caution)\nUPDATE curve_outbox_event\nSET status = 'PENDING', retry_count = 0, last_error = NULL, next_retry_at = NOW()\nWHERE status = 'FAILED';\n</code></pre></p> </li> <li> <p>Monitor recovery: <pre><code>watch -n 5 'curl -s http://localhost:8081/actuator/curve-metrics | jq \".summary\"'\n</code></pre></p> </li> </ol>"},{"location":"OPERATIONS/#procedure-4-circuit-breaker-reset","title":"Procedure 4: Circuit Breaker Reset","text":"<p>When to use: Circuit breaker stuck in OPEN state after Kafka recovery.</p> <p>Steps:</p> <ol> <li> <p>Verify Kafka is healthy: <pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre></p> </li> <li> <p>Check circuit breaker state: <pre><code>curl http://localhost:8081/actuator/curve-metrics | jq '.summary.circuitBreakerState'\n</code></pre></p> </li> <li> <p>Wait for automatic half-open (60 seconds)</p> </li> </ol> <p>The circuit breaker will automatically transition to HALF-OPEN state after 60 seconds, allowing test requests.</p> <ol> <li> <p>Alternative: Restart application: <pre><code># Graceful shutdown\nkill -TERM $(pgrep -f 'your-application')\n\n# Or via actuator (if enabled)\ncurl -X POST http://localhost:8081/actuator/shutdown\n</code></pre></p> </li> <li> <p>Monitor state transition: <pre><code>watch -n 10 'curl -s http://localhost:8081/actuator/curve-metrics | jq \".summary.circuitBreakerState\"'\n</code></pre></p> </li> </ol>"},{"location":"OPERATIONS/#alert-configuration","title":"Alert Configuration","text":""},{"location":"OPERATIONS/#prometheus-alert-rules","title":"Prometheus Alert Rules","text":"<pre><code>groups:\n  - name: curve-alerts\n    rules:\n      # DLQ Events Alert\n      - alert: CurveDlqEventsHigh\n        expr: curve_events_dlq_count_total &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High DLQ event count\"\n          description: \"{{ $value }} events accumulated in DLQ\"\n\n      # Success Rate Alert\n      - alert: CurveSuccessRateLow\n        expr: (curve_events_published_success_total / curve_events_published_total) &lt; 0.95\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Low event publishing success rate\"\n          description: \"Success rate is {{ $value | humanizePercentage }}\"\n\n      # Circuit Breaker Alert\n      - alert: CurveCircuitBreakerOpen\n        expr: curve_circuit_breaker_state == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Circuit breaker is OPEN\"\n          description: \"Outbox publisher circuit breaker is open, events are not being published\"\n\n      # Kafka Producer Down\n      - alert: CurveKafkaProducerDown\n        expr: curve_health_status == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Curve Kafka producer is down\"\n          description: \"Kafka producer failed to initialize or is unhealthy\"\n\n      # High Latency Alert\n      - alert: CurvePublishLatencyHigh\n        expr: histogram_quantile(0.95, curve_events_publish_duration_seconds_bucket) &gt; 0.5\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event publishing latency\"\n          description: \"95th percentile latency is {{ $value }}s\"\n\n      # Outbox Backlog Alert\n      - alert: CurveOutboxBacklogHigh\n        expr: curve_outbox_pending_total &gt; 1000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High outbox backlog\"\n          description: \"{{ $value }} events pending in outbox\"\n</code></pre>"},{"location":"OPERATIONS/#grafana-dashboard-panels","title":"Grafana Dashboard Panels","text":"<p>Recommended panels for Curve monitoring dashboard:</p> <ol> <li>Event Publishing Rate - <code>rate(curve_events_published_total[5m])</code></li> <li>Success Rate Gauge - Current success percentage</li> <li>DLQ Event Count - <code>curve_events_dlq_count_total</code> over time</li> <li>Publishing Latency - <code>histogram_quantile(0.95, curve_events_publish_duration_seconds_bucket)</code></li> <li>Circuit Breaker State - Current state indicator (CLOSED/OPEN/HALF-OPEN)</li> <li>Outbox Queue Depth - <code>curve_outbox_pending_total</code> over time</li> <li>Retry Count - <code>rate(curve_events_retry_count_total[5m])</code></li> <li>Kafka Errors - <code>curve_kafka_producer_errors_total</code> over time</li> </ol>"},{"location":"OPERATIONS/#runbook-checklist","title":"Runbook Checklist","text":""},{"location":"OPERATIONS/#daily-operations","title":"Daily Operations","text":"<ul> <li>[ ] Check <code>/actuator/health/curve</code> status</li> <li>[ ] Review <code>/actuator/curve-metrics</code> summary</li> <li>[ ] Verify DLQ topic is empty or stable</li> <li>[ ] Check for local backup files in <code>./dlq-backup/</code></li> <li>[ ] Review application logs for WARN/ERROR entries</li> </ul>"},{"location":"OPERATIONS/#weekly-operations","title":"Weekly Operations","text":"<ul> <li>[ ] Review DLQ event patterns and root causes</li> <li>[ ] Analyze publishing latency trends</li> <li>[ ] Verify outbox cleanup job ran successfully</li> <li>[ ] Archive old backup files (if any)</li> <li>[ ] Review and rotate logs</li> </ul>"},{"location":"OPERATIONS/#incident-response","title":"Incident Response","text":"<ul> <li>[ ] Identify affected time range</li> <li>[ ] Check circuit breaker state history</li> <li>[ ] Count events in DLQ and local backup</li> <li>[ ] Determine root cause (Kafka, network, configuration)</li> <li>[ ] Execute appropriate recovery procedure</li> <li>[ ] Verify event delivery to consumers</li> <li>[ ] Document incident in post-mortem</li> </ul>"},{"location":"OPERATIONS/#monthly-operations","title":"Monthly Operations","text":"<ul> <li>[ ] Review alert thresholds and adjust if needed</li> <li>[ ] Analyze success rate trends</li> <li>[ ] Capacity planning based on event volume</li> <li>[ ] Review and update this runbook if necessary</li> </ul>"},{"location":"OPERATIONS/#additional-resources","title":"Additional Resources","text":"<ul> <li>Configuration Guide - Detailed configuration options</li> <li>DLQ Recovery Script - Automated recovery tool</li> <li>Sample Application - Working examples</li> <li>README - Project overview and quick start</li> </ul>"},{"location":"PUBLISHING/","title":"Publishing Guide","text":"<p>This guide explains how to publish Curve to Maven Central.</p> <p>Note: As of January 2024, Sonatype has migrated from the old JIRA-based system (issues.sonatype.org) to the new Central Publisher Portal.</p> <p>Important: Central Portal uses new API endpoints: - New URL: <code>https://ossrh-staging-api.central.sonatype.com/service/local/</code> - Old URL (deprecated): <code>https://s01.oss.sonatype.org/service/local/</code> - Central Portal tokens do NOT work with this URL</p>"},{"location":"PUBLISHING/#prerequisites","title":"Prerequisites","text":"<p>Before publishing, you need:</p> <ol> <li>Sonatype Central Portal Account</li> <li>Namespace (Group ID) Verification</li> <li>GPG Key for signing artifacts</li> <li>GitHub Secrets configured</li> </ol>"},{"location":"PUBLISHING/#step-1-create-sonatype-central-portal-account","title":"Step 1: Create Sonatype Central Portal Account","text":""},{"location":"PUBLISHING/#11-sign-up","title":"1.1 Sign Up","text":"<ol> <li>Go to https://central.sonatype.com</li> <li>Click \"Sign In\" (top right)</li> <li>Choose sign-up method:</li> <li>GitHub (recommended - easiest for <code>io.github.*</code> namespace)</li> <li>Google</li> <li>Username/Password</li> </ol>"},{"location":"PUBLISHING/#12-verify-email","title":"1.2 Verify Email","text":"<p>Check your email and verify your account.</p>"},{"location":"PUBLISHING/#step-2-register-namespace-group-id","title":"Step 2: Register Namespace (Group ID)","text":""},{"location":"PUBLISHING/#21-go-to-namespace-registration","title":"2.1 Go to Namespace Registration","text":"<ol> <li>Login to https://central.sonatype.com</li> <li>Click on your profile \u2192 \"View Namespaces\"</li> <li>Click \"Add Namespace\"</li> </ol>"},{"location":"PUBLISHING/#22-register-iogithubcloseup1202","title":"2.2 Register <code>io.github.closeup1202</code>","text":"<ol> <li>Enter namespace: <code>io.github.closeup1202</code></li> <li>Select verification method: GitHub</li> <li>Follow the verification steps:</li> <li>Create a temporary public repository with the specified name</li> <li>Sonatype will verify your GitHub account ownership</li> <li>After verification, you can delete the temporary repository</li> </ol>"},{"location":"PUBLISHING/#23-wait-for-verification","title":"2.3 Wait for Verification","text":"<ul> <li>GitHub-based verification is usually automatic (within minutes)</li> <li>You'll see the namespace status change to \"Verified\"</li> </ul>"},{"location":"PUBLISHING/#step-3-generate-user-token","title":"Step 3: Generate User Token","text":""},{"location":"PUBLISHING/#31-create-token-for-publishing","title":"3.1 Create Token for Publishing","text":"<ol> <li>Login to https://central.sonatype.com</li> <li>Click on your profile \u2192 \"View Account\"</li> <li>Click \"Generate User Token\"</li> <li>Save the generated credentials:</li> <li>Username: (token username)</li> <li>Password: (token password)</li> </ol> <p>Important: Save these credentials securely. You won't be able to see the password again.</p>"},{"location":"PUBLISHING/#step-4-generate-gpg-key","title":"Step 4: Generate GPG Key","text":""},{"location":"PUBLISHING/#41-install-gpg","title":"4.1 Install GPG","text":"<pre><code># macOS\nbrew install gnupg\n\n# Ubuntu/Debian\nsudo apt-get install gnupg\n\n# Windows (PowerShell)\nwinget install GnuPG.GnuPG\n# Or download from https://gpg4win.org/\n</code></pre>"},{"location":"PUBLISHING/#42-generate-key-pair","title":"4.2 Generate Key Pair","text":"<pre><code>gpg --full-generate-key\n</code></pre> <p>Select: - Key type: <code>RSA and RSA</code> - Key size: <code>4096</code> - Expiration: <code>0</code> (does not expire) or your preference - Real name: <code>closeup1202</code> - Email: <code>closeup1202@gmail.com</code> - Passphrase: (remember this!)</p>"},{"location":"PUBLISHING/#43-get-key-id","title":"4.3 Get Key ID","text":"<pre><code>gpg --list-secret-keys --keyid-format LONG\n\n# Output example:\n# sec   rsa4096/ABCDEF1234567890 2024-01-01 [SC]\n#       1234567890ABCDEF1234567890ABCDEF12345678\n# uid                 [ultimate] closeup1202 &lt;closeup1202@gmail.com&gt;\n\n# Key ID: ABCDEF1234567890 (16 characters after rsa4096/)\n# Or short form: last 8 characters\n</code></pre>"},{"location":"PUBLISHING/#44-upload-public-key-to-keyserver","title":"4.4 Upload Public Key to Keyserver","text":"<pre><code>gpg --keyserver keyserver.ubuntu.com --send-keys YOUR_KEY_ID\n\n# Also upload to other keyservers for redundancy\ngpg --keyserver keys.openpgp.org --send-keys YOUR_KEY_ID\n</code></pre>"},{"location":"PUBLISHING/#45-export-private-key-for-github-actions","title":"4.5 Export Private Key for GitHub Actions","text":"<pre><code># Export private key\ngpg --armor --export-secret-keys YOUR_KEY_ID &gt; private-key.asc\n\n# View content (copy this for GitHub Secret)\ncat private-key.asc\n</code></pre>"},{"location":"PUBLISHING/#step-5-configure-github-secrets","title":"Step 5: Configure GitHub Secrets","text":"<p>Go to your repository \u2192 Settings \u2192 Secrets and variables \u2192 Actions</p> <p>Add these secrets:</p> Secret Name Value Description <code>OSSRH_USERNAME</code> Token username from Step 3 Central Portal token username <code>OSSRH_PASSWORD</code> Token password from Step 3 Central Portal token password <code>GPG_KEY_ID</code> <code>ABCDEF1234567890</code> Your GPG key ID <code>GPG_PRIVATE_KEY</code> Content of <code>private-key.asc</code> Entire file including headers <code>GPG_PASSPHRASE</code> Your GPG passphrase The password you set for GPG key"},{"location":"PUBLISHING/#step-6-test-locally-optional","title":"Step 6: Test Locally (Optional)","text":""},{"location":"PUBLISHING/#61-configure-local-credentials","title":"6.1 Configure Local Credentials","text":"<p>Create or edit <code>~/.gradle/gradle.properties</code>:</p> <pre><code>ossrhUsername=your-token-username\nossrhPassword=your-token-password\nsigning.keyId=ABCDEF1234567890\nsigning.password=your-gpg-passphrase\nsigning.secretKeyRingFile=C:/Users/YourName/.gnupg/secring.gpg\n</code></pre>"},{"location":"PUBLISHING/#62-publish-snapshot","title":"6.2 Publish SNAPSHOT","text":"<pre><code>./gradlew publish\n</code></pre> <p>Check your artifacts at: https://central.sonatype.com (Deployments tab)</p>"},{"location":"PUBLISHING/#step-7-release","title":"Step 7: Release","text":""},{"location":"PUBLISHING/#71-update-version","title":"7.1 Update Version","text":"<p>Edit <code>gradle.properties</code>: <pre><code># Change from SNAPSHOT to release version\nversion=0.0.1\n</code></pre></p>"},{"location":"PUBLISHING/#72-commit-and-tag","title":"7.2 Commit and Tag","text":"<pre><code>git add .\ngit commit -m \"Release v0.0.1\"\ngit tag v0.0.1\ngit push origin main --tags\n</code></pre>"},{"location":"PUBLISHING/#73-automatic-release","title":"7.3 Automatic Release","text":"<p>The GitHub Actions workflow will automatically: 1. Build and test 2. Sign artifacts with GPG 3. Publish to Central Portal 4. Create GitHub Release</p>"},{"location":"PUBLISHING/#74-manual-release-via-portal-if-needed","title":"7.4 Manual Release via Portal (if needed)","text":"<ol> <li>Go to https://central.sonatype.com</li> <li>Click \"Deployments\" tab</li> <li>Find your deployment</li> <li>Click \"Publish\" to release to Maven Central</li> </ol>"},{"location":"PUBLISHING/#step-8-verify-publication","title":"Step 8: Verify Publication","text":"<p>After release, your artifacts will be available at:</p> <ul> <li>Maven Central Search: https://search.maven.org/search?q=g:io.github.closeup1202</li> <li>Direct URL: https://repo1.maven.org/maven2/io/github/closeup1202/</li> </ul> <p>Note: It may take 10-30 minutes for artifacts to sync to Maven Central after publishing.</p>"},{"location":"PUBLISHING/#usage-after-publication","title":"Usage After Publication","text":"<p>Users can add your library:</p> <p>Gradle (Kotlin DSL): <pre><code>dependencies {\n    implementation(\"io.github.closeup1202:curve:0.1.2\")\n}\n</code></pre></p> <p>Gradle (Groovy): <pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'\n}\n</code></pre></p> <p>Maven: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.1.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p>"},{"location":"PUBLISHING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"PUBLISHING/#gpg-key-not-found-on-keyserver","title":"GPG Key Not Found on Keyserver","text":"<pre><code># Re-upload to multiple keyservers\ngpg --keyserver keyserver.ubuntu.com --send-keys YOUR_KEY_ID\ngpg --keyserver keys.openpgp.org --send-keys YOUR_KEY_ID\ngpg --keyserver pgp.mit.edu --send-keys YOUR_KEY_ID\n</code></pre>"},{"location":"PUBLISHING/#namespace-verification-failed","title":"Namespace Verification Failed","text":"<ul> <li>Ensure the temporary repository is public</li> <li>Repository name must match exactly what Sonatype specifies</li> <li>Try verification again after a few minutes</li> </ul>"},{"location":"PUBLISHING/#publication-failed","title":"Publication Failed","text":"<p>Check the Deployments tab in Central Portal for specific errors: - Missing POM information - Invalid GPG signatures - Missing Javadoc/Sources JARs</p>"},{"location":"PUBLISHING/#401-unauthorized-error","title":"\"401 Unauthorized\" Error","text":"<ul> <li>Regenerate your User Token in Central Portal</li> <li>Update GitHub Secrets with new credentials</li> </ul>"},{"location":"PUBLISHING/#quick-reference","title":"Quick Reference","text":"Resource URL Central Portal https://central.sonatype.com Maven Central Search https://search.maven.org GPG Keyserver https://keyserver.ubuntu.com Support Email central-support@sonatype.com"},{"location":"PUBLISHING/#summary-checklist","title":"Summary Checklist","text":"<ul> <li>[ ] Create Central Portal account (https://central.sonatype.com)</li> <li>[ ] Register and verify namespace <code>io.github.closeup1202</code></li> <li>[ ] Generate User Token</li> <li>[ ] Generate GPG key and upload to keyserver</li> <li>[ ] Configure GitHub Secrets</li> <li>[ ] Update version in <code>gradle.properties</code></li> <li>[ ] Create git tag and push</li> <li>[ ] Verify publication on Maven Central</li> </ul>"},{"location":"TROUBLESHOOTING/","title":"Troubleshooting Guide","text":"<p>This guide helps you diagnose and resolve common issues with Curve.</p>"},{"location":"TROUBLESHOOTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Event Publishing Issues</li> <li>Kafka Connection Issues</li> <li>Outbox Pattern Issues</li> <li>PII Processing Issues</li> <li>ID Generation Issues</li> <li>Performance Issues</li> <li>Health Check Failures</li> </ul>"},{"location":"TROUBLESHOOTING/#event-publishing-issues","title":"Event Publishing Issues","text":""},{"location":"TROUBLESHOOTING/#events-not-being-published","title":"Events Not Being Published","text":"<p>Symptoms: - <code>@PublishEvent</code> annotated methods execute but no events appear in Kafka - No errors in logs</p> <p>Possible Causes &amp; Solutions:</p> <ol> <li> <p>AOP not enabled <pre><code>curve:\n  aop:\n    enabled: true  # Ensure this is true\n</code></pre></p> </li> <li> <p>Method not proxied (Spring AOP limitation)    <pre><code>// BAD: Internal call bypasses AOP\npublic void methodA() {\n    methodB();  // @PublishEvent on methodB won't trigger\n}\n\n// GOOD: Use self-injection or refactor\n@Autowired\nprivate MyService self;\n\npublic void methodA() {\n    self.methodB();  // AOP will intercept\n}\n</code></pre></p> </li> <li> <p>Exception thrown before event creation</p> </li> <li>Check if method throws exception before returning</li> <li>Events are only published on successful method completion</li> </ol>"},{"location":"TROUBLESHOOTING/#events-published-but-not-in-kafka","title":"Events Published But Not in Kafka","text":"<p>Symptoms: - Logs show event creation but Kafka topic is empty - DLQ topic has events</p> <p>Diagnosis: <pre><code># Check DLQ topic\nkafka-console-consumer --bootstrap-server localhost:9092 \\\n  --topic event.audit.dlq.v1 --from-beginning\n</code></pre></p> <p>Solutions: 1. Check Kafka connectivity (see Kafka Connection Issues) 2. Verify topic exists and has correct permissions 3. Check for serialization errors in logs</p>"},{"location":"TROUBLESHOOTING/#duplicate-events","title":"Duplicate Events","text":"<p>Symptoms: - Same event appears multiple times in Kafka</p> <p>Possible Causes: 1. Retry mechanism triggering    - Normal behavior when initial send fails    - Check <code>curve.retry.max-attempts</code> setting</p> <ol> <li>Application restart during async send</li> <li>Use Outbox pattern for exactly-once semantics    <pre><code>curve:\n  outbox:\n    enabled: true\n</code></pre></li> </ol>"},{"location":"TROUBLESHOOTING/#kafka-connection-issues","title":"Kafka Connection Issues","text":""},{"location":"TROUBLESHOOTING/#connection-refused","title":"Connection Refused","text":"<p>Error: <pre><code>org.apache.kafka.common.errors.TimeoutException:\nFailed to update metadata after 60000 ms\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify Kafka is running <pre><code>docker ps | grep kafka\n# or\nnc -zv localhost 9092\n</code></pre></p> </li> <li> <p>Check bootstrap servers configuration <pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9092  # Correct address?\n</code></pre></p> </li> <li> <p>Network/Firewall issues</p> </li> <li>Ensure port 9092 is accessible</li> <li>Check Docker network configuration</li> </ol>"},{"location":"TROUBLESHOOTING/#ssltls-handshake-failure","title":"SSL/TLS Handshake Failure","text":"<p>Error: <pre><code>javax.net.ssl.SSLHandshakeException: PKIX path building failed\n</code></pre></p> <p>Solutions: <pre><code>spring:\n  kafka:\n    ssl:\n      trust-store-location: classpath:kafka.truststore.jks\n      trust-store-password: ${KAFKA_TRUSTSTORE_PASSWORD}\n    properties:\n      security.protocol: SSL\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#authentication-failure","title":"Authentication Failure","text":"<p>Error: <pre><code>org.apache.kafka.common.errors.SaslAuthenticationException\n</code></pre></p> <p>Solutions: <pre><code>spring:\n  kafka:\n    properties:\n      security.protocol: SASL_SSL\n      sasl.mechanism: PLAIN\n      sasl.jaas.config: &gt;\n        org.apache.kafka.common.security.plain.PlainLoginModule required\n        username=\"${KAFKA_USERNAME}\"\n        password=\"${KAFKA_PASSWORD}\";\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#outbox-pattern-issues","title":"Outbox Pattern Issues","text":""},{"location":"TROUBLESHOOTING/#events-stuck-in-pending-status","title":"Events Stuck in PENDING Status","text":"<p>Symptoms: - Events in outbox table remain in PENDING status - No events being published to Kafka</p> <p>Diagnosis: <pre><code>SELECT status, COUNT(*) FROM curve_outbox_events\nGROUP BY status;\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Publisher not enabled <pre><code>curve:\n  outbox:\n    enabled: true\n    publisher-enabled: true  # Must be true\n</code></pre></p> </li> <li> <p>Circuit breaker is open</p> </li> <li>Check logs for: <code>Circuit breaker is OPEN</code></li> <li> <p>Wait for recovery or fix Kafka connection    <pre><code>-- Check failed events\nSELECT * FROM curve_outbox_events\nWHERE status = 'PENDING' AND retry_count &gt; 0;\n</code></pre></p> </li> <li> <p>Database lock contention</p> </li> <li>Reduce batch size    <pre><code>curve:\n  outbox:\n    batch-size: 50  # Reduce from default 100\n</code></pre></li> </ol>"},{"location":"TROUBLESHOOTING/#outbox-table-not-created","title":"Outbox Table Not Created","text":"<p>Error: <pre><code>Table 'curve_outbox_events' doesn't exist\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Set initialization mode <pre><code>curve:\n  outbox:\n    initialize-schema: always  # Create if not exists\n</code></pre></p> </li> <li> <p>Create manually with migration tool <pre><code>CREATE TABLE curve_outbox_events (\n    id VARCHAR(36) PRIMARY KEY,\n    event_type VARCHAR(255) NOT NULL,\n    payload TEXT NOT NULL,\n    status VARCHAR(20) NOT NULL DEFAULT 'PENDING',\n    retry_count INT NOT NULL DEFAULT 0,\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    published_at TIMESTAMP,\n    error_message TEXT,\n    INDEX idx_status_created (status, created_at)\n);\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#events-processed-multiple-times","title":"Events Processed Multiple Times","text":"<p>Symptoms: - Duplicate processing after restart - Events published more than once</p> <p>Cause: Multiple publisher instances running</p> <p>Solutions: 1. Use distributed lock (recommended for clustered environments) 2. Disable publisher on some instances <pre><code># On secondary instances\ncurve:\n  outbox:\n    publisher-enabled: false  # Let CDC handle publishing\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#pii-processing-issues","title":"PII Processing Issues","text":""},{"location":"TROUBLESHOOTING/#pii-fields-not-masked","title":"PII Fields Not Masked","text":"<p>Symptoms: - Sensitive data appears in plain text in events</p> <p>Possible Causes:</p> <ol> <li> <p>Missing <code>@PiiField</code> annotation <pre><code>public class UserPayload {\n    @PiiField(type = PiiType.EMAIL)  // Required!\n    private String email;\n}\n</code></pre></p> </li> <li> <p>PII processor not configured <pre><code>curve:\n  pii:\n    enabled: true\n</code></pre></p> </li> <li> <p>Field is null or empty</p> </li> <li>Null/empty fields are not processed</li> </ol>"},{"location":"TROUBLESHOOTING/#encryption-key-not-found","title":"Encryption Key Not Found","text":"<p>Error: <pre><code>PiiEncryptionException: Encryption key not configured\n</code></pre></p> <p>Solution: <pre><code># Set environment variable (Base64-encoded 32-byte key)\nexport CURVE_PII_ENCRYPTION_KEY=$(openssl rand -base64 32)\n</code></pre></p> <p>Generate a key: <pre><code>SecureRandom random = new SecureRandom();\nbyte[] key = new byte[32];  // Must be exactly 32 bytes for AES-256\nrandom.nextBytes(key);\nString base64Key = Base64.getEncoder().encodeToString(key);\n</code></pre></p> <p>Note: The key must be exactly 32 bytes (Base64-encoded). Keys of incorrect length will be rejected at startup.</p>"},{"location":"TROUBLESHOOTING/#decryption-failure","title":"Decryption Failure","text":"<p>Error: <pre><code>javax.crypto.AEADBadTagException: Tag mismatch!\n</code></pre></p> <p>Possible Causes: 1. Wrong encryption key 2. Corrupted encrypted data 3. Key rotation without re-encryption</p> <p>Solution: Verify key consistency across environments</p>"},{"location":"TROUBLESHOOTING/#id-generation-issues","title":"ID Generation Issues","text":""},{"location":"TROUBLESHOOTING/#duplicate-ids-generated","title":"Duplicate IDs Generated","text":"<p>Symptoms: - <code>DuplicateKeyException</code> or constraint violations - Same ID appearing for different events</p> <p>Cause: Multiple instances using same worker ID</p> <p>Solutions:</p> <ol> <li> <p>Assign unique worker IDs <pre><code># Instance 1\ncurve:\n  id-generator:\n    worker-id: 1\n\n# Instance 2\ncurve:\n  id-generator:\n    worker-id: 2\n</code></pre></p> </li> <li> <p>Use environment-based configuration <pre><code>curve:\n  id-generator:\n    worker-id: ${WORKER_ID:1}\n</code></pre></p> </li> <li> <p>Kubernetes StatefulSet <pre><code>curve:\n  id-generator:\n    worker-id: ${POD_ORDINAL:1}\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#worker-id-out-of-range","title":"Worker ID Out of Range","text":"<p>Error: <pre><code>IllegalArgumentException: Worker ID must be between 0 and 1023\n</code></pre></p> <p>Solution: Ensure worker ID is in valid range (0-1023)</p>"},{"location":"TROUBLESHOOTING/#clock-moved-backwards","title":"Clock Moved Backwards","text":"<p>Error: <pre><code>ClockMovedBackwardsException: Clock moved backwards\n</code></pre></p> <p>Cause: System clock adjustment (NTP sync, VM migration)</p> <p>Solutions: 1. Use NTP with slew mode instead of step mode 2. Implement clock skew tolerance (built-in: 5ms) 3. Restart application if clock difference is large</p>"},{"location":"TROUBLESHOOTING/#performance-issues","title":"Performance Issues","text":""},{"location":"TROUBLESHOOTING/#high-latency-in-event-publishing","title":"High Latency in Event Publishing","text":"<p>Diagnosis: <pre><code># Check metrics endpoint\ncurl http://localhost:8080/actuator/curve-metrics\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Enable async mode <pre><code>curve:\n  kafka:\n    async-mode: true\n    async-timeout-ms: 5000\n</code></pre></p> </li> <li> <p>Tune Kafka producer <pre><code>spring:\n  kafka:\n    producer:\n      batch-size: 16384\n      linger-ms: 5\n      buffer-memory: 33554432\n</code></pre></p> </li> <li> <p>Reduce retry attempts <pre><code>curve:\n  retry:\n    max-attempts: 2\n    initial-interval: 500\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#memory-issues-with-large-events","title":"Memory Issues with Large Events","text":"<p>Symptoms: - OutOfMemoryError - GC pressure</p> <p>Solutions: 1. Limit payload size 2. Use compression    <pre><code>spring:\n  kafka:\n    producer:\n      compression-type: lz4\n</code></pre> 3. Stream large data separately, reference by ID in events</p>"},{"location":"TROUBLESHOOTING/#outbox-table-growing-too-large","title":"Outbox Table Growing Too Large","text":"<p>Diagnosis: <pre><code>SELECT COUNT(*) FROM curve_outbox_events;\nSELECT status, COUNT(*) FROM curve_outbox_events GROUP BY status;\n</code></pre></p> <p>Solutions: <pre><code>curve:\n  outbox:\n    cleanup-enabled: true\n    retention-days: 3        # Reduce retention\n    cleanup-cron: \"0 0 * * * *\"  # Run every hour\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#health-check-failures","title":"Health Check Failures","text":""},{"location":"TROUBLESHOOTING/#curve-health-indicator-down","title":"Curve Health Indicator DOWN","text":"<p>Check health endpoint: <pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre></p> <p>Possible causes: 1. Kafka connection lost 2. Outbox publisher stopped 3. Too many failed events</p> <p>Diagnosis: <pre><code># Full health details\ncurl http://localhost:8080/actuator/health/curve | jq\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#actuator-endpoint-not-available","title":"Actuator Endpoint Not Available","text":"<p>Error: 404 on <code>/actuator/curve-metrics</code></p> <p>Solution: <pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,curve-metrics\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#getting-help","title":"Getting Help","text":"<p>If you can't resolve your issue:</p> <ol> <li> <p>Check logs with DEBUG level:    <pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n</code></pre></p> </li> <li> <p>Gather diagnostics:</p> </li> <li>Application logs</li> <li>Health endpoint output</li> <li>Metrics endpoint output</li> <li> <p>Kafka topic state</p> </li> <li> <p>Open an issue at https://github.com/closeup1202/curve/issues with:</p> </li> <li>Curve version</li> <li>Spring Boot version</li> <li>Java version</li> <li>Configuration (sanitized)</li> <li>Error messages and stack traces</li> <li>Steps to reproduce</li> </ol>"},{"location":"api/annotations/","title":"Annotation Reference","text":"<p>Complete reference for all Curve annotations.</p>"},{"location":"api/annotations/#publishevent","title":"@PublishEvent","text":"<p>Marks a method to automatically publish events after execution.</p>"},{"location":"api/annotations/#package","title":"Package","text":"<pre><code>io.github.closeup1202.curve.spring.audit.annotation.PublishEvent\n</code></pre>"},{"location":"api/annotations/#parameters","title":"Parameters","text":"Parameter Type Required Default Description <code>eventType</code> String No \"\" Unique event type identifier (auto-generated from method name if empty) <code>severity</code> EventSeverity No INFO Event severity level <code>payloadIndex</code> int No -1 Parameter index for payload (-1: use return value, 0+: use parameter) <code>payload</code> String (SpEL) No \"\" Payload extraction SpEL expression (overrides payloadIndex) <code>phase</code> Phase No AFTER_RETURNING When to publish (BEFORE, AFTER_RETURNING, AFTER) <code>failOnError</code> boolean No false Throw exception if event publishing fails <code>outbox</code> boolean No false Enable transactional outbox pattern <code>aggregateType</code> String No \"\" Entity type for outbox (required if outbox=true) <code>aggregateId</code> String (SpEL) No \"\" Entity ID SpEL expression for outbox (required if outbox=true)"},{"location":"api/annotations/#example","title":"Example","text":"<pre><code>@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    severity = EventSeverity.INFO,\n    payload = \"#result.toDto()\",\n    phase = PublishEvent.Phase.AFTER_RETURNING,\n    failOnError = false,\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre>"},{"location":"api/annotations/#phase-options","title":"Phase Options","text":"<pre><code>public enum Phase {\n    BEFORE,          // Publish before method execution\n    AFTER_RETURNING, // Publish after successful execution (default)\n    AFTER            // Publish after execution (even if method throws exception)\n}\n</code></pre>"},{"location":"api/annotations/#payload-extraction-examples","title":"Payload Extraction Examples","text":"<pre><code>// Use return value (default when payloadIndex=-1 and payload=\"\")\n@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest req) { ... }\n\n// Use specific parameter by index\n@PublishEvent(\n    eventType = \"ORDER_SUBMITTED\",\n    payloadIndex = 0  // Use first parameter\n)\npublic Order submitOrder(OrderSubmission submission) { ... }\n\n// Use SpEL expression (overrides payloadIndex)\n@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#args[0].toEventDto()\"\n)\npublic User updateUser(UserUpdateRequest request) { ... }\n\n// SpEL with return value method call\n@PublishEvent(\n    eventType = \"ORDER_COMPLETED\",\n    payload = \"#result.toCompletedDto()\"\n)\npublic Order completeOrder(String reason) { ... }\n</code></pre>"},{"location":"api/annotations/#piifield","title":"@PiiField","text":"<p>Marks a field for automatic PII protection.</p>"},{"location":"api/annotations/#package_1","title":"Package","text":"<pre><code>io.github.closeup1202.curve.spring.pii.annotation.PiiField\n</code></pre>"},{"location":"api/annotations/#parameters_1","title":"Parameters","text":"Parameter Type Required Default Description <code>type</code> PiiType Yes - Type of PII data <code>strategy</code> PiiStrategy Yes - Protection strategy <code>condition</code> String (SpEL) No \"\" Conditional protection"},{"location":"api/annotations/#piitype-values","title":"PiiType Values","text":"<ul> <li><code>EMAIL</code> - Email addresses</li> <li><code>PHONE</code> - Phone numbers</li> <li><code>SSN</code> - Social Security Numbers</li> <li><code>NAME</code> - Person names</li> <li><code>ADDRESS</code> - Physical addresses</li> <li><code>CREDIT_CARD</code> - Credit card numbers</li> <li><code>IP_ADDRESS</code> - IP addresses</li> <li><code>GENERIC</code> - Custom sensitive data</li> </ul>"},{"location":"api/annotations/#piistrategy-values","title":"PiiStrategy Values","text":"<ul> <li><code>MASK</code> - Pattern-based masking</li> <li><code>ENCRYPT</code> - AES-256-GCM encryption</li> <li><code>HASH</code> - HMAC-SHA256 hashing</li> </ul>"},{"location":"api/annotations/#example_1","title":"Example","text":"<pre><code>public class UserPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;\n}\n</code></pre>"},{"location":"api/annotations/#enums","title":"Enums","text":""},{"location":"api/annotations/#eventseverity","title":"EventSeverity","text":"<pre><code>public enum EventSeverity {\n    INFO,     // Normal operations (default)\n    WARN,     // Warnings\n    ERROR,    // Errors requiring attention\n    CRITICAL  // Critical failures requiring immediate action\n}\n</code></pre>"},{"location":"api/annotations/#spel-context-variables","title":"SpEL Context Variables","text":"<p>Available in SpEL expressions:</p> Variable Description Example <code>#result</code> Method return value <code>#result</code> <code>#args[n]</code> Method arguments (0-indexed) <code>#args[0]</code> <code>#root</code> Root evaluation context <code>#root.methodName</code> <code>#this</code> Current object <code>#this.getId()</code>"},{"location":"api/annotations/#example_2","title":"Example","text":"<pre><code>// Use return value\n@PublishEvent(payload = \"#result\")\n\n// Use method argument\n@PublishEvent(payload = \"#args[0].toDto()\")\n\n// Call method on return value\n@PublishEvent(payload = \"#result.getId()\")\n\n// Call method on parameter\n@PublishEvent(\n    payload = \"#args[0].toPayloadDto()\"\n)\n</code></pre>"},{"location":"api/annotations/#best-practices","title":"Best Practices","text":"<ol> <li>Event Type Naming: Use SCREAMING_SNAKE_CASE (e.g., <code>ORDER_CREATED</code>)</li> <li>Severity Levels: Choose appropriate severity for filtering (INFO, WARN, ERROR, CRITICAL)</li> <li>SpEL Expressions: Keep simple for maintainability</li> <li>PII Protection: Apply to all sensitive fields</li> <li>Phase Selection: Use AFTER_RETURNING for normal cases, BEFORE for pre-validation events</li> <li>Error Handling: Set <code>failOnError=false</code> (default) to prevent business logic failure from event publishing issues</li> <li>Transactional Outbox: Enable for critical events requiring guaranteed delivery</li> </ol>"},{"location":"api/annotations/#see-also","title":"See Also","text":"<ul> <li>Declarative Publishing Guide</li> <li>PII Protection Guide</li> <li>Configuration Properties</li> </ul>"},{"location":"api/custom-implementation/","title":"Custom Implementation","text":"<p>Curve's hexagonal architecture makes it easy to extend and customize.</p>"},{"location":"api/custom-implementation/#custom-event-producer","title":"Custom Event Producer","text":"<p>Implement the <code>EventProducer</code> interface to support non-Kafka brokers.</p>"},{"location":"api/custom-implementation/#example-rabbitmq-producer","title":"Example: RabbitMQ Producer","text":"<pre><code>import io.github.closeup1202.curve.core.port.EventProducer;\nimport io.github.closeup1202.curve.core.envelope.EventEnvelope;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class RabbitMqEventProducer extends AbstractEventPublisher {\n\n    private final RabbitTemplate rabbitTemplate;\n    private final ObjectMapper objectMapper;\n\n    public RabbitMqEventProducer(\n        RabbitTemplate rabbitTemplate,\n        ObjectMapper objectMapper\n    ) {\n        this.rabbitTemplate = rabbitTemplate;\n        this.objectMapper = objectMapper;\n    }\n\n    @Override\n    protected &lt;T extends DomainEventPayload&gt; void send(EventEnvelope&lt;T&gt; envelope) {\n        try {\n            String json = objectMapper.writeValueAsString(envelope);\n            rabbitTemplate.convertAndSend(\n                \"events.exchange\",\n                envelope.getEventType(),\n                json\n            );\n        } catch (Exception e) {\n            throw new EventPublishException(\"Failed to publish to RabbitMQ\", e);\n        }\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#custom-context-provider","title":"Custom Context Provider","text":"<p>Add custom metadata to events.</p>"},{"location":"api/custom-implementation/#example-custom-tag-provider","title":"Example: Custom Tag Provider","text":"<pre><code>import io.github.closeup1202.curve.core.context.ContextProvider;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class FeatureFlagContextProvider implements ContextProvider {\n\n    private final FeatureFlagService featureFlagService;\n\n    @Override\n    public Map&lt;String, String&gt; provide() {\n        return Map.of(\n            \"experiment_id\", featureFlagService.getCurrentExperiment(),\n            \"feature_flags\", featureFlagService.getActiveFlags()\n        );\n    }\n}\n</code></pre> <p>Context providers are automatically discovered and added to event metadata.</p>"},{"location":"api/custom-implementation/#custom-serializer","title":"Custom Serializer","text":"<p>Implement custom serialization logic.</p>"},{"location":"api/custom-implementation/#example-protobuf-serializer","title":"Example: Protobuf Serializer","text":"<pre><code>import io.github.closeup1202.curve.core.serde.EventSerializer;\nimport com.google.protobuf.Message;\n\n@Component\npublic class ProtobufEventSerializer implements EventSerializer {\n\n    @Override\n    public byte[] serialize(EventEnvelope&lt;?&gt; envelope) {\n        EventProto.Event proto = EventProto.Event.newBuilder()\n            .setEventId(envelope.getEventId())\n            .setEventType(envelope.getEventType())\n            .setPayload(serializePayload(envelope.getPayload()))\n            .build();\n\n        return proto.toByteArray();\n    }\n\n    private ByteString serializePayload(DomainEventPayload payload) {\n        // Custom protobuf serialization\n        return ByteString.copyFrom(/* ... */);\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#custom-pii-strategy","title":"Custom PII Strategy","text":"<p>Implement custom PII protection logic.</p>"},{"location":"api/custom-implementation/#example-tokenization-strategy","title":"Example: Tokenization Strategy","text":"<pre><code>import io.github.closeup1202.curve.spring.pii.PiiProcessor;\n\n@Component\npublic class TokenizationPiiProcessor implements PiiProcessor {\n\n    private final TokenVault tokenVault;\n\n    @Override\n    public String process(String value, PiiType type, PiiStrategy strategy) {\n        if (strategy == PiiStrategy.TOKENIZE) {\n            return tokenVault.tokenize(value);\n        }\n        // Delegate to default processor\n        return defaultProcessor.process(value, type, strategy);\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#complete-example-aws-sns-producer","title":"Complete Example: AWS SNS Producer","text":"<pre><code>@Component\n@ConditionalOnProperty(name = \"curve.producer.type\", havingValue = \"sns\")\npublic class SnsEventProducer extends AbstractEventPublisher {\n\n    private final AmazonSNS snsClient;\n    private final ObjectMapper objectMapper;\n\n    @Value(\"${curve.sns.topic-arn}\")\n    private String topicArn;\n\n    public SnsEventProducer(AmazonSNS snsClient, ObjectMapper objectMapper) {\n        this.snsClient = snsClient;\n        this.objectMapper = objectMapper;\n    }\n\n    @Override\n    protected &lt;T extends DomainEventPayload&gt; void send(EventEnvelope&lt;T&gt; envelope) {\n        try {\n            String message = objectMapper.writeValueAsString(envelope);\n\n            PublishRequest request = new PublishRequest()\n                .withTopicArn(topicArn)\n                .withMessage(message)\n                .withMessageAttributes(buildAttributes(envelope));\n\n            snsClient.publish(request);\n\n        } catch (Exception e) {\n            throw new EventPublishException(\"Failed to publish to SNS\", e);\n        }\n    }\n\n    private Map&lt;String, MessageAttributeValue&gt; buildAttributes(EventEnvelope&lt;?&gt; envelope) {\n        return Map.of(\n            \"eventType\", new MessageAttributeValue()\n                .withDataType(\"String\")\n                .withStringValue(envelope.getEventType()),\n            \"severity\", new MessageAttributeValue()\n                .withDataType(\"String\")\n                .withStringValue(envelope.getSeverity().name())\n        );\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#see-also","title":"See Also","text":"<ul> <li>Architecture Overview</li> <li>API Reference</li> </ul>"},{"location":"api/properties/","title":"Configuration Properties","text":"<p>Complete reference for all Curve configuration properties.</p>"},{"location":"api/properties/#core-configuration","title":"Core Configuration","text":""},{"location":"api/properties/#curveenabled","title":"curve.enabled","text":"<p>Enable or disable Curve.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  enabled: true\n</code></pre>"},{"location":"api/properties/#kafka-configuration","title":"Kafka Configuration","text":""},{"location":"api/properties/#curvekafkatopic","title":"curve.kafka.topic","text":"<p>Main Kafka topic for event publishing.</p> <ul> <li>Type: <code>string</code></li> <li>Required: Yes</li> </ul> <pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n</code></pre>"},{"location":"api/properties/#curvekafkadlq-topic","title":"curve.kafka.dlq-topic","text":"<p>Dead Letter Queue topic for failed events.</p> <ul> <li>Type: <code>string</code></li> <li>Required: No</li> </ul> <pre><code>curve:\n  kafka:\n    dlq-topic: event.audit.dlq.v1\n</code></pre>"},{"location":"api/properties/#curvekafkaasync-mode","title":"curve.kafka.async-mode","text":"<p>Enable asynchronous publishing for high throughput.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  kafka:\n    async-mode: true\n</code></pre>"},{"location":"api/properties/#curvekafkaasync-timeout-ms","title":"curve.kafka.async-timeout-ms","text":"<p>Timeout for async publishing (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>5000</code></li> </ul> <pre><code>curve:\n  kafka:\n    async-timeout-ms: 5000\n</code></pre>"},{"location":"api/properties/#curvekafkaretries","title":"curve.kafka.retries","text":"<p>Number of Kafka send retries.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>3</code></li> </ul> <pre><code>curve:\n  kafka:\n    retries: 3\n</code></pre>"},{"location":"api/properties/#curvekafkaretry-backoff-ms","title":"curve.kafka.retry-backoff-ms","text":"<p>Backoff time between retries (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1000</code></li> </ul> <pre><code>curve:\n  kafka:\n    retry-backoff-ms: 1000\n</code></pre>"},{"location":"api/properties/#curvekafkarequest-timeout-ms","title":"curve.kafka.request-timeout-ms","text":"<p>Kafka request timeout (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>30000</code></li> </ul> <pre><code>curve:\n  kafka:\n    request-timeout-ms: 30000\n</code></pre>"},{"location":"api/properties/#retry-configuration","title":"Retry Configuration","text":""},{"location":"api/properties/#curveretryenabled","title":"curve.retry.enabled","text":"<p>Enable retry mechanism for failed publishes.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  retry:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curveretrymax-attempts","title":"curve.retry.max-attempts","text":"<p>Maximum retry attempts.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>3</code></li> </ul> <pre><code>curve:\n  retry:\n    max-attempts: 3\n</code></pre>"},{"location":"api/properties/#curveretryinitial-interval","title":"curve.retry.initial-interval","text":"<p>Initial retry interval (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1000</code></li> </ul> <pre><code>curve:\n  retry:\n    initial-interval: 1000\n</code></pre>"},{"location":"api/properties/#curveretrymultiplier","title":"curve.retry.multiplier","text":"<p>Retry backoff multiplier.</p> <ul> <li>Type: <code>double</code></li> <li>Default: <code>2.0</code></li> </ul> <pre><code>curve:\n  retry:\n    multiplier: 2.0\n</code></pre>"},{"location":"api/properties/#curveretrymax-interval","title":"curve.retry.max-interval","text":"<p>Maximum retry interval (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>10000</code></li> </ul> <pre><code>curve:\n  retry:\n    max-interval: 10000\n</code></pre>"},{"location":"api/properties/#pii-configuration","title":"PII Configuration","text":""},{"location":"api/properties/#curvepiienabled","title":"curve.pii.enabled","text":"<p>Enable PII protection.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  pii:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curvepiicryptodefault-key","title":"curve.pii.crypto.default-key","text":"<p>Encryption key for PII (Base64-encoded 32-byte key).</p> <ul> <li>Type: <code>string</code></li> <li>Required: For ENCRYPT strategy</li> </ul> <pre><code>curve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n</code></pre>"},{"location":"api/properties/#curvepiicryptosalt","title":"curve.pii.crypto.salt","text":"<p>Salt for hashing PII.</p> <ul> <li>Type: <code>string</code></li> <li>Required: For HASH strategy</li> </ul> <pre><code>curve:\n  pii:\n    crypto:\n      salt: ${PII_HASH_SALT}\n</code></pre>"},{"location":"api/properties/#outbox-configuration","title":"Outbox Configuration","text":""},{"location":"api/properties/#curveoutboxenabled","title":"curve.outbox.enabled","text":"<p>Enable transactional outbox pattern.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  outbox:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curveoutboxpoll-interval-ms","title":"curve.outbox.poll-interval-ms","text":"<p>Outbox poller interval (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1000</code></li> </ul> <pre><code>curve:\n  outbox:\n    poll-interval-ms: 1000\n</code></pre>"},{"location":"api/properties/#curveoutboxbatch-size","title":"curve.outbox.batch-size","text":"<p>Number of events processed per batch.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>100</code></li> </ul> <pre><code>curve:\n  outbox:\n    batch-size: 100\n</code></pre>"},{"location":"api/properties/#curveoutboxmax-retries","title":"curve.outbox.max-retries","text":"<p>Max retries for failed outbox events.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>3</code></li> </ul> <pre><code>curve:\n  outbox:\n    max-retries: 3\n</code></pre>"},{"location":"api/properties/#curveoutboxcleanup-enabled","title":"curve.outbox.cleanup-enabled","text":"<p>Enable automatic cleanup of old events.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  outbox:\n    cleanup-enabled: true\n</code></pre>"},{"location":"api/properties/#curveoutboxretention-days","title":"curve.outbox.retention-days","text":"<p>Days to retain completed events.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>7</code></li> </ul> <pre><code>curve:\n  outbox:\n    retention-days: 7\n</code></pre>"},{"location":"api/properties/#curveoutboxcleanup-cron","title":"curve.outbox.cleanup-cron","text":"<p>Cron expression for cleanup job.</p> <ul> <li>Type: <code>string</code></li> <li>Default: <code>\"0 0 2 * * *\"</code> (2 AM daily)</li> </ul> <pre><code>curve:\n  outbox:\n    cleanup-cron: \"0 0 2 * * *\"\n</code></pre>"},{"location":"api/properties/#serialization-configuration","title":"Serialization Configuration","text":""},{"location":"api/properties/#curveserdetype","title":"curve.serde.type","text":"<p>Serialization format.</p> <ul> <li>Type: <code>enum</code></li> <li>Values: <code>JSON</code>, <code>AVRO</code>, <code>PROTOBUF</code></li> <li>Default: <code>JSON</code></li> </ul> <pre><code>curve:\n  serde:\n    type: JSON\n</code></pre>"},{"location":"api/properties/#id-generator-configuration","title":"ID Generator Configuration","text":""},{"location":"api/properties/#curveid-generatorworker-id","title":"curve.id-generator.worker-id","text":"<p>Snowflake worker ID (0-1023).</p> <ul> <li>Type: <code>integer</code></li> <li>Range: <code>0-1023</code></li> <li>Default: Auto-generated</li> </ul> <pre><code>curve:\n  id-generator:\n    worker-id: 1\n</code></pre>"},{"location":"api/properties/#curveid-generatorauto-generate","title":"curve.id-generator.auto-generate","text":"<p>Auto-generate worker ID from hostname/IP.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre>"},{"location":"api/properties/#async-executor-configuration","title":"Async Executor Configuration","text":""},{"location":"api/properties/#curveasyncenabled","title":"curve.async.enabled","text":"<p>Enable dedicated async executor bean (<code>curveAsyncExecutor</code>).</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  async:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curveasynccore-pool-size","title":"curve.async.core-pool-size","text":"<p>Core thread pool size for async executor.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>2</code></li> </ul> <pre><code>curve:\n  async:\n    core-pool-size: 4\n</code></pre>"},{"location":"api/properties/#curveasyncmax-pool-size","title":"curve.async.max-pool-size","text":"<p>Maximum thread pool size for async executor.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>10</code></li> </ul> <pre><code>curve:\n  async:\n    max-pool-size: 20\n</code></pre>"},{"location":"api/properties/#curveasyncqueue-capacity","title":"curve.async.queue-capacity","text":"<p>Task queue capacity for async executor.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>500</code></li> </ul> <pre><code>curve:\n  async:\n    queue-capacity: 1000\n</code></pre>"},{"location":"api/properties/#backup-configuration","title":"Backup Configuration","text":""},{"location":"api/properties/#curvekafkabackups3-enabled","title":"curve.kafka.backup.s3-enabled","text":"<p>Enable S3 backup for failed events.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  kafka:\n    backup:\n      s3-enabled: true\n</code></pre>"},{"location":"api/properties/#curvekafkabackups3-bucket","title":"curve.kafka.backup.s3-bucket","text":"<p>S3 bucket name for backup.</p> <ul> <li>Type: <code>string</code></li> <li>Required: When <code>s3-enabled=true</code></li> </ul> <pre><code>curve:\n  kafka:\n    backup:\n      s3-bucket: \"my-event-backup\"\n</code></pre>"},{"location":"api/properties/#curvekafkabackups3-prefix","title":"curve.kafka.backup.s3-prefix","text":"<p>S3 key prefix for backup files.</p> <ul> <li>Type: <code>string</code></li> <li>Default: <code>\"dlq-backup\"</code></li> </ul> <pre><code>curve:\n  kafka:\n    backup:\n      s3-prefix: \"dlq-backup\"\n</code></pre>"},{"location":"api/properties/#curvekafkabackuplocal-enabled","title":"curve.kafka.backup.local-enabled","text":"<p>Enable local file backup.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  kafka:\n    backup:\n      local-enabled: true\n</code></pre>"},{"location":"api/properties/#kafka-additional-properties","title":"Kafka Additional Properties","text":""},{"location":"api/properties/#curvekafkasync-timeout-seconds","title":"curve.kafka.sync-timeout-seconds","text":"<p>Timeout for synchronous send operations (seconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>10</code></li> </ul> <pre><code>curve:\n  kafka:\n    sync-timeout-seconds: 10\n</code></pre>"},{"location":"api/properties/#curvekafkadlq-executor-threads","title":"curve.kafka.dlq-executor-threads","text":"<p>Number of threads for DLQ executor.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1</code></li> </ul> <pre><code>curve:\n  kafka:\n    dlq-executor-threads: 2\n</code></pre>"},{"location":"api/properties/#outbox-additional-properties","title":"Outbox Additional Properties","text":""},{"location":"api/properties/#curveoutboxsend-timeout-seconds","title":"curve.outbox.send-timeout-seconds","text":"<p>Timeout for outbox event send operations (seconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>10</code></li> </ul> <pre><code>curve:\n  outbox:\n    send-timeout-seconds: 10\n</code></pre>"},{"location":"api/properties/#curveoutboxpublisher-enabled","title":"curve.outbox.publisher-enabled","text":"<p>Enable the outbox publisher (polling and sending events).</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  outbox:\n    publisher-enabled: true\n</code></pre>"},{"location":"api/properties/#curveoutboxinitialize-schema","title":"curve.outbox.initialize-schema","text":"<p>Database schema initialization mode.</p> <ul> <li>Type: <code>string</code></li> <li>Values: <code>embedded</code>, <code>always</code>, <code>never</code></li> <li>Default: <code>embedded</code></li> </ul> <pre><code>curve:\n  outbox:\n    initialize-schema: always\n</code></pre>"},{"location":"api/properties/#security-configuration","title":"Security Configuration","text":""},{"location":"api/properties/#curvesecurityuse-forwarded-headers","title":"curve.security.use-forwarded-headers","text":"<p>Use X-Forwarded-* headers for IP extraction.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  security:\n    use-forwarded-headers: true  # When behind proxy\n</code></pre>"},{"location":"api/properties/#complete-example","title":"Complete Example","text":"application.yml<pre><code>spring:\n  application:\n    name: my-service\n  kafka:\n    bootstrap-servers: localhost:9092\n\ncurve:\n  enabled: true\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false\n    async-timeout-ms: 5000\n    retries: 3\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Base64-encoded 32-byte key\n      salt: ${PII_HASH_SALT}\n\n  async:\n    enabled: true\n    core-pool-size: 2\n    max-pool-size: 10\n    queue-capacity: 500\n\n  outbox:\n    enabled: true\n    poll-interval-ms: 1000\n    batch-size: 100\n    max-retries: 3\n    send-timeout-seconds: 10\n    cleanup-enabled: true\n    retention-days: 7\n    cleanup-cron: \"0 0 2 * * *\"\n    initialize-schema: embedded\n\n  serde:\n    type: JSON\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  security:\n    use-forwarded-headers: false\n</code></pre>"},{"location":"api/properties/#environment-specific-profiles","title":"Environment-Specific Profiles","text":"<p>See Configuration Guide for environment-specific examples.</p>"},{"location":"community/contributing/","title":"Contributing to Curve","text":"<p>First off, thanks for taking the time to contribute! \ud83c\udf89</p> <p>The following is a set of guidelines for contributing to Curve. These are mostly guidelines, not rules. Use your best judgment, and feel free to propose changes to this document in a pull request.</p>"},{"location":"community/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project and everyone participating in it is governed by the Code of Conduct. By participating, you are expected to uphold this code.</p>"},{"location":"community/contributing/#how-can-i-contribute","title":"How Can I Contribute?","text":""},{"location":"community/contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>This section guides you through submitting a bug report for Curve. Following these guidelines helps maintainers and the community understand your report, reproduce the behavior, and find related reports.</p> <ul> <li>Use a clear and descriptive title for the issue to identify the problem.</li> <li>Describe the exact steps to reproduce the problem in as many details as possible.</li> <li>Provide specific examples to demonstrate the steps.</li> <li>Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior.</li> <li>Explain which behavior you expected to see instead and why.</li> <li>Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem.</li> </ul>"},{"location":"community/contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>This section guides you through submitting an enhancement suggestion for Curve, including completely new features and minor improvements to existing functionality.</p> <ul> <li>Use a clear and descriptive title for the issue to identify the suggestion.</li> <li>Provide a step-by-step description of the suggested enhancement in as many details as possible.</li> <li>Provide specific examples to demonstrate the steps.</li> <li>Describe the current behavior and explain which behavior you expected to see instead and why.</li> </ul>"},{"location":"community/contributing/#pull-requests","title":"Pull Requests","text":"<p>The process described here has several goals:</p> <ul> <li>Maintain Curve's quality</li> <li>Fix problems that are important to users</li> <li>Engage the community in working toward the best possible Curve</li> <li>Enable a sustainable system for Curve's maintainers to review contributions</li> </ul> <p>Please follow these steps to have your contribution considered by the maintainers:</p> <ol> <li>Follow all instructions in the template</li> <li>Follow the styleguides</li> <li>After you submit your pull request, verify that all status checks are passing</li> </ol>"},{"location":"community/contributing/#styleguides","title":"Styleguides","text":""},{"location":"community/contributing/#git-commit-messages","title":"Git Commit Messages","text":"<ul> <li>Use the present tense (\"Add feature\" not \"Added feature\")</li> <li>Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\")</li> <li>Limit the first line to 72 characters or less</li> <li>Reference issues and pull requests liberally after the first line</li> </ul>"},{"location":"community/contributing/#java-styleguide","title":"Java Styleguide","text":"<ul> <li>Use Google Java Style Guide</li> <li>Use 4 spaces for indentation</li> <li>Use meaningful variable and method names</li> <li>Add Javadoc for public methods and classes</li> </ul>"},{"location":"community/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository    <pre><code>git clone https://github.com/closeup1202/curve.git\n</code></pre></p> </li> <li> <p>Build the project    <pre><code>./gradlew build\n</code></pre></p> </li> <li> <p>Run tests    <pre><code>./gradlew test\n</code></pre></p> </li> </ol>"},{"location":"community/contributing/#project-structure","title":"Project Structure","text":"<ul> <li><code>core</code>: Pure domain model (No framework dependencies)</li> <li><code>spring</code>: Spring Framework adapter</li> <li><code>kafka</code>: Kafka adapter</li> <li><code>spring-boot-autoconfigure</code>: Spring Boot auto-configuration</li> <li><code>sample</code>: Sample application</li> </ul>"},{"location":"community/contributing/#need-help","title":"Need Help?","text":"<p>If you have any questions, please feel free to reach out to us via GitHub Issues.</p> <p>Thank you for contributing! \ud83d\ude80</p>"},{"location":"community/faq/","title":"Frequently Asked Questions","text":""},{"location":"community/faq/#general-questions","title":"General Questions","text":""},{"location":"community/faq/#what-is-curve","title":"What is Curve?","text":"<p>Curve is a declarative event publishing library for Spring Boot applications. It simplifies event-driven architecture by providing automatic Kafka publishing, PII protection, DLQ handling, and observability with minimal code.</p>"},{"location":"community/faq/#why-use-curve-instead-of-spring-kafka-directly","title":"Why use Curve instead of Spring Kafka directly?","text":"<p>Curve reduces boilerplate by 90% while providing:</p> <ul> <li>Declarative annotations (<code>@PublishEvent</code>)</li> <li>Automatic PII protection</li> <li>Built-in DLQ and backup</li> <li>Standardized event structure</li> <li>Production-ready observability</li> </ul>"},{"location":"community/faq/#is-curve-production-ready","title":"Is Curve production-ready?","text":"<p>Yes! Curve is designed for production use with:</p> <ul> <li>Comprehensive testing (&gt;80% coverage)</li> <li>Battle-tested patterns (outbox, DLQ, retry)</li> <li>Observability and monitoring</li> <li>Active maintenance</li> </ul>"},{"location":"community/faq/#compatibility","title":"Compatibility","text":""},{"location":"community/faq/#what-versions-of-spring-boot-are-supported","title":"What versions of Spring Boot are supported?","text":"<p>Curve supports Spring Boot 3.0+. For specific version compatibility, see the Installation Guide.</p>"},{"location":"community/faq/#what-kafka-versions-are-supported","title":"What Kafka versions are supported?","text":"<p>Kafka 2.8+ is supported. Kafka 3.0+ is recommended for best performance.</p>"},{"location":"community/faq/#can-i-use-curve-with-spring-boot-2x","title":"Can I use Curve with Spring Boot 2.x?","text":"<p>Not currently. Curve requires Spring Boot 3.0+ due to Jakarta EE dependencies.</p>"},{"location":"community/faq/#configuration","title":"Configuration","text":""},{"location":"community/faq/#how-do-i-enable-async-publishing","title":"How do I enable async publishing?","text":"<pre><code>curve:\n  kafka:\n    async-mode: true\n    async-timeout-ms: 5000\n</code></pre> <p>See Configuration Guide for details.</p>"},{"location":"community/faq/#how-do-i-configure-multiple-kafka-topics","title":"How do I configure multiple Kafka topics?","text":"<p>Currently, Curve uses a single main topic. For multiple topics, you can:</p> <ol> <li>Use different event types and route downstream</li> <li>Implement custom <code>EventProducer</code> with routing logic</li> </ol>"},{"location":"community/faq/#can-i-disable-curve-conditionally","title":"Can I disable Curve conditionally?","text":"<p>Yes, use Spring profiles:</p> <pre><code>spring:\n  profiles: prod\n\ncurve:\n  enabled: true\n</code></pre>"},{"location":"community/faq/#features","title":"Features","text":""},{"location":"community/faq/#does-curve-support-transactional-publishing","title":"Does Curve support transactional publishing?","text":"<p>Yes! Use the Transactional Outbox Pattern:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true\n)\n</code></pre>"},{"location":"community/faq/#can-i-publish-events-without-kafka","title":"Can I publish events without Kafka?","text":"<p>Yes, Curve's hexagonal architecture allows custom implementations. See Custom Implementation Guide.</p>"},{"location":"community/faq/#does-curve-support-event-replay","title":"Does Curve support event replay?","text":"<p>Not built-in, but you can:</p> <ol> <li>Republish from DLQ topic</li> <li>Republish from outbox table</li> <li>Use Kafka's consumer group reset</li> </ol>"},{"location":"community/faq/#performance","title":"Performance","text":""},{"location":"community/faq/#whats-the-throughput","title":"What's the throughput?","text":"<ul> <li>Sync mode: ~500 TPS</li> <li>Async mode: ~10,000+ TPS</li> <li>Transactional outbox: ~1,000 TPS</li> </ul>"},{"location":"community/faq/#how-can-i-improve-performance","title":"How can I improve performance?","text":"<ol> <li>Enable async mode</li> <li>Increase Kafka batch size</li> <li>Use connection pooling</li> <li>Scale Kafka brokers</li> </ol>"},{"location":"community/faq/#does-curve-add-latency","title":"Does Curve add latency?","text":"<p>Minimal overhead (~5-10ms) for:</p> <ul> <li>Annotation processing</li> <li>Metadata extraction</li> <li>PII protection</li> </ul>"},{"location":"community/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"community/faq/#events-not-publishing","title":"Events not publishing?","text":"<p>Check:</p> <ol> <li><code>curve.enabled=true</code></li> <li>Kafka connection is healthy</li> <li>Method is called through Spring proxy (not <code>this.method()</code>)</li> <li>No exceptions before method completes</li> </ol> <p>See Troubleshooting Guide.</p>"},{"location":"community/faq/#pii-not-being-masked","title":"PII not being masked?","text":"<p>Verify:</p> <ol> <li><code>curve.pii.enabled=true</code></li> <li><code>@PiiField</code> annotation is present</li> <li>Payload class implements <code>DomainEventPayload</code></li> </ol>"},{"location":"community/faq/#outbox-events-stuck-in-pending","title":"Outbox events stuck in PENDING?","text":"<p>Check:</p> <ol> <li>Outbox poller is running (enable DEBUG logging)</li> <li>Kafka is accessible</li> <li>No database connection issues</li> </ol>"},{"location":"community/faq/#best-practices","title":"Best Practices","text":""},{"location":"community/faq/#should-i-use-outbox-for-all-events","title":"Should I use outbox for all events?","text":"<p>No. Use outbox for:</p> <ul> <li>Critical events (payments, orders)</li> <li>Events requiring atomicity</li> </ul> <p>Use async for:</p> <ul> <li>High-volume events</li> <li>Non-critical events</li> </ul>"},{"location":"community/faq/#what-should-i-include-in-event-payload","title":"What should I include in event payload?","text":"<p>Include:</p> <ul> <li>Essential data for consumers</li> <li>Identifiers (IDs)</li> <li>Timestamps</li> </ul> <p>Exclude:</p> <ul> <li>Large objects (&gt;1MB)</li> <li>Binary data</li> <li>Entire entity graphs</li> </ul>"},{"location":"community/faq/#how-should-i-name-event-types","title":"How should I name event types?","text":"<p>Use SCREAMING_SNAKE_CASE with entity and action:</p> <ul> <li>\u2705 <code>ORDER_CREATED</code>, <code>PAYMENT_COMPLETED</code></li> <li>\u274c <code>created</code>, <code>update</code>, <code>event</code></li> </ul>"},{"location":"community/faq/#advanced","title":"Advanced","text":""},{"location":"community/faq/#can-i-customize-event-metadata","title":"Can I customize event metadata?","text":"<p>Yes, implement <code>ContextProvider</code>:</p> <pre><code>@Component\npublic class CustomContextProvider implements ContextProvider {\n    @Override\n    public Map&lt;String, String&gt; provide() {\n        return Map.of(\"custom_key\", \"custom_value\");\n    }\n}\n</code></pre>"},{"location":"community/faq/#can-i-use-curve-with-kotlin","title":"Can I use Curve with Kotlin?","text":"<p>Yes! Curve works with Kotlin:</p> <pre><code>@PublishEvent(eventType = \"ORDER_CREATED\")\nfun createOrder(request: OrderRequest): Order {\n    return orderRepository.save(Order(request))\n}\n</code></pre>"},{"location":"community/faq/#can-i-publish-events-manually","title":"Can I publish events manually?","text":"<p>Yes, inject <code>EventProducer</code>:</p> <pre><code>@Autowired\nprivate EventProducer eventProducer;\n\npublic void manualPublish() {\n    EventEnvelope&lt;MyPayload&gt; envelope = EventEnvelope.builder()\n        .eventType(\"MANUAL_EVENT\")\n        .payload(new MyPayload())\n        .build();\n\n    eventProducer.publish(envelope);\n}\n</code></pre>"},{"location":"community/faq/#contributing","title":"Contributing","text":""},{"location":"community/faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>See our Contributing Guide for:</p> <ul> <li>Code contributions</li> <li>Bug reports</li> <li>Feature requests</li> <li>Documentation improvements</li> </ul>"},{"location":"community/faq/#where-can-i-ask-questions","title":"Where can I ask questions?","text":"<ul> <li>GitHub Issues</li> <li>GitHub Discussions</li> <li>Email: closeup1202@gmail.com</li> </ul>"},{"location":"community/faq/#still-have-questions","title":"Still have questions?","text":"<p>Check our Documentation or open an issue.</p>"},{"location":"configuration/basic-setup/","title":"Basic Setup Guide","text":"<p>This guide covers the fundamental configuration options for Curve.</p>"},{"location":"configuration/basic-setup/#basic-configuration","title":"Basic Configuration","text":""},{"location":"configuration/basic-setup/#applicationyml","title":"application.yml","text":"<pre><code>curve:\n  enabled: true  # Enable Curve (default: true)\n\n  kafka:\n    topic: event.audit.v1  # Main topic name\n    dlq-topic: event.audit.dlq.v1  # DLQ topic (optional)\n\n  id-generator:\n    worker-id: 1  # Snowflake Worker ID (0~1023)\n    auto-generate: false  # Auto-generate based on MAC address\n</code></pre>"},{"location":"configuration/basic-setup/#configuration-validation","title":"Configuration Validation","text":"<p>Curve automatically validates configuration values at application startup using <code>@Validated</code>.</p>"},{"location":"configuration/basic-setup/#validation-rules","title":"Validation Rules","text":"Configuration Item Validation Rule Error Message <code>curve.kafka.topic</code> Required (non-empty string) \"Kafka topic is required\" <code>curve.kafka.retries</code> 0 or greater \"retries must be 0 or greater\" <code>curve.kafka.retry-backoff-ms</code> Positive number \"retryBackoffMs must be positive\" <code>curve.kafka.request-timeout-ms</code> Positive number \"requestTimeoutMs must be positive\" <code>curve.kafka.async-timeout-ms</code> Positive number \"asyncTimeoutMs must be positive\" <code>curve.kafka.sync-timeout-seconds</code> Positive number \"syncTimeoutSeconds must be positive\" <code>curve.kafka.dlq-executor-threads</code> 1 or greater \"dlqExecutorThreads must be 1 or greater\" <code>curve.id-generator.worker-id</code> 0 ~ 1023 \"workerId must be between 0 and 1023\" <code>curve.retry.max-attempts</code> 1 or greater \"maxAttempts must be 1 or greater\" <code>curve.retry.initial-interval</code> Positive number \"initialInterval must be positive\" <code>curve.retry.multiplier</code> 1 or greater \"multiplier must be 1 or greater\" <code>curve.retry.max-interval</code> Positive number \"maxInterval must be positive\" <code>curve.outbox.poll-interval-ms</code> Positive number \"pollIntervalMs must be positive\" <code>curve.outbox.batch-size</code> 1 ~ 1000 \"batchSize must be between 1 and 1000\" <code>curve.outbox.max-retries</code> 1 or greater \"maxRetries must be 1 or greater\" <code>curve.outbox.send-timeout-seconds</code> Positive number \"sendTimeoutSeconds must be positive\" <code>curve.outbox.retention-days</code> 1 or greater \"retentionDays must be 1 or greater\" <code>curve.async.core-pool-size</code> 1 or greater \"corePoolSize must be at least 1\" <code>curve.async.max-pool-size</code> 1 or greater \"maxPoolSize must be at least 1\" <code>curve.async.queue-capacity</code> 0 or greater \"queueCapacity must be at least 0\" <code>curve.kafka.backup.s3-bucket</code> Required when s3Enabled=true \"s3Bucket is required when s3Enabled=true\" <code>curve.serde.schema-registry-url</code> Required when type=AVRO \"schemaRegistryUrl is required when serde type is AVRO\""},{"location":"configuration/basic-setup/#worker-id-configuration","title":"Worker ID Configuration","text":"<p>The Snowflake ID Generator uses a Worker ID to generate unique IDs in a distributed environment.</p>"},{"location":"configuration/basic-setup/#method-1-explicit-worker-id-configuration-recommended","title":"Method 1: Explicit Worker ID Configuration (Recommended)","text":"<p>Assign a unique Worker ID to each instance.</p> <pre><code>curve:\n  id-generator:\n    worker-id: 1  # Instance 1\n    auto-generate: false\n</code></pre>"},{"location":"configuration/basic-setup/#method-2-auto-generation-caution","title":"Method 2: Auto-Generation (Caution)","text":"<p>Auto-generate Worker ID based on MAC address.</p> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre>"},{"location":"configuration/basic-setup/#kafka-transmission-mode-configuration","title":"Kafka Transmission Mode Configuration","text":"<p>Curve supports both synchronous and asynchronous transmission modes.</p>"},{"location":"configuration/basic-setup/#synchronous-transmission-default","title":"Synchronous Transmission (Default)","text":"<pre><code>curve:\n  kafka:\n    async-mode: false  # Synchronous transmission\n    request-timeout-ms: 30000  # 30 seconds\n</code></pre>"},{"location":"configuration/basic-setup/#asynchronous-transmission","title":"Asynchronous Transmission","text":"<pre><code>curve:\n  kafka:\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000  # 5 seconds timeout\n</code></pre>"},{"location":"configuration/basic-setup/#dlq-configuration","title":"DLQ Configuration","text":"<p>The Dead Letter Queue stores events that fail to be transmitted.</p> <pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # Enable DLQ\n</code></pre>"},{"location":"configuration/basic-setup/#retry-configuration","title":"Retry Configuration","text":"<p>Automatic retry configuration in case of transmission failure.</p> <pre><code>curve:\n  retry:\n    enabled: true  # Enable retry\n    max-attempts: 3  # Maximum 3 attempts\n    initial-interval: 1000  # Initial 1 second wait\n    multiplier: 2.0  # Increase by 2x (1s -&gt; 2s -&gt; 4s)\n    max-interval: 10000  # Maximum 10 seconds\n</code></pre>"},{"location":"configuration/basic-setup/#pii-protection-configuration","title":"PII Protection Configuration","text":"<p>Through PII (Personally Identifiable Information) protection features, sensitive data can be automatically masked, encrypted, or hashed.</p> <pre><code>curve:\n  pii:\n    enabled: true  # Enable PII protection (default: true)\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Encryption key (environment variable required)\n      salt: ${PII_HASH_SALT}              # Hashing salt (environment variable recommended)\n</code></pre>"},{"location":"configuration/basic-setup/#outbox-configuration","title":"Outbox Configuration","text":"<p>Use the Transactional Outbox Pattern to ensure atomicity between DB transactions and event publishing.</p> <pre><code>curve:\n  outbox:\n    enabled: true  # Enable Outbox\n    poll-interval-ms: 1000  # Polling interval (1 second)\n    batch-size: 100  # Batch size\n    max-retries: 3  # Maximum retry count\n    send-timeout-seconds: 10  # Send timeout\n    cleanup-enabled: true  # Enable old event cleanup\n    retention-days: 7  # Retention period (7 days)\n    cleanup-cron: \"0 0 2 * * *\"  # Cleanup job execution time (2 AM daily)\n    initialize-schema: embedded  # Schema initialization mode (embedded, always, never)\n</code></pre>"},{"location":"configuration/basic-setup/#serialization-configuration","title":"Serialization Configuration","text":"<p>Configure the event payload serialization method.</p> <pre><code>curve:\n  serde:\n    type: JSON  # JSON (default), AVRO, PROTOBUF\n</code></pre>"},{"location":"configuration/basic-setup/#logging-configuration","title":"Logging Configuration","text":"<p>By default, Curve outputs minimal logs. To see detailed configuration information or internal operations, enable the DEBUG level.</p> <pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n</code></pre>"},{"location":"configuration/profiles/","title":"Environment Profiles","text":"<p>This guide provides configuration examples and recommendations for different environments.</p>"},{"location":"configuration/profiles/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"configuration/profiles/#production-environment-stability-focused","title":"Production Environment (Stability-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${INSTANCE_ID}  # Injected from environment variable\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # Synchronous transmission\n    retries: 5\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n  retry:\n    enabled: true\n    max-attempts: 5\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  aop:\n    enabled: true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Environment variable required\n      salt: ${PII_HASH_SALT}\n\n  async:\n    enabled: true\n    core-pool-size: 4\n    max-pool-size: 20\n    queue-capacity: 1000\n\n  outbox:\n    enabled: true\n    initialize-schema: never  # Use Flyway\n    cleanup-enabled: true\n    retention-days: 14\n</code></pre>"},{"location":"configuration/profiles/#developmenttest-environment-performance-focused","title":"Development/Test Environment (Performance-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.dev.v1\n    dlq-topic: event.audit.dlq.dev.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 3000\n    retries: 3\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 500\n    multiplier: 1.5\n\n  aop:\n    enabled: true\n\n  outbox:\n    enabled: true\n    initialize-schema: always\n\n  async:\n    enabled: true\n</code></pre>"},{"location":"configuration/profiles/#high-performance-environment","title":"High-Performance Environment","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${WORKER_ID}\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000\n    retries: 1  # Minimum retry\n\n  retry:\n    enabled: false  # Disable retry (performance priority)\n\n  aop:\n    enabled: true\n\n  async:\n    enabled: true\n    core-pool-size: 8\n    max-pool-size: 32\n    queue-capacity: 2000\n</code></pre>"},{"location":"configuration/profiles/#environment-specific-configuration-recommendations","title":"Environment-specific Configuration Recommendations","text":""},{"location":"configuration/profiles/#local-development","title":"Local Development","text":"<ul> <li>Worker ID: 1 (fixed)</li> <li>Transmission Mode: Synchronous (debugging convenience)</li> <li>DLQ: Enabled</li> <li>Retry: Minimum (fast failure)</li> <li>Outbox: Enabled (auto schema generation)</li> </ul>"},{"location":"configuration/profiles/#staging","title":"Staging","text":"<ul> <li>Worker ID: Environment variable</li> <li>Transmission Mode: Asynchronous</li> <li>DLQ: Enabled</li> <li>Retry: Medium level</li> <li>Outbox: Enabled</li> </ul>"},{"location":"configuration/profiles/#production","title":"Production","text":"<ul> <li>Worker ID: Centrally managed (Consul/etcd)</li> <li>Transmission Mode: Based on business requirements</li> <li>DLQ: Mandatory enabled</li> <li>Retry: High level</li> <li>Outbox: Mandatory enabled (data consistency)</li> </ul>"},{"location":"features/declarative-publishing/","title":"Declarative Event Publishing","text":"<p>The <code>@PublishEvent</code> annotation is the core feature of Curve, enabling declarative event publishing with minimal code.</p>"},{"location":"features/declarative-publishing/#basic-usage","title":"Basic Usage","text":"<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(eventType = \"ORDER_CREATED\")\n    public Order createOrder(OrderRequest request) {\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre> <p>When <code>createOrder()</code> is called, Curve automatically:</p> <ol> <li>Captures the method return value (<code>Order</code>)</li> <li>Extracts metadata (trace ID, user, etc.)</li> <li>Wraps it in <code>EventEnvelope</code></li> <li>Publishes to Kafka</li> </ol>"},{"location":"features/declarative-publishing/#annotation-parameters","title":"Annotation Parameters","text":""},{"location":"features/declarative-publishing/#required-parameters","title":"Required Parameters","text":""},{"location":"features/declarative-publishing/#eventtype-string","title":"<code>eventType</code> (String)","text":"<p>Unique identifier for this event type.</p> <pre><code>@PublishEvent(eventType = \"USER_REGISTERED\")\n</code></pre> <p>Naming conventions:</p> <ul> <li>Use SCREAMING_SNAKE_CASE</li> <li>Be specific: <code>ORDER_CREATED</code> not just <code>CREATED</code></li> <li>Include entity name: <code>USER_DELETED</code>, <code>PAYMENT_COMPLETED</code></li> </ul>"},{"location":"features/declarative-publishing/#optional-parameters","title":"Optional Parameters","text":""},{"location":"features/declarative-publishing/#severity-eventseverity","title":"<code>severity</code> (EventSeverity)","text":"<p>Event severity level for filtering and alerting.</p> <pre><code>@PublishEvent(\n    eventType = \"PAYMENT_FAILED\",\n    severity = EventSeverity.ERROR\n)\n</code></pre> <p>Available values:</p> <ul> <li><code>INFO</code> - Normal operations (default)</li> <li><code>WARN</code> - Warnings</li> <li><code>ERROR</code> - Errors requiring attention</li> <li><code>CRITICAL</code> - Critical failures requiring immediate action</li> </ul>"},{"location":"features/declarative-publishing/#payload-spel-expression","title":"<code>payload</code> (SpEL Expression)","text":"<p>Extract specific data for the event payload using Spring Expression Language.</p> <pre><code>@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#args[0].toEventDto()\"  // Transform request\n)\npublic User updateUser(UserUpdateRequest request) {\n    return userRepository.save(request.toEntity());\n}\n</code></pre> <p>SpEL Variables:</p> Variable Description Example <code>#result</code> Method return value <code>#result</code> <code>#args[n]</code> Method arguments <code>#args[0]</code>, <code>#args[1]</code> <code>#root</code> Root evaluation context <code>#root.methodName</code> <p>Examples:</p> <pre><code>// Use entire return value (default)\n@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest req) { ... }\n\n// Use specific field\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    payload = \"#result.id\"\n)\npublic Order createOrder(OrderRequest req) { ... }\n\n// Transform with custom method\n@PublishEvent(\n    eventType = \"USER_CREATED\",\n    payload = \"#result.toPublicDto()\"\n)\npublic User createUser(UserRequest req) { ... }\n\n// Use method argument\n@PublishEvent(\n    eventType = \"ORDER_SUBMITTED\",\n    payload = \"#args[0]\"\n)\npublic Order submitOrder(OrderSubmission submission) { ... }\n</code></pre>"},{"location":"features/declarative-publishing/#payloadindex-int","title":"<code>payloadIndex</code> (int)","text":"<p>Specify which method parameter to use as the event payload.</p> <pre><code>@PublishEvent(\n    eventType = \"ORDER_SUBMITTED\",\n    payloadIndex = 0  // Use first parameter (0-indexed)\n)\npublic Order submitOrder(OrderSubmission submission) {\n    // submission will be used as payload\n    return orderRepository.save(submission.toOrder());\n}\n</code></pre> <p>Values: - <code>-1</code> (default): Use method return value as payload - <code>0</code> or greater: Use the parameter at this index as payload</p> <p>Note: The <code>payload</code> SpEL expression overrides this setting if specified.</p>"},{"location":"features/declarative-publishing/#phase-publisheventphase","title":"<code>phase</code> (PublishEvent.Phase)","text":"<p>Control when the event is published relative to method execution.</p> <pre><code>@PublishEvent(\n    eventType = \"VALIDATION_PERFORMED\",\n    phase = PublishEvent.Phase.BEFORE  // Publish before method runs\n)\npublic void validateOrder(Order order) {\n    // Event published first, then validation runs\n    validator.validate(order);\n}\n</code></pre> <p>Available phases:</p> Phase When Published Use Case <code>BEFORE</code> Before method execution Pre-validation events, audit trails <code>AFTER_RETURNING</code> After successful return (default) Success events, state changes <code>AFTER</code> After method execution (even on exception) Audit trails regardless of outcome <p>Example scenarios:</p> <pre><code>// Success-only events\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    phase = PublishEvent.Phase.AFTER_RETURNING\n)\npublic Order createOrder(OrderRequest req) { ... }\n\n// Always publish, even on failure\n@PublishEvent(\n    eventType = \"ORDER_CREATION_ATTEMPTED\",\n    phase = PublishEvent.Phase.AFTER\n)\npublic Order createOrder(OrderRequest req) { ... }\n</code></pre>"},{"location":"features/declarative-publishing/#failonerror-boolean","title":"<code>failOnError</code> (boolean)","text":"<p>Control whether event publishing failures should fail the business logic.</p> <pre><code>@PublishEvent(\n    eventType = \"CRITICAL_OPERATION\",\n    failOnError = true  // Throw exception if event publishing fails\n)\npublic void performCriticalOperation() {\n    // If event publishing fails, this method will throw exception\n    // and rollback any transaction\n}\n</code></pre> <p>Values: - <code>false</code> (default): Log error but continue business logic - <code>true</code>: Throw exception and fail the method if event publishing fails</p> <p>Recommendation: Use <code>false</code> (default) for most cases to prevent event publishing issues from breaking business logic. Only use <code>true</code> for critical audit requirements where event loss is unacceptable.</p>"},{"location":"features/declarative-publishing/#transactional-outbox-parameters","title":"Transactional Outbox Parameters","text":"<p>For guaranteed delivery with transactional outbox pattern:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,                      // Enable outbox\n    aggregateType = \"Order\",            // Entity type\n    aggregateId = \"#result.id\"          // Entity ID\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>outbox</code> boolean Enable transactional outbox <code>aggregateType</code> String Entity type name <code>aggregateId</code> SpEL Entity unique identifier <p> Transactional Outbox Guide</p>"},{"location":"features/declarative-publishing/#advanced-examples","title":"Advanced Examples","text":""},{"location":"features/declarative-publishing/#1-multi-parameter-method","title":"1. Multi-Parameter Method","text":"<pre><code>@PublishEvent(\n    eventType = \"ORDER_SHIPPED\",\n    payload = \"#result.toShipmentPayload()\"\n)\npublic Shipment shipOrder(Long orderId, Address address) {\n    // ...\n    return shipment;\n}\n</code></pre>"},{"location":"features/declarative-publishing/#2-conditional-publishing","title":"2. Conditional Publishing","text":"<p>Use Spring's conditional annotations:</p> <pre><code>@ConditionalOnProperty(name = \"features.audit\", havingValue = \"true\")\n@PublishEvent(eventType = \"ADMIN_ACTION\")\npublic void performAdminAction(AdminRequest request) {\n    // ...\n}\n</code></pre>"},{"location":"features/declarative-publishing/#3-method-level-configuration","title":"3. Method-Level Configuration","text":"<p>Override global settings per method:</p> <pre><code>@Service\npublic class CriticalService {\n\n    // High-priority event with custom severity and error handling\n    @PublishEvent(\n        eventType = \"FRAUD_DETECTED\",\n        severity = EventSeverity.CRITICAL,\n        failOnError = true  // Fail method if event cannot be published\n    )\n    public FraudAlert detectFraud(Transaction tx) {\n        // Critical audit event - must be published\n        return fraudDetectionService.analyze(tx);\n    }\n}\n</code></pre>"},{"location":"features/declarative-publishing/#4-async-method-publishing","title":"4. Async Method Publishing","text":"<p>Works with <code>@Async</code> methods:</p> <pre><code>@Async\n@PublishEvent(eventType = \"REPORT_GENERATED\")\npublic CompletableFuture&lt;Report&gt; generateReport(ReportRequest req) {\n    Report report = reportGenerator.generate(req);\n    return CompletableFuture.completedFuture(report);\n}\n</code></pre> <p>MDC Context Propagation</p> <p>Curve automatically propagates MDC context (trace ID, etc.) to async threads.</p>"},{"location":"features/declarative-publishing/#best-practices","title":"Best Practices","text":""},{"location":"features/declarative-publishing/#do","title":"DO","text":"<ul> <li>Use descriptive event types: <code>USER_REGISTERED</code>, <code>ORDER_COMPLETED</code></li> <li>Apply on service layer methods (not controllers or repositories)</li> <li>Keep payload minimal - only essential data</li> <li>Use <code>@PiiField</code> for sensitive data</li> <li>Set appropriate severity levels</li> </ul>"},{"location":"features/declarative-publishing/#dont","title":"DON'T","text":"<ul> <li>Publish high-volume events in sync mode (use async)</li> <li>Include entire entities as payload (extract DTOs)</li> <li>Publish from controllers (breaks separation of concerns)</li> <li>Use generic event types like <code>CREATED</code> or <code>UPDATED</code></li> </ul>"},{"location":"features/declarative-publishing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/declarative-publishing/#events-not-publishing","title":"Events Not Publishing","text":"<p>Events not appearing in Kafka</p> <p>Check:</p> <ol> <li><code>curve.enabled=true</code> in application.yml</li> <li>Method is called through Spring proxy (not <code>this.method()</code>)</li> <li>No exceptions thrown before method completes</li> <li>Kafka connection is healthy</li> </ol> <p>Debug:</p> <pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n</code></pre>"},{"location":"features/declarative-publishing/#payload-extraction-fails","title":"Payload Extraction Fails","text":"<p>SpEL evaluation error</p> <p>Common issues:</p> <ul> <li>Typo in SpEL expression</li> <li>Accessing null fields</li> <li>Wrong argument index</li> </ul> <p>Solution:</p> <pre><code>// Add null check\n@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#result != null ? #result.toDto() : null\"\n)\n</code></pre>"},{"location":"features/declarative-publishing/#whats-next","title":"What's Next?","text":"<ul> <li> <p> PII Protection</p> <p>Automatically protect sensitive data</p> <p> PII Guide</p> </li> <li> <p> Transactional Outbox</p> <p>Guarantee exactly-once delivery</p> <p> Outbox Pattern</p> </li> <li> <p> API Reference</p> <p>Complete annotation reference</p> <p> API Docs</p> </li> </ul>"},{"location":"features/failure-recovery/","title":"Failure Recovery","text":"<p>Curve provides 3-tier failure recovery to ensure zero event loss, even when Kafka is down.</p>"},{"location":"features/failure-recovery/#overview","title":"Overview","text":"<pre><code>graph LR\n    A[Event] --&gt; B{Publish to Main Topic}\n    B --&gt;|Success| C[Done \u2713]\n    B --&gt;|Failure| D{Publish to DLQ}\n    D --&gt;|Success| E[DLQ \u2713]\n    D --&gt;|Failure| F{Backup Strategy}\n    F --&gt;|S3| G[S3 Bucket \u2601\ufe0f]\n    F --&gt;|Local| H[Local File \ud83d\udcbe]\n\n    style C fill:#00897b\n    style E fill:#ff9800\n    style G fill:#2196f3\n    style H fill:#f44336\n</code></pre>"},{"location":"features/failure-recovery/#tiers","title":"Tiers","text":"<ol> <li>Main Topic - Primary Kafka topic for events</li> <li>DLQ (Dead Letter Queue) - Fallback topic for failed events</li> <li>Backup Strategy - Last resort when Kafka is unavailable (S3 or Local File)</li> </ol>"},{"location":"features/failure-recovery/#configuration","title":"Configuration","text":"application.yml<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # DLQ topic\n\n    # Backup Strategy Configuration\n    backup:\n      s3-enabled: true             # Enable S3 backup\n      s3-bucket: \"my-event-backup\" # S3 Bucket name\n      s3-prefix: \"dlq-backup\"      # S3 Key prefix\n      local-enabled: true          # Enable local file backup as fallback\n\n  retry:\n    enabled: true\n    max-attempts: 3           # Retry 3 times\n    initial-interval: 1000    # 1 second\n    multiplier: 2.0           # Exponential backoff\n    max-interval: 10000       # Max 10 seconds\n</code></pre>"},{"location":"features/failure-recovery/#tier-1-main-topic","title":"Tier 1: Main Topic","text":"<p>Normal event publishing to the primary Kafka topic.</p> <pre><code>@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>Retry behavior:</p> <ul> <li>Attempt 1: Immediate</li> <li>Attempt 2: Wait 1 second</li> <li>Attempt 3: Wait 2 seconds (1s \u00d7 2.0)</li> <li>Attempt 4: Wait 4 seconds (2s \u00d7 2.0)</li> </ul> <p>If all attempts fail \u2192 Move to Tier 2 (DLQ)</p>"},{"location":"features/failure-recovery/#tier-2-dead-letter-queue-dlq","title":"Tier 2: Dead Letter Queue (DLQ)","text":"<p>Failed events are sent to a separate DLQ topic for analysis and reprocessing.</p>"},{"location":"features/failure-recovery/#dlq-event-structure","title":"DLQ Event Structure","text":"<pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"failureReason\": \"Kafka broker not available\",\n  \"failureTimestamp\": \"2026-02-03T10:30:00Z\",\n  \"retryCount\": 3,\n  \"originalEvent\": {\n    \"eventType\": \"ORDER_CREATED\",\n    \"payload\": { ... }\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#monitoring-dlq","title":"Monitoring DLQ","text":""},{"location":"features/failure-recovery/#1-kafka-console-consumer","title":"1. Kafka Console Consumer","text":"<pre><code>kafka-console-consumer --bootstrap-server localhost:9092 \\\n    --topic event.audit.dlq.v1 --from-beginning\n</code></pre>"},{"location":"features/failure-recovery/#2-kafka-ui","title":"2. Kafka UI","text":"<p>Access Kafka UI at http://localhost:8080 and navigate to the DLQ topic.</p>"},{"location":"features/failure-recovery/#3-spring-boot-actuator","title":"3. Spring Boot Actuator","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"dlq\": {\n    \"totalDlqEvents\": 5,\n    \"recentDlqEvents\": [\n      {\n        \"eventType\": \"ORDER_CREATED\",\n        \"failureReason\": \"Timeout\",\n        \"timestamp\": \"2026-02-03T10:30:00Z\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#tier-3-backup-strategies","title":"Tier 3: Backup Strategies","text":"<p>If Kafka is completely unavailable (broker down, network issue), events are saved using configured backup strategies.</p>"},{"location":"features/failure-recovery/#1-s3-backup-recommended-for-cloudk8s","title":"1. S3 Backup (Recommended for Cloud/K8s)","text":"<p>Stores failed events in AWS S3 or MinIO. Ideal for containerized environments where local storage is ephemeral.</p> <p>Requirements: - <code>software.amazon.awssdk:s3</code> dependency - <code>S3Client</code> bean configured in Spring Context</p> <p>S3 Key Structure: <code>prefix/yyyy/MM/dd/{eventId}.json</code></p>"},{"location":"features/failure-recovery/#2-local-file-backup","title":"2. Local File Backup","text":"<p>Stores failed events to the local file system. Useful for bare-metal servers or development environments.</p> <p>Backup Location: <pre><code>/tmp/curve-backup/\n  \u2514\u2500\u2500 failed-events/\n      \u251c\u2500\u2500 1738587000000.json\n      \u251c\u2500\u2500 1738587001000.json\n      \u2514\u2500\u2500 1738587002000.json\n</code></pre></p> <p>Security: - POSIX systems: Files created with <code>600</code> permissions (rw-------) - Windows: ACL restricted to current user only</p>"},{"location":"features/failure-recovery/#backup-file-format","title":"Backup File Format","text":"1738587000000.json<pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"ORDER_CREATED\",\n  \"occurredAt\": \"2026-02-03T10:30:00Z\",\n  \"backupReason\": \"Kafka broker unavailable\",\n  \"backupTimestamp\": \"2026-02-03T10:30:00.500Z\",\n  \"payload\": { ... }\n}\n</code></pre>"},{"location":"features/failure-recovery/#recovery-process","title":"Recovery Process","text":""},{"location":"features/failure-recovery/#1-manual-recovery-with-script","title":"1. Manual Recovery with Script","text":"<p>Curve provides a recovery script for republishing backed-up events:</p> scripts/dlq-recovery.sh<pre><code>#!/bin/bash\n\n# List backup files\n./scripts/dlq-recovery.sh --list\n\n# Recover all files\n./scripts/dlq-recovery.sh \\\n    --topic event.audit.v1 \\\n    --broker localhost:9092\n\n# Recover specific file\n./scripts/dlq-recovery.sh \\\n    --file /tmp/curve-backup/failed-events/1738587000000.json \\\n    --topic event.audit.v1 \\\n    --broker localhost:9092\n</code></pre>"},{"location":"features/failure-recovery/#2-automated-recovery-future-feature","title":"2. Automated Recovery (Future Feature)","text":"<p>Planned for v0.1.0:</p> <ul> <li>Automatic retry from S3/Local backup when Kafka recovers</li> <li>Configurable recovery schedule</li> <li>Recovery metrics and alerts</li> </ul>"},{"location":"features/failure-recovery/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"features/failure-recovery/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"clusterId\": \"lkc-abc123\",\n    \"nodeCount\": 3,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#metrics","title":"Metrics","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\",\n    \"totalDlqEvents\": 3,\n    \"totalBackupFiles\": 0\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#alerts","title":"Alerts","text":"<p>Set up alerts for:</p> <ul> <li>DLQ event count &gt; threshold</li> <li>Backup file count &gt; 0</li> <li>Success rate &lt; 99%</li> </ul> <p>Example with Prometheus:</p> <pre><code>- alert: HighDLQEventCount\n  expr: curve_dlq_events_total &gt; 10\n  for: 5m\n  annotations:\n    summary: \"High DLQ event count detected\"\n</code></pre>"},{"location":"features/failure-recovery/#best-practices","title":"Best Practices","text":""},{"location":"features/failure-recovery/#do","title":"DO","text":"<ul> <li>Use S3 Backup in K8s - Local files are lost on pod restart</li> <li>Monitor DLQ regularly - Set up alerts for DLQ events</li> <li>Investigate failures - Analyze failure reasons</li> <li>Test recovery - Practice recovery procedures</li> <li>Set up alerts - Notify on backup file creation</li> <li>Regular cleanup - Archive old backup files</li> </ul>"},{"location":"features/failure-recovery/#dont","title":"DON'T","text":"<ul> <li>Ignore DLQ events - they indicate issues</li> <li>Disable backup in production</li> <li>Store backups on ephemeral storage without S3 backup</li> <li>Delete backup files without analysis</li> </ul>"},{"location":"features/failure-recovery/#production-recommendations","title":"Production Recommendations","text":""},{"location":"features/failure-recovery/#1-s3-backup-for-kubernetes","title":"1. S3 Backup for Kubernetes","text":"<p>Configure S3 backup to ensure data persistence across pod restarts:</p> <pre><code>curve:\n  kafka:\n    backup:\n      s3-enabled: true\n      s3-bucket: \"prod-event-backups\"\n      local-enabled: false # Optional: disable local backup if S3 is reliable\n</code></pre>"},{"location":"features/failure-recovery/#2-separate-dlq-consumer","title":"2. Separate DLQ Consumer","text":"<p>Create a dedicated consumer for DLQ analysis:</p> <pre><code>@KafkaListener(topics = \"event.audit.dlq.v1\")\npublic void handleDlqEvent(DlqEvent event) {\n    log.error(\"DLQ Event: {} - Reason: {}\",\n        event.getEventType(),\n        event.getFailureReason()\n    );\n\n    // Send alert\n    alertService.sendAlert(event);\n\n    // Store for analysis\n    dlqRepository.save(event);\n}\n</code></pre>"},{"location":"features/failure-recovery/#3-automated-recovery-job","title":"3. Automated Recovery Job","text":"<p>Run periodic recovery job:</p> <pre><code>@Scheduled(fixedDelay = 3600000) // Every hour\npublic void recoverBackupFiles() {\n    List&lt;File&gt; backups = backupService.listBackupFiles();\n\n    for (File backup : backups) {\n        try {\n            eventProducer.republish(backup);\n            backup.delete();\n        } catch (Exception e) {\n            log.error(\"Recovery failed for {}\", backup, e);\n        }\n    }\n}\n</code></pre>"},{"location":"features/failure-recovery/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/failure-recovery/#dlq-events-not-created","title":"DLQ Events Not Created","text":"<p>Events failing but no DLQ events</p> <p>Check:</p> <ol> <li><code>curve.kafka.dlq-topic</code> is configured</li> <li>DLQ topic exists in Kafka</li> <li>Kafka is accessible</li> </ol>"},{"location":"features/failure-recovery/#backup-files-accumulating","title":"Backup Files Accumulating","text":"<p>Many backup files created</p> <p>Possible causes:</p> <ul> <li>Kafka broker down</li> <li>Network issues</li> <li>Authentication failure</li> </ul> <p>Solution:</p> <ol> <li>Check Kafka health: <code>docker-compose ps</code></li> <li>Verify bootstrap servers</li> <li>Check Kafka logs</li> </ol>"},{"location":"features/failure-recovery/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Transactional Outbox</p> <p>Guarantee atomicity</p> <p> Outbox Pattern</p> </li> <li> <p> Observability</p> <p>Monitor your events</p> <p> Observability</p> </li> </ul>"},{"location":"features/observability/","title":"Observability","text":"<p>Curve provides built-in observability through Spring Boot Actuator, custom metrics, and health checks.</p>"},{"location":"features/observability/#health-checks","title":"Health Checks","text":""},{"location":"features/observability/#curve-health-indicator","title":"Curve Health Indicator","text":"<p>Check Curve's operational status:</p> <pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"clusterId\": \"lkc-abc123\",\n    \"nodeCount\": 3,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre>"},{"location":"features/observability/#configuration","title":"Configuration","text":"application.yml<pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,metrics,curve-metrics\n  endpoint:\n    health:\n      show-details: always\n</code></pre>"},{"location":"features/observability/#custom-metrics-endpoint","title":"Custom Metrics Endpoint","text":"<p>Curve exposes a dedicated metrics endpoint:</p> <pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <p>Response:</p> <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\",\n    \"totalDlqEvents\": 3,\n    \"totalKafkaErrors\": 0\n  },\n  \"events\": {\n    \"published\": [\n      {\n        \"name\": \"events.published.total\",\n        \"description\": \"Total published events\",\n        \"baseUnit\": \"events\",\n        \"measurements\": [\n          { \"statistic\": \"COUNT\", \"value\": 1523.0 }\n        ]\n      }\n    ],\n    \"publishDuration\": [\n      {\n        \"name\": \"events.publish.duration\",\n        \"description\": \"Event publish duration\",\n        \"baseUnit\": \"milliseconds\",\n        \"measurements\": [\n          { \"statistic\": \"MEAN\", \"value\": 45.2 },\n          { \"statistic\": \"MAX\", \"value\": 150.0 }\n        ]\n      }\n    ]\n  },\n  \"dlq\": {\n    \"totalDlqEvents\": 3,\n    \"recentDlqEvents\": [\n      {\n        \"eventType\": \"ORDER_CREATED\",\n        \"failureReason\": \"Kafka timeout\",\n        \"timestamp\": \"2026-02-03T10:30:00Z\"\n      }\n    ]\n  },\n  \"kafka\": {\n    \"connectionCount\": 1,\n    \"inFlightRequests\": 0,\n    \"requestLatencyAvg\": 25.5\n  }\n}\n</code></pre>"},{"location":"features/observability/#micrometer-metrics","title":"Micrometer Metrics","text":"<p>Curve integrates with Micrometer for standard metrics:</p>"},{"location":"features/observability/#available-metrics","title":"Available Metrics","text":"Metric Type Description <code>curve.events.published.total</code> Counter Total events published <code>curve.events.failed.total</code> Counter Total failed events <code>curve.events.publish.duration</code> Timer Event publish duration <code>curve.dlq.events.total</code> Counter Total DLQ events <code>curve.outbox.pending</code> Gauge Pending outbox events <code>curve.kafka.errors.total</code> Counter Kafka errors"},{"location":"features/observability/#prometheus-integration","title":"Prometheus Integration","text":"application.yml<pre><code>management:\n  metrics:\n    export:\n      prometheus:\n        enabled: true\n  endpoints:\n    web:\n      exposure:\n        include: prometheus\n</code></pre> <p>Scrape metrics:</p> <pre><code>curl http://localhost:8080/actuator/prometheus | grep curve\n</code></pre> <p>Output:</p> <pre><code># TYPE curve_events_published_total counter\ncurve_events_published_total{eventType=\"ORDER_CREATED\",} 856.0\ncurve_events_published_total{eventType=\"USER_REGISTERED\",} 667.0\n\n# TYPE curve_events_publish_duration_seconds summary\ncurve_events_publish_duration_seconds_count 1523.0\ncurve_events_publish_duration_seconds_sum 68.8\n</code></pre>"},{"location":"features/observability/#logging","title":"Logging","text":""},{"location":"features/observability/#enable-debug-logging","title":"Enable Debug Logging","text":"application.yml<pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n    io.github.closeup1202.curve.kafka: TRACE  # Kafka-specific\n</code></pre>"},{"location":"features/observability/#log-output","title":"Log Output","text":"<pre><code>2026-02-03 10:30:00.123 DEBUG [curve] Publishing event: ORDER_CREATED\n2026-02-03 10:30:00.125 DEBUG [curve.kafka] Sending to topic: event.audit.v1\n2026-02-03 10:30:00.150 INFO  [curve] Event published successfully: eventId=7355889748156289024\n</code></pre>"},{"location":"features/observability/#structured-logging-json","title":"Structured Logging (JSON)","text":"<pre><code>logging:\n  pattern:\n    console: '{\"time\":\"%d\",\"level\":\"%p\",\"logger\":\"%c\",\"message\":\"%m\"}%n'\n</code></pre>"},{"location":"features/observability/#distributed-tracing","title":"Distributed Tracing","text":"<p>Curve automatically propagates trace context:</p>"},{"location":"features/observability/#spring-cloud-sleuth-integration","title":"Spring Cloud Sleuth Integration","text":"<pre><code>dependencies {\n    implementation 'org.springframework.cloud:spring-cloud-starter-sleuth'\n}\n</code></pre> <p>Trace context in events:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"metadata\": {\n    \"trace\": {\n      \"traceId\": \"abc123\",       // \u2190 Propagated\n      \"spanId\": \"def456\",         // \u2190 Propagated\n      \"parentSpanId\": \"ghi789\"\n    }\n  }\n}\n</code></pre>"},{"location":"features/observability/#mdc-context-propagation","title":"MDC Context Propagation","text":"<p>Even in async mode, MDC context is preserved:</p> <pre><code>@Async\n@PublishEvent(eventType = \"REPORT_GENERATED\")\npublic CompletableFuture&lt;Report&gt; generateReport() {\n    // Trace ID available in logs\n    log.info(\"Generating report\");\n    return CompletableFuture.completedFuture(new Report());\n}\n</code></pre>"},{"location":"features/observability/#dashboards","title":"Dashboards","text":""},{"location":"features/observability/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Import the Curve Grafana dashboard:</p> curve-dashboard.json<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Curve Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Event Throughput\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(curve_events_published_total[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Success Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"curve_events_published_total / (curve_events_published_total + curve_events_failed_total) * 100\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"features/observability/#key-panels","title":"Key Panels","text":"<ol> <li>Event Throughput - Events/sec over time</li> <li>Success Rate - Percentage of successful publishes</li> <li>DLQ Events - Failed events count</li> <li>Publish Latency - P50, P95, P99 latencies</li> <li>Outbox Queue - Pending events in outbox</li> </ol>"},{"location":"features/observability/#alerts","title":"Alerts","text":""},{"location":"features/observability/#prometheus-alerting-rules","title":"Prometheus Alerting Rules","text":"alerts.yml<pre><code>groups:\n  - name: curve\n    interval: 30s\n    rules:\n      - alert: HighEventFailureRate\n        expr: |\n          (\n            rate(curve_events_failed_total[5m])\n            /\n            rate(curve_events_published_total[5m])\n          ) &gt; 0.01\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event failure rate ({{ $value }}%)\"\n\n      - alert: DLQEventsDetected\n        expr: curve_dlq_events_total &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"{{ $value }} events in DLQ\"\n\n      - alert: OutboxQueueGrowing\n        expr: curve_outbox_pending &gt; 1000\n        for: 10m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Outbox queue has {{ $value }} pending events\"\n\n      - alert: KafkaConnectionLost\n        expr: curve_kafka_connection_count == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Kafka connection lost\"\n</code></pre>"},{"location":"features/observability/#best-practices","title":"Best Practices","text":""},{"location":"features/observability/#do","title":"DO","text":"<ul> <li>Enable health checks - Monitor Curve status</li> <li>Set up alerts - Notify on failures</li> <li>Monitor DLQ - Investigate failed events</li> <li>Track success rate - Aim for &gt;99.9%</li> <li>Use distributed tracing - Debug issues across services</li> <li>Dashboard key metrics - Visualize trends</li> </ul>"},{"location":"features/observability/#dont","title":"DON'T","text":"<ul> <li>Ignore DLQ events</li> <li>Disable metrics in production</li> <li>Skip alerting setup</li> <li>Log at TRACE level in production</li> </ul>"},{"location":"features/observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/observability/#metrics-not-appearing","title":"Metrics Not Appearing","text":"<p>Metrics endpoint returns empty</p> <p>Check:</p> <ol> <li>Actuator is enabled: <code>management.endpoints.web.exposure.include=curve-metrics</code></li> <li>Curve is enabled: <code>curve.enabled=true</code></li> <li>Events have been published</li> </ol>"},{"location":"features/observability/#high-latency","title":"High Latency","text":"<p>Publish duration &gt; 1 second</p> <p>Possible causes:</p> <ul> <li>Network latency to Kafka</li> <li>Large payloads</li> <li>Kafka broker overload</li> </ul> <p>Solutions:</p> <ol> <li>Enable async mode: <code>curve.kafka.async-mode=true</code></li> <li>Reduce payload size</li> <li>Scale Kafka brokers</li> </ol>"},{"location":"features/observability/#production-checklist","title":"Production Checklist","text":"<ul> <li>[ ] Enable health checks</li> <li>[ ] Set up Prometheus scraping</li> <li>[ ] Create Grafana dashboards</li> <li>[ ] Configure alerting rules</li> <li>[ ] Enable distributed tracing</li> <li>[ ] Set up log aggregation</li> <li>[ ] Monitor DLQ topic</li> <li>[ ] Test failover scenarios</li> </ul>"},{"location":"features/observability/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Operations Guide</p> <p>Production deployment best practices</p> <p> Operations</p> </li> <li> <p> Troubleshooting</p> <p>Common issues and solutions</p> <p> Troubleshooting</p> </li> </ul>"},{"location":"features/overview/","title":"Features Overview","text":"<p>Curve provides production-ready features for event-driven microservices out of the box.</p>"},{"location":"features/overview/#core-features","title":"Core Features","text":""},{"location":"features/overview/#declarative-event-publishing","title":"Declarative Event Publishing","text":"<p>Publish events with a single annotation - no boilerplate code required.</p> <pre><code>@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>Benefits:</p> <ul> <li>90% less code compared to manual Kafka usage</li> <li>Type-safe with compile-time validation</li> <li>SpEL support for flexible payload extraction</li> </ul> <p> Learn more</p>"},{"location":"features/overview/#standardized-event-structure","title":"Standardized Event Structure","text":"<p>All events follow CloudEvents-inspired schema:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"ORDER_CREATED\",\n  \"occurredAt\": \"2026-02-03T10:30:00Z\",\n  \"publishedAt\": \"2026-02-03T10:30:00.123Z\",\n  \"severity\": \"INFO\",\n  \"metadata\": {\n    \"source\": { ... },\n    \"actor\": { ... },\n    \"trace\": { ... },\n    \"tags\": { ... }\n  },\n  \"payload\": { ... }\n}\n</code></pre> <p>Metadata includes:</p> <ul> <li>Source: Service name, version, hostname</li> <li>Actor: User ID, session ID, roles</li> <li>Trace: Distributed tracing (trace ID, span ID)</li> <li>Tags: Custom key-value pairs</li> </ul>"},{"location":"features/overview/#3-tier-failure-recovery","title":"3-Tier Failure Recovery","text":"<p>Main Topic \u2192 DLQ \u2192 Local File Backup</p> <p>Zero event loss even when Kafka is completely down.</p> <ol> <li>Primary: Publish to main Kafka topic</li> <li>DLQ: Failed events sent to Dead Letter Queue</li> <li>Backup: If Kafka unavailable, save to local disk</li> </ol> <p> Failure Recovery Guide</p>"},{"location":"features/overview/#automatic-pii-protection","title":"Automatic PII Protection","text":"<p>Annotate sensitive fields and Curve handles the rest:</p> <pre><code>public class UserPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;  // \u2192 \"j***@ex***.com\"\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;  // \u2192 Encrypted with AES-256-GCM\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;   // \u2192 HMAC-SHA256 hashed\n}\n</code></pre> <p> PII Protection Guide</p>"},{"location":"features/overview/#high-performance","title":"High Performance","text":"Mode Throughput Use Case Sync ~500 TPS Strong consistency Async ~10,000+ TPS High throughput Transactional Outbox ~1,000 TPS Atomicity guarantee <p>Async Mode with MDC context propagation:</p> <pre><code>curve:\n  kafka:\n    async-mode: true\n    async-timeout-ms: 5000\n</code></pre>"},{"location":"features/overview/#transactional-outbox-pattern","title":"Transactional Outbox Pattern","text":"<p>Guarantee atomicity between database and event publishing:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>How it works:</p> <ol> <li>Event saved to DB in same transaction</li> <li>Background poller publishes to Kafka</li> <li>Exponential backoff for retries</li> <li><code>SKIP LOCKED</code> prevents duplicate processing</li> </ol> <p> Outbox Pattern Guide</p>"},{"location":"features/overview/#built-in-observability","title":"Built-in Observability","text":""},{"location":"features/overview/#health-checks","title":"Health Checks","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"clusterId\": \"lkc-abc123\",\n    \"nodeCount\": 3,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre>"},{"location":"features/overview/#custom-metrics","title":"Custom Metrics","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\"\n  }\n}\n</code></pre> <p> Observability Guide</p>"},{"location":"features/overview/#architecture","title":"Architecture","text":""},{"location":"features/overview/#hexagonal-architecture-ports-adapters","title":"Hexagonal Architecture (Ports &amp; Adapters)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Domain Layer (Core)         \u2502\n\u2502  \u2022 EventEnvelope, EventMetadata     \u2502\n\u2502  \u2022 Framework-independent            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                \u2502\n        \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Spring   \u2502      \u2502   Kafka    \u2502\n\u2502 (Adapter) \u2502      \u2502 (Adapter)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits:</p> <ul> <li>Framework-independent core</li> <li>Easy to test</li> <li>Extensible (can swap Kafka for RabbitMQ, etc.)</li> </ul>"},{"location":"features/overview/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Quick Start</p> <p>Get up and running in 5 minutes</p> <p> Quick Start</p> </li> <li> <p> PII Protection</p> <p>Protect sensitive data automatically</p> <p> PII Guide</p> </li> <li> <p> Failure Recovery</p> <p>Handle failures gracefully</p> <p> Failure Recovery</p> </li> <li> <p> Configuration</p> <p>Production-ready settings</p> <p> Configuration</p> </li> </ul>"},{"location":"features/pii-protection/","title":"PII Protection","text":"<p>Curve provides automatic PII (Personally Identifiable Information) protection with declarative annotations.</p>"},{"location":"features/pii-protection/#quick-start","title":"Quick Start","text":"<pre><code>import io.github.closeup1202.curve.spring.pii.annotation.PiiField;\nimport io.github.closeup1202.curve.spring.pii.type.PiiType;\nimport io.github.closeup1202.curve.spring.pii.strategy.PiiStrategy;\n\npublic class UserPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;  // \"user@example.com\" \u2192 \"u***@ex***.com\"\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;  // \"+1234567890\" \u2192 \"AES-encrypted\"\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;   // \"John Doe\" \u2192 \"5a4b3c2d...\"\n}\n</code></pre>"},{"location":"features/pii-protection/#how-it-works","title":"How It Works","text":"<pre><code>flowchart LR\n    Obj[Java Object] --&gt;|Jackson Serialize| PII[PII Processor]\n    PII --&gt;|Strategy: MASK| Masked[\"j***@doe.com\"]\n    PII --&gt;|Strategy: ENCRYPT| Encrypted[\"ENC(a8f9...)\"]\n    PII --&gt;|Strategy: HASH| Hashed[\"hmac-sha256(...)\"]\n    Masked --&gt; Json[JSON Output]\n    Encrypted --&gt; Json\n    Hashed --&gt; Json\n</code></pre> <p>Process:</p> <ol> <li>Serialization Interception: Curve intercepts Jackson serialization process.</li> <li>Annotation Detection: Scans for <code>@PiiField</code> annotations on fields.</li> <li>Strategy Execution: Applies the configured strategy (MASK, ENCRYPT, HASH).</li> <li>Output Generation: Replaces the original value with the protected value in the JSON output.</li> </ol>"},{"location":"features/pii-protection/#protection-strategies","title":"Protection Strategies","text":""},{"location":"features/pii-protection/#1-mask-pattern-based-masking","title":"1. MASK - Pattern-Based Masking","text":"<p>Partially hides data while keeping it recognizable.</p> <pre><code>@PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\nprivate String email;\n</code></pre> <p>Examples:</p> PII Type Original Masked EMAIL <code>john.doe@example.com</code> <code>j***@ex***.com</code> PHONE <code>+1-555-123-4567</code> <code>+1-***-***-4567</code> SSN <code>123-45-6789</code> <code>***-**-6789</code> NAME <code>John Michael Doe</code> <code>J*** M*** D***</code> ADDRESS <code>123 Main St, City</code> <code>*** Main St, ***</code> CREDIT_CARD <code>1234-5678-9012-3456</code> <code>****-****-****-3456</code> <p>When to use:</p> <ul> <li>Logs and audit trails</li> <li>Customer support dashboards</li> <li>Non-production environments</li> </ul>"},{"location":"features/pii-protection/#2-encrypt-reversible-encryption","title":"2. ENCRYPT - Reversible Encryption","text":"<p>AES-256-GCM encryption for reversible protection.</p> <pre><code>@PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\nprivate String phone;\n</code></pre> <p>Output:</p> <pre><code>Original: +1-555-123-4567\nEncrypted: AQIDAHj8...9f3a2b1c0 (Base64-encoded)\n</code></pre> <p>When to use:</p> <ul> <li>Data that needs to be decrypted later</li> <li>Cross-service communication</li> <li>Secure storage</li> </ul> <p>Configuration:</p> <pre><code>curve:\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Base64-encoded 32-byte key\n</code></pre> <p>Key Management</p> <p>Store encryption keys in secure vaults (AWS Secrets Manager, HashiCorp Vault, etc.)</p>"},{"location":"features/pii-protection/#3-hash-irreversible-hashing","title":"3. HASH - Irreversible Hashing","text":"<p>HMAC-SHA256 hashing for one-way protection with salt-based keyed hashing.</p> <pre><code>@PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\nprivate String name;\n</code></pre> <p>Output:</p> <pre><code>Original: John Doe\nHashed: 5a4b3c2d1e0f9a8b7c6d5e4f3a2b1c0d...\n</code></pre> <p>When to use:</p> <ul> <li>Analytics and aggregation</li> <li>Deduplication</li> <li>Data that should never be reversed</li> </ul> <p>Configuration:</p> <pre><code>curve:\n  pii:\n    crypto:\n      salt: ${PII_HASH_SALT}  # Add salt for security\n</code></pre>"},{"location":"features/pii-protection/#supported-pii-types","title":"Supported PII Types","text":"PII Type Description Example <code>EMAIL</code> Email addresses john@example.com <code>PHONE</code> Phone numbers +1-555-123-4567 <code>SSN</code> Social Security Numbers 123-45-6789 <code>NAME</code> Full names John Doe <code>ADDRESS</code> Physical addresses 123 Main St <code>CREDIT_CARD</code> Credit card numbers 1234-5678-9012-3456 <code>IP_ADDRESS</code> IP addresses 192.168.1.1 <code>GENERIC</code> Custom sensitive data Any string"},{"location":"features/pii-protection/#configuration","title":"Configuration","text":""},{"location":"features/pii-protection/#enable-pii-protection","title":"Enable PII Protection","text":"application.yml<pre><code>curve:\n  pii:\n    enabled: true  # Default: true\n\n    crypto:\n      # AES-256 encryption key (Base64-encoded 32-byte key)\n      default-key: ${PII_ENCRYPTION_KEY}\n\n      # Salt for hashing (recommended)\n      salt: ${PII_HASH_SALT}\n</code></pre>"},{"location":"features/pii-protection/#environment-variables","title":"Environment Variables","text":".env<pre><code>PII_ENCRYPTION_KEY=K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=  # Base64-encoded 32-byte key\nPII_HASH_SALT=random-salt-for-hashing-123\n</code></pre>"},{"location":"features/pii-protection/#kms-integration","title":"KMS Integration","text":"<p>Curve supports external Key Management Services for enterprise-grade encryption key management.</p>"},{"location":"features/pii-protection/#aws-kms-envelope-encryption","title":"AWS KMS (Envelope Encryption)","text":"application.yml<pre><code>curve:\n  pii:\n    enabled: true\n    kms:\n      enabled: true\n      type: aws\n\n# KMS module configuration\ncurve-kms:\n  aws:\n    key-id: \"arn:aws:kms:us-east-1:123456789:key/abc-123\"\n    region: us-east-1\n    cache-ttl-minutes: 60\n    cache-max-size: 100\n</code></pre> <p>How it works:</p> <ol> <li>AWS KMS generates a Data Encryption Key (DEK)</li> <li>DEK encrypts the PII data locally (AES-256-GCM)</li> <li>Encrypted DEK is stored alongside the ciphertext</li> <li>Decryption requests KMS to decrypt the DEK first</li> </ol>"},{"location":"features/pii-protection/#hashicorp-vault-static-key","title":"HashiCorp Vault (Static Key)","text":"application.yml<pre><code>curve:\n  pii:\n    enabled: true\n    kms:\n      enabled: true\n      type: vault\n\n# KMS module configuration\ncurve-kms:\n  vault:\n    path: \"secret/data/curve/encryption-key\"\n    key-field: \"key\"\n</code></pre> <p>How it works:</p> <ol> <li>Curve fetches the encryption key from Vault K/V secret engine</li> <li>Key is used for local AES-256-GCM encryption</li> <li>Key rotation is handled by updating the Vault secret</li> </ol>"},{"location":"features/pii-protection/#advanced-usage","title":"Advanced Usage","text":""},{"location":"features/pii-protection/#custom-masking-patterns","title":"Custom Masking Patterns","text":"<p>Create custom masking logic:</p> <pre><code>public class CustomMaskingStrategy implements PiiMaskingStrategy {\n\n    @Override\n    public String mask(String value, PiiType type) {\n        // Custom masking logic\n        return maskCustom(value);\n    }\n}\n</code></pre> <p>Register as Spring bean:</p> <pre><code>@Configuration\npublic class PiiConfig {\n\n    @Bean\n    public PiiMaskingStrategy customMaskingStrategy() {\n        return new CustomMaskingStrategy();\n    }\n}\n</code></pre>"},{"location":"features/pii-protection/#conditional-protection","title":"Conditional Protection","text":"<p>Protect fields conditionally based on environment:</p> <pre><code>public class UserPayload {\n\n    @PiiField(\n        type = PiiType.EMAIL,\n        strategy = PiiStrategy.MASK,\n        condition = \"#{environment.getProperty('app.environment') == 'prod'}\"\n    )\n    private String email;\n}\n</code></pre>"},{"location":"features/pii-protection/#best-practices","title":"Best Practices","text":""},{"location":"features/pii-protection/#do","title":"DO","text":"<ul> <li>Use MASK for logs - Keeps data recognizable for debugging</li> <li>Use ENCRYPT for storage - Allows decryption when needed</li> <li>Use HASH for analytics - Irreversible for aggregation</li> <li>Rotate keys regularly - Update encryption keys periodically</li> <li>Store keys securely - Use secret management services</li> </ul>"},{"location":"features/pii-protection/#dont","title":"DON'T","text":"<ul> <li>Store encryption keys in source code</li> <li>Use HASH when you need to decrypt later</li> <li>Over-mask data (e.g., masking non-sensitive fields)</li> <li>Use weak keys (must be exactly 32 bytes, Base64-encoded)</li> </ul>"},{"location":"features/pii-protection/#compliance","title":"Compliance","text":"<p>Curve's PII protection helps with:</p> <ul> <li>GDPR (General Data Protection Regulation)</li> <li>CCPA (California Consumer Privacy Act)</li> <li>HIPAA (Health Insurance Portability and Accountability Act)</li> <li>PCI DSS (Payment Card Industry Data Security Standard)</li> </ul> <p>Legal Disclaimer</p> <p>Curve provides tools for PII protection, but compliance is the responsibility of the application owner.</p>"},{"location":"features/pii-protection/#examples","title":"Examples","text":""},{"location":"features/pii-protection/#complete-user-event","title":"Complete User Event","text":"<pre><code>public class UserRegisteredPayload implements DomainEventPayload {\n\n    private Long userId;\n    private String username;  // Not sensitive\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String firstName;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String lastName;\n\n    @PiiField(type = PiiType.ADDRESS, strategy = PiiStrategy.MASK)\n    private String address;\n\n    @PiiField(type = PiiType.IP_ADDRESS, strategy = PiiStrategy.HASH)\n    private String lastLoginIp;\n\n    private Instant createdAt;\n}\n</code></pre> <p>Published Event:</p> <pre><code>{\n  \"userId\": 12345,\n  \"username\": \"john_doe\",\n  \"email\": \"j***@ex***.com\",\n  \"phone\": \"AQIDAHj8...9f3a2b1c0\",\n  \"firstName\": \"5a4b3c2d...\",\n  \"lastName\": \"7f8e9d1a...\",\n  \"address\": \"*** Main St, ***\",\n  \"lastLoginIp\": \"8f7e6d5c...\",\n  \"createdAt\": \"2026-02-03T10:30:00Z\"\n}\n</code></pre>"},{"location":"features/pii-protection/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Failure Recovery</p> <p>Handle failures with DLQ</p> <p> Failure Recovery</p> </li> <li> <p> Transactional Outbox</p> <p>Guarantee event delivery</p> <p> Outbox Pattern</p> </li> </ul>"},{"location":"features/transactional-outbox/","title":"Transactional Outbox Pattern","text":"<p>Guarantee atomicity between database transactions and event publishing with Curve's transactional outbox pattern.</p>"},{"location":"features/transactional-outbox/#the-problem","title":"The Problem","text":"<p>Without transactional outbox:</p> <pre><code>@Transactional\npublic Order createOrder(OrderRequest request) {\n    // 1. Save to database\n    Order order = orderRepository.save(new Order(request));\n\n    // 2. Publish to Kafka\n    kafkaProducer.send(\"orders\", orderEvent);  // \u274c What if this fails?\n\n    return order;\n}\n</code></pre> <p>Issues:</p> <ul> <li>Order saved but event not published \u2192 Lost event</li> <li>Event published but transaction rolled back \u2192 Ghost event</li> <li>No atomicity between DB and Kafka</li> </ul>"},{"location":"features/transactional-outbox/#the-solution","title":"The Solution","text":"<p>Transactional outbox saves events to the database in the same transaction:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,                    // \u2713 Enable outbox\n    aggregateType = \"Order\",          // Entity type\n    aggregateId = \"#result.id\"        // Entity ID\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre>"},{"location":"features/transactional-outbox/#how-it-works","title":"How It Works","text":"<pre><code>sequenceDiagram\n    participant App as Application\n    participant DB as Database (Outbox)\n    participant Kafka as Kafka Broker\n    participant Poller as Outbox Publisher\n\n    Note over App, DB: Transaction Start\n    App-&gt;&gt;DB: 1. Save Business Entity (Order)\n    App-&gt;&gt;DB: 2. Save Outbox Event (PENDING)\n    DB--&gt;&gt;App: TX Committed \u2713\n\n    loop Every 1s (Polling)\n        Poller-&gt;&gt;DB: 3. Fetch PENDING Events\n        Poller-&gt;&gt;Kafka: 4. Publish to Kafka\n        alt Success\n            Kafka--&gt;&gt;Poller: Ack\n            Poller-&gt;&gt;DB: 5. Update Status to PUBLISHED\n        else Failure\n            Poller-&gt;&gt;DB: 5. Increment Retry Count\n        end\n    end\n</code></pre> <p>Steps:</p> <ol> <li>Save entity and event in same transaction - Atomicity guaranteed</li> <li>Background poller - Periodically checks for unsent events</li> <li>Publish to Kafka - Events sent asynchronously</li> <li>Mark as sent - Successful events marked complete</li> </ol>"},{"location":"features/transactional-outbox/#configuration","title":"Configuration","text":""},{"location":"features/transactional-outbox/#enable-outbox","title":"Enable Outbox","text":"application.yml<pre><code>spring:\n  datasource:\n    url: jdbc:postgresql://localhost:5432/mydb\n    username: user\n    password: pass\n\n  jpa:\n    hibernate:\n      ddl-auto: update  # Or use Flyway/Liquibase\n\ncurve:\n  outbox:\n    enabled: true\n    poll-interval-ms: 1000      # Poll every 1 second\n    batch-size: 100             # Process 100 events per batch\n    max-retries: 3              # Retry failed events 3 times\n    cleanup-enabled: true       # Auto-cleanup old events\n    retention-days: 7           # Keep events for 7 days\n    cleanup-cron: \"0 0 2 * * *\" # Cleanup at 2 AM daily\n</code></pre>"},{"location":"features/transactional-outbox/#database-schema","title":"Database Schema","text":"<p>Curve auto-creates the outbox table:</p> <pre><code>CREATE TABLE curve_outbox_events (\n    id BIGINT PRIMARY KEY,\n    event_id VARCHAR(255) NOT NULL,\n    event_type VARCHAR(255) NOT NULL,\n    aggregate_type VARCHAR(255) NOT NULL,\n    aggregate_id VARCHAR(255) NOT NULL,\n    payload TEXT NOT NULL,\n    metadata TEXT,\n    status VARCHAR(50) NOT NULL,  -- PENDING, SENT, FAILED\n    retry_count INT DEFAULT 0,\n    last_retry_at TIMESTAMP,\n    created_at TIMESTAMP NOT NULL,\n    sent_at TIMESTAMP,\n    error_message TEXT\n);\n\nCREATE INDEX idx_status ON curve_outbox_events(status);\nCREATE INDEX idx_created_at ON curve_outbox_events(created_at);\n</code></pre>"},{"location":"features/transactional-outbox/#usage-examples","title":"Usage Examples","text":""},{"location":"features/transactional-outbox/#basic-outbox","title":"Basic Outbox","text":"<pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre>"},{"location":"features/transactional-outbox/#with-custom-payload","title":"With Custom Payload","text":"<pre><code>@Transactional\n@PublishEvent(\n    eventType = \"USER_REGISTERED\",\n    outbox = true,\n    aggregateType = \"User\",\n    aggregateId = \"#result.userId\",\n    payload = \"#result.toRegisteredPayload()\"\n)\npublic User registerUser(UserRequest request) {\n    User user = userRepository.save(new User(request));\n\n    // Other operations in same transaction\n    auditRepository.save(new AuditLog(\"User registered\"));\n\n    return user;\n}\n</code></pre>"},{"location":"features/transactional-outbox/#complex-transaction","title":"Complex Transaction","text":"<pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_COMPLETED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order completeOrder(Long orderId) {\n    // 1. Update order\n    Order order = orderRepository.findById(orderId)\n        .orElseThrow();\n    order.setStatus(OrderStatus.COMPLETED);\n    order.setCompletedAt(Instant.now());\n\n    // 2. Update inventory\n    inventoryService.decrementStock(order.getItems());\n\n    // 3. Create invoice\n    Invoice invoice = invoiceService.create(order);\n\n    // All operations atomic - event published after TX commits\n    return orderRepository.save(order);\n}\n</code></pre>"},{"location":"features/transactional-outbox/#advanced-features","title":"Advanced Features","text":""},{"location":"features/transactional-outbox/#exponential-backoff","title":"Exponential Backoff","text":"<p>Failed events are retried with exponential backoff:</p> <pre><code>Retry 1: Immediate\nRetry 2: 2 seconds later\nRetry 3: 4 seconds later  (2s \u00d7 2)\nRetry 4: 8 seconds later  (4s \u00d7 2)\n</code></pre>"},{"location":"features/transactional-outbox/#skip-locked-for-multi-instance","title":"SKIP LOCKED for Multi-Instance","text":"<p>Prevents duplicate processing in multi-instance deployments:</p> <pre><code>SELECT * FROM curve_outbox_events\nWHERE status = 'PENDING'\nORDER BY created_at\nLIMIT 100\nFOR UPDATE SKIP LOCKED;  -- Prevents duplicates\n</code></pre>"},{"location":"features/transactional-outbox/#automatic-cleanup","title":"Automatic Cleanup","text":"<p>Old events are automatically cleaned up:</p> <pre><code>curve:\n  outbox:\n    cleanup-enabled: true\n    retention-days: 7           # Delete events older than 7 days\n    cleanup-cron: \"0 0 2 * * *\" # Daily at 2 AM\n</code></pre>"},{"location":"features/transactional-outbox/#monitoring","title":"Monitoring","text":""},{"location":"features/transactional-outbox/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8080/actuator/health/curve-outbox\n</code></pre> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"pendingEvents\": 5,\n    \"failedEvents\": 2,\n    \"totalEvents\": 1523\n  }\n}\n</code></pre>"},{"location":"features/transactional-outbox/#metrics","title":"Metrics","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"outbox\": {\n    \"pendingEvents\": 5,\n    \"sentEvents\": 1518,\n    \"failedEvents\": 2,\n    \"avgProcessingTimeMs\": 45\n  }\n}\n</code></pre>"},{"location":"features/transactional-outbox/#query-outbox-table","title":"Query Outbox Table","text":"<pre><code>-- Pending events\nSELECT * FROM curve_outbox_events\nWHERE status = 'PENDING'\nORDER BY created_at DESC;\n\n-- Failed events\nSELECT event_type, error_message, retry_count\nFROM curve_outbox_events\nWHERE status = 'FAILED'\nORDER BY created_at DESC;\n\n-- Event throughput\nSELECT DATE(created_at) as date, COUNT(*)\nFROM curve_outbox_events\nWHERE status = 'SENT'\nGROUP BY DATE(created_at)\nORDER BY date DESC;\n</code></pre>"},{"location":"features/transactional-outbox/#best-practices","title":"Best Practices","text":""},{"location":"features/transactional-outbox/#do","title":"DO","text":"<ul> <li>Use outbox for critical events - Order creation, payments, etc.</li> <li>Monitor pending events - Alert if queue grows</li> <li>Set appropriate retention - Balance storage and auditability</li> <li>Use database indexes - Optimize poller queries</li> <li>Test failure scenarios - Ensure recovery works</li> </ul>"},{"location":"features/transactional-outbox/#dont","title":"DON'T","text":"<ul> <li>Use outbox for high-volume events (&gt;10,000/sec)</li> <li>Set poll interval too low (&lt;500ms)</li> <li>Disable cleanup in production</li> <li>Ignore failed events</li> </ul>"},{"location":"features/transactional-outbox/#performance-considerations","title":"Performance Considerations","text":"Factor Impact Recommendation Poll Interval Lower = faster, higher DB load 1000ms for most cases Batch Size Larger = more throughput 100-500 events Retention Longer = more storage 7-30 days Indexes Essential for performance On status, created_at"},{"location":"features/transactional-outbox/#throughput-estimates","title":"Throughput Estimates","text":"Configuration Throughput Poll: 1s, Batch: 100 ~100 events/sec Poll: 500ms, Batch: 200 ~400 events/sec Poll: 1s, Batch: 500 ~500 events/sec <p>High Throughput</p> <p>For &gt;1,000 events/sec, use async mode without outbox:</p> <pre><code>curve:\n  kafka:\n    async-mode: true\n</code></pre>"},{"location":"features/transactional-outbox/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/transactional-outbox/#events-stuck-in-pending","title":"Events Stuck in PENDING","text":"<p>Events not being published</p> <p>Check:</p> <ol> <li>Outbox poller is running: <code>logging.level.io.github.closeup1202.curve.outbox=DEBUG</code></li> <li>Kafka is accessible</li> <li>No DB connection pool exhaustion</li> </ol>"},{"location":"features/transactional-outbox/#high-failed-event-count","title":"High Failed Event Count","text":"<p>Many events in FAILED status</p> <p>Solutions:</p> <ol> <li>Check Kafka connectivity</li> <li>Increase <code>max-retries</code></li> <li>Analyze <code>error_message</code> column</li> <li>Manual republish:</li> </ol> <pre><code>UPDATE curve_outbox_events\nSET status = 'PENDING', retry_count = 0\nWHERE status = 'FAILED'\n  AND created_at &gt; NOW() - INTERVAL '1 hour';\n</code></pre>"},{"location":"features/transactional-outbox/#comparison-outbox-vs-async","title":"Comparison: Outbox vs Async","text":"Feature Outbox Async Atomicity \u2705 Guaranteed \u274c Best-effort Throughput ~1,000 TPS ~10,000+ TPS Latency ~1-2 seconds &lt;100ms Storage DB required No extra storage Complexity Medium Low <p>Use outbox when:</p> <ul> <li>Atomicity is critical (payments, orders)</li> <li>Events must not be lost</li> <li>Moderate throughput (&lt;1,000 TPS)</li> </ul> <p>Use async when:</p> <ul> <li>High throughput needed</li> <li>Best-effort delivery acceptable</li> <li>Low latency required</li> </ul>"},{"location":"features/transactional-outbox/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Observability</p> <p>Monitor your events</p> <p> Observability</p> </li> <li> <p> Configuration</p> <p>Advanced configuration options</p> <p> Configuration</p> </li> </ul>"},{"location":"getting-started/first-event/","title":"Your First Event","text":"<p>This tutorial walks you through creating a complete event publishing setup with Curve.</p>"},{"location":"getting-started/first-event/#scenario","title":"Scenario","text":"<p>We'll build a user registration system that publishes a <code>USER_REGISTERED</code> event to Kafka.</p>"},{"location":"getting-started/first-event/#step-1-define-your-domain-model","title":"Step 1: Define Your Domain Model","text":"User.java<pre><code>public class User {\n    private Long id;\n    private String username;\n    private String email;\n    private String firstName;\n    private String lastName;\n    private Instant createdAt;\n\n    // getters, setters, constructors\n}\n</code></pre> UserRequest.java<pre><code>public record UserRequest(\n    String username,\n    String email,\n    String firstName,\n    String lastName\n) {}\n</code></pre>"},{"location":"getting-started/first-event/#step-2-create-event-payload","title":"Step 2: Create Event Payload","text":"<p>Create a payload class that implements <code>DomainEventPayload</code>:</p> UserRegisteredPayload.java<pre><code>import io.github.closeup1202.curve.core.envelope.DomainEventPayload;\nimport io.github.closeup1202.curve.spring.pii.annotation.PiiField;\nimport io.github.closeup1202.curve.spring.pii.type.PiiType;\nimport io.github.closeup1202.curve.spring.pii.strategy.PiiStrategy;\n\npublic class UserRegisteredPayload implements DomainEventPayload {\n\n    private Long userId;\n    private String username;\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String firstName;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String lastName;\n\n    private Instant registeredAt;\n\n    // Constructor\n    public UserRegisteredPayload(User user) {\n        this.userId = user.getId();\n        this.username = user.getUsername();\n        this.email = user.getEmail();\n        this.firstName = user.getFirstName();\n        this.lastName = user.getLastName();\n        this.registeredAt = user.getCreatedAt();\n    }\n\n    // Getters\n    // ...\n}\n</code></pre> <p>PII Protection</p> <p>The <code>@PiiField</code> annotation automatically masks/hashes sensitive data before publishing.</p>"},{"location":"getting-started/first-event/#step-3-implement-service-with-publishevent","title":"Step 3: Implement Service with @PublishEvent","text":"UserService.java<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\nimport io.github.closeup1202.curve.core.type.EventSeverity;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\n@Service\npublic class UserService {\n\n    private final UserRepository userRepository;\n\n    public UserService(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n\n    @Transactional\n    @PublishEvent(\n        eventType = \"USER_REGISTERED\",\n        severity = EventSeverity.INFO,\n        payload = \"#result.toEventPayload()\"\n    )\n    public User registerUser(UserRequest request) {\n        // Business logic\n        User user = new User();\n        user.setUsername(request.username());\n        user.setEmail(request.email());\n        user.setFirstName(request.firstName());\n        user.setLastName(request.lastName());\n        user.setCreatedAt(Instant.now());\n\n        return userRepository.save(user);\n    }\n}\n</code></pre>"},{"location":"getting-started/first-event/#annotation-breakdown","title":"Annotation Breakdown","text":"Parameter Value Description <code>eventType</code> <code>\"USER_REGISTERED\"</code> Unique identifier for this event type <code>severity</code> <code>EventSeverity.INFO</code> Event severity level <code>payload</code> SpEL expression Extracts data from method result <p>SpEL Expressions</p> <ul> <li><code>#result</code> - Method return value</li> <li><code>#args[0]</code> - First method argument</li> <li><code>#args[0].toEventDto()</code> - Custom transformation</li> </ul>"},{"location":"getting-started/first-event/#step-4-configure-application","title":"Step 4: Configure Application","text":"application.yml<pre><code>spring:\n  application:\n    name: user-service\n    version: 1.0.0\n\n  kafka:\n    bootstrap-servers: localhost:9092\n\n  jpa:\n    hibernate:\n      ddl-auto: update\n\ncurve:\n  enabled: true\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # Synchronous for reliability\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Base64-encoded 32-byte key\n</code></pre>"},{"location":"getting-started/first-event/#step-5-test-your-event","title":"Step 5: Test Your Event","text":""},{"location":"getting-started/first-event/#unit-test-with-mockeventproducer","title":"Unit Test with MockEventProducer","text":"UserServiceTest.java<pre><code>import io.github.closeup1202.curve.spring.test.MockEventProducer;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context;\n\n@SpringBootTest\nclass UserServiceTest {\n\n    @Autowired\n    private UserService userService;\n\n    @Autowired\n    private MockEventProducer mockEventProducer;\n\n    @Test\n    void shouldPublishEventWhenUserRegisters() {\n        // Given\n        UserRequest request = new UserRequest(\n            \"john_doe\",\n            \"john@example.com\",\n            \"John\",\n            \"Doe\"\n        );\n\n        // When\n        User user = userService.registerUser(request);\n\n        // Then\n        assertThat(user.getId()).isNotNull();\n\n        // Verify event was published\n        var events = mockEventProducer.getPublishedEvents();\n        assertThat(events).hasSize(1);\n\n        var event = events.get(0);\n        assertThat(event.getEventType()).isEqualTo(\"USER_REGISTERED\");\n        assertThat(event.getSeverity()).isEqualTo(EventSeverity.INFO);\n    }\n}\n</code></pre>"},{"location":"getting-started/first-event/#integration-test-with-kafka","title":"Integration Test with Kafka","text":"UserServiceIntegrationTest.java<pre><code>import org.springframework.kafka.test.context.EmbeddedKafka;\nimport org.springframework.test.context.TestPropertySource;\n\n@SpringBootTest\n@EmbeddedKafka(partitions = 1, topics = {\"event.audit.v1\"})\n@TestPropertySource(properties = {\n    \"spring.kafka.bootstrap-servers=${spring.embedded.kafka.brokers}\",\n    \"curve.enabled=true\"\n})\nclass UserServiceIntegrationTest {\n\n    @Autowired\n    private UserService userService;\n\n    @Autowired\n    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;\n\n    @Test\n    void shouldPublishToKafkaWhenUserRegisters() throws Exception {\n        // Setup consumer\n        CountDownLatch latch = new CountDownLatch(1);\n        AtomicReference&lt;String&gt; receivedEvent = new AtomicReference&lt;&gt;();\n\n        // Consume from Kafka\n        // ... (consumer setup)\n\n        // When\n        userService.registerUser(new UserRequest(\n            \"test_user\", \"test@example.com\", \"Test\", \"User\"\n        ));\n\n        // Then\n        assertThat(latch.await(5, TimeUnit.SECONDS)).isTrue();\n        assertThat(receivedEvent.get()).contains(\"USER_REGISTERED\");\n    }\n}\n</code></pre>"},{"location":"getting-started/first-event/#step-6-verify-in-kafka","title":"Step 6: Verify in Kafka","text":"<p>Start your application and register a user:</p> <pre><code>curl -X POST http://localhost:8080/api/users \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"john_doe\",\n    \"email\": \"john@example.com\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Doe\"\n  }'\n</code></pre> <p>Check the Kafka topic:</p> <pre><code>kafka-console-consumer --bootstrap-server localhost:9092 \\\n    --topic event.audit.v1 --from-beginning\n</code></pre> <p>Published event:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"USER_REGISTERED\",\n  \"occurredAt\": \"2026-02-03T10:30:00Z\",\n  \"publishedAt\": \"2026-02-03T10:30:00.123Z\",\n  \"severity\": \"INFO\",\n  \"metadata\": {\n    \"source\": {\n      \"serviceName\": \"user-service\",\n      \"serviceVersion\": \"1.0.0\"\n    },\n    \"trace\": {\n      \"traceId\": \"abc123\"\n    }\n  },\n  \"payload\": {\n    \"userId\": 1,\n    \"username\": \"john_doe\",\n    \"email\": \"j***@ex***.com\",  // \u2190 Masked!\n    \"firstName\": \"5a4b3c...\",    // \u2190 Hashed!\n    \"lastName\": \"7f8e9d...\",     // \u2190 Hashed!\n    \"registeredAt\": \"2026-02-03T10:30:00Z\"\n  }\n}\n</code></pre> <p>Notice</p> <p>PII fields are automatically protected based on <code>@PiiField</code> annotations!</p>"},{"location":"getting-started/first-event/#next-steps","title":"Next Steps","text":"<ul> <li> <p> PII Protection</p> <p>Learn more about data masking strategies</p> <p> PII Guide</p> </li> <li> <p> Transactional Outbox</p> <p>Guarantee atomicity between DB and events</p> <p> Outbox Pattern</p> </li> <li> <p> Failure Recovery</p> <p>Handle failures with DLQ and backups</p> <p> Failure Recovery</p> </li> <li> <p> Monitoring</p> <p>Set up metrics and health checks</p> <p> Observability</p> </li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"Component Version Java 17 or higher Spring Boot 3.0+ Apache Kafka 2.8+ (3.0+ recommended) Build Tool Gradle 7+ or Maven 3.6+"},{"location":"getting-started/installation/#dependency-installation","title":"Dependency Installation","text":""},{"location":"getting-started/installation/#gradle","title":"Gradle","text":"<p>Add to your <code>build.gradle</code>:</p> build.gradle<pre><code>repositories {\n    mavenCentral()\n}\n\ndependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'\n}\n</code></pre>"},{"location":"getting-started/installation/#maven","title":"Maven","text":"<p>Add to your <code>pom.xml</code>:</p> pom.xml<pre><code>&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n        &lt;artifactId&gt;curve&lt;/artifactId&gt;\n        &lt;version&gt;0.1.2&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"getting-started/installation/#avro-serialization","title":"Avro Serialization","text":"<p>If you want to use Avro serialization (<code>serde.type: AVRO</code>), add:</p> GradleMaven build.gradle<pre><code>repositories {\n    mavenCentral()\n    maven { url 'https://packages.confluent.io/maven/' }\n}\n\ndependencies {\n    implementation 'org.apache.avro:avro:1.11.4'\n    implementation 'io.confluent:kafka-avro-serializer:8.1.1'\n}\n</code></pre> pom.xml<pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;confluent&lt;/id&gt;\n        &lt;url&gt;https://packages.confluent.io/maven/&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n        &lt;artifactId&gt;avro&lt;/artifactId&gt;\n        &lt;version&gt;1.11.4&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.confluent&lt;/groupId&gt;\n        &lt;artifactId&gt;kafka-avro-serializer&lt;/artifactId&gt;\n        &lt;version&gt;7.5.0&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> <p>JSON by Default</p> <p>Curve uses JSON serialization by default, which requires no additional dependencies.</p>"},{"location":"getting-started/installation/#database-for-transactional-outbox","title":"Database for Transactional Outbox","text":"<p>If using the transactional outbox pattern, ensure you have a JPA-compatible database:</p> <pre><code>// Example: PostgreSQL\nimplementation 'org.springframework.boot:spring-boot-starter-data-jpa'\nruntimeOnly 'org.postgresql:postgresql'\n</code></pre>"},{"location":"getting-started/installation/#version-compatibility","title":"Version Compatibility","text":"Curve Version Spring Boot Kafka Client Java 0.1.2 3.5.x 3.8.x 17+ 0.1.2 3.5.x 3.8.x 17+ 0.1.0 3.5.x 3.8.x 17+ 0.0.5 3.5.x 3.8.x 17+ 0.0.2 3.5.x 3.8.x 17+ 0.0.1 3.4.x 3.7.x 17+"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After adding the dependency, verify Curve is correctly installed:</p>"},{"location":"getting-started/installation/#1-build-your-project","title":"1. Build Your Project","text":"GradleMaven <pre><code>./gradlew clean build\n</code></pre> <pre><code>./mvnw clean install\n</code></pre>"},{"location":"getting-started/installation/#2-check-auto-configuration","title":"2. Check Auto-Configuration","text":"<p>Enable debug logging to see if Curve auto-configuration is loaded:</p> application.yml<pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n</code></pre> <p>Start your application and look for:</p> <pre><code>CurveAutoConfiguration matched:\n   - @ConditionalOnProperty (curve.enabled=true) matched\n</code></pre>"},{"location":"getting-started/installation/#3-test-health-endpoint","title":"3. Test Health Endpoint","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"clusterId\": \"lkc-abc123\",\n    \"nodeCount\": 3,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#dependency-resolution-fails","title":"Dependency Resolution Fails","text":"<p>Error: Could not find io.github.closeup1202:curve:0.1.2</p> <p>Solution: Ensure Maven Central is in your repositories:</p> GradleMaven <pre><code>repositories {\n    mavenCentral()\n}\n</code></pre> <p>Maven includes Central by default. Try:</p> <pre><code>./mvnw dependency:purge-local-repository\n</code></pre>"},{"location":"getting-started/installation/#auto-configuration-not-loading","title":"Auto-Configuration Not Loading","text":"<p>Curve features not working</p> <p>Check:</p> <ol> <li>Spring Boot version is 3.0+</li> <li><code>curve.enabled=true</code> in application.yml</li> <li>No conflicting auto-configurations</li> </ol>"},{"location":"getting-started/installation/#kafka-client-version-conflict","title":"Kafka Client Version Conflict","text":"<p>ClassNotFoundException or MethodNotFoundException</p> <p>Solution: Align Kafka client versions:</p> <pre><code>dependencies {\n    implementation('io.github.closeup1202:curve:0.1.2') {\n        exclude group: 'org.apache.kafka'\n    }\n    implementation 'org.apache.kafka:kafka-clients:3.8.0'\n}\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, proceed to:</p> <ol> <li>Quick Start Guide - Create your first event</li> <li>Configuration - Set up production settings</li> <li>First Event Tutorial - Detailed walkthrough</li> </ol> <p>Need Help?</p> <p>If you encounter issues, check the Troubleshooting Guide or open an issue.</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get Curve up and running in your Spring Boot application in under 5 minutes.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Java 17 or higher</li> <li>Spring Boot 3.x</li> <li>Apache Kafka (or Docker)</li> </ul>"},{"location":"getting-started/quick-start/#step-1-add-dependency","title":"Step 1: Add Dependency","text":"<p>Add Curve to your project:</p> GradleMaven build.gradle<pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'\n}\n</code></pre> pom.xml<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.1.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"getting-started/quick-start/#step-2-configure-kafka","title":"Step 2: Configure Kafka","text":"<p>Add Kafka configuration to your <code>application.yml</code>:</p> application.yml<pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9092\n\ncurve:\n  enabled: true\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n</code></pre> <p>Local Kafka Setup</p> <p>Don't have Kafka running? Use Docker Compose:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"getting-started/quick-start/#step-3-publish-your-first-event","title":"Step 3: Publish Your First Event","text":"<p>Add the <code>@PublishEvent</code> annotation to any service method:</p> OrderService.java<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\nimport io.github.closeup1202.curve.core.type.EventSeverity;\nimport org.springframework.stereotype.Service;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(\n        eventType = \"ORDER_CREATED\",\n        severity = EventSeverity.INFO\n    )\n    public Order createOrder(OrderRequest request) {\n        // Your business logic\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre>"},{"location":"getting-started/quick-start/#step-4-verify","title":"Step 4: Verify","text":"<p>Start your application and create an order. Check the Kafka topic:</p> <pre><code># View events in Kafka\nkafka-console-consumer --bootstrap-server localhost:9092 \\\n    --topic event.audit.v1 --from-beginning\n</code></pre> <p>Expected output:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"ORDER_CREATED\",\n  \"occurredAt\": \"2026-02-03T10:30:00Z\",\n  \"publishedAt\": \"2026-02-03T10:30:00.123Z\",\n  \"severity\": \"INFO\",\n  \"metadata\": {\n    \"source\": {\n      \"serviceName\": \"order-service\",\n      \"serviceVersion\": \"1.0.0\",\n      \"hostname\": \"localhost\"\n    },\n    \"actor\": {\n      \"userId\": \"user123\",\n      \"sessionId\": \"session-abc\"\n    },\n    \"trace\": {\n      \"traceId\": \"trace-xyz\",\n      \"spanId\": \"span-123\"\n    }\n  },\n  \"payload\": {\n    \"orderId\": 12345,\n    \"customerId\": \"CUST-001\",\n    \"amount\": 99.99\n  }\n}\n</code></pre>"},{"location":"getting-started/quick-start/#step-5-monitor-optional","title":"Step 5: Monitor (Optional)","text":"<p>Check health and metrics:</p> <pre><code># Health check\ncurl http://localhost:8080/actuator/health/curve\n\n# Metrics\ncurl http://localhost:8080/actuator/curve-metrics\n</code></pre>"},{"location":"getting-started/quick-start/#success","title":"Success!","text":"<p>You've successfully published your first event with Curve!</p>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Learn Features</p> <p>Explore PII protection, DLQ, and observability</p> <p> Features</p> </li> <li> <p> Advanced Configuration</p> <p>Production-ready settings and optimization</p> <p> Configuration</p> </li> <li> <p> API Reference</p> <p>Detailed annotation and property reference</p> <p> API Docs</p> </li> <li> <p> Need Help?</p> <p>Troubleshooting and FAQ</p> <p> Troubleshooting</p> </li> </ul>"},{"location":"getting-started/quick-start/#common-issues","title":"Common Issues","text":"<p>Kafka Connection Failed</p> <p>If you see <code>Connection to node -1 could not be established</code>, ensure Kafka is running:</p> <pre><code>docker-compose ps\n</code></pre> <p>Events Not Publishing</p> <ol> <li>Check <code>curve.enabled=true</code> in application.yml</li> <li>Verify Kafka bootstrap servers</li> <li>Check logs for errors</li> </ol> <p>See Troubleshooting Guide for more solutions.</p>"},{"location":"ko/","title":"Home","text":"# Curve  **Spring Boot \ub9c8\uc774\ud06c\ub85c\uc11c\ube44\uc2a4\ub97c \uc704\ud55c \uc120\uc5b8\uc801 \uc774\ubca4\ud2b8 \ubc1c\ud589 \ub77c\uc774\ube0c\ub7ec\ub9ac**  [![Java](https://img.shields.io/badge/Java-17-orange.svg)](https://openjdk.java.net/) [![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.5.9-brightgreen.svg)](https://spring.io/projects/spring-boot) [![Kafka](https://img.shields.io/badge/Apache%20Kafka-3.0+-red.svg)](https://kafka.apache.org/) [![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE) [![CI](https://github.com/closeup1202/curve/actions/workflows/ci.yml/badge.svg)](https://github.com/closeup1202/curve/actions) [![codecov](https://codecov.io/gh/closeup1202/curve/branch/main/graph/badge.svg)](https://codecov.io/gh/closeup1202/curve) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=curve&amp;metric=alert_status)](https://sonarcloud.io/dashboard?id=curve)  [English](index.md) | [\ud55c\uad6d\uc5b4](index.ko.md)"},{"location":"ko/#_1","title":"\ud83c\udfac \ube60\ub978 \ub370\ubaa8","text":"<pre><code>// \uc5b4\ub178\ud14c\uc774\uc158 \ud558\ub098\ub9cc \ucd94\uac00\ud558\uba74 \ub05d!\n@PublishEvent(eventType = \"USER_CREATED\")\npublic User createUser(CreateUserRequest request) {\n    return userRepository.save(new User(request));\n}\n</code></pre> <p>\u2192 Kafka \uc790\ub3d9 \ubc1c\ud589 + PII \ub9c8\uc2a4\ud0b9 + \uc2e4\ud328 \uc2dc DLQ + \uba54\ud2b8\ub9ad \uc218\uc9d1 \u2728</p>"},{"location":"ko/#curve","title":"\ud83d\udd25 \uc65c Curve\uc778\uac00?","text":"### Before (\uae30\uc874 \ubc29\uc2dd) <pre><code>// 50\uc904 \uc774\uc0c1\uc758 \ubcf4\uc77c\ub7ec\ud50c\ub808\uc774\ud2b8 \ucf54\ub4dc\n@Service\npublic class UserService {\n\n    @Autowired\n    private KafkaTemplate&lt;String, Object&gt; kafka;\n\n    @Autowired\n    private ObjectMapper objectMapper;\n\n    public User createUser(UserRequest request) {\n        User user = userRepository.save(\n            new User(request)\n        );\n\n        try {\n            // \uc218\ub3d9\uc73c\ub85c \uc774\ubca4\ud2b8 \uc0dd\uc131\n            EventEnvelope event = EventEnvelope.builder()\n                .eventId(UUID.randomUUID().toString())\n                .eventType(\"USER_CREATED\")\n                .occurredAt(Instant.now())\n                .publishedAt(Instant.now())\n                .metadata(/* ... */)\n                .payload(/* ... */)\n                .build();\n\n            // \uc218\ub3d9\uc73c\ub85c PII \ub9c8\uc2a4\ud0b9\n            String json = maskPii(\n                objectMapper.writeValueAsString(event)\n            );\n\n            // \uc218\ub3d9\uc73c\ub85c Kafka \uc804\uc1a1 \ubc0f \uc7ac\uc2dc\ub3c4\n            kafka.send(\"user-events\", json)\n                .get(30, TimeUnit.SECONDS);\n\n        } catch (Exception e) {\n            // \uc218\ub3d9\uc73c\ub85c \uc5d0\ub7ec \ucc98\ub9ac\n            log.error(\"Failed to publish event\", e);\n            sendToDlq(event);\n        }\n\n        return user;\n    }\n}\n</code></pre>   ### After (Curve) <pre><code>// \uc5b4\ub178\ud14c\uc774\uc158 \ud558\ub098\ub9cc!\n@Service\npublic class UserService {\n\n    @PublishEvent(eventType = \"USER_CREATED\")\n    public User createUser(UserRequest request) {\n        return userRepository.save(\n            new User(request)\n        );\n    }\n}\n</code></pre>  **\ucf54\ub4dc 90% \uac10\uc18c** \u2728  \ubaa8\ub4e0 \uac83\uc774 \uc790\ub3d9\uc73c\ub85c \ucc98\ub9ac\ub429\ub2c8\ub2e4: - \u2705 \uc774\ubca4\ud2b8 ID \uc0dd\uc131 - \u2705 \uba54\ud0c0\ub370\uc774\ud130 \ucd94\ucd9c - \u2705 PII \ub9c8\uc2a4\ud0b9 - \u2705 Kafka \ubc1c\ud589 - \u2705 \uc7ac\uc2dc\ub3c4 &amp; DLQ - \u2705 \uba54\ud2b8\ub9ad \uc218\uc9d1"},{"location":"ko/#_2","title":"\u2728 \uc8fc\uc694 \uae30\ub2a5","text":""},{"location":"ko/#_3","title":"\ud83c\udfaf \uc120\uc5b8\uc801 \uc774\ubca4\ud2b8 \ubc1c\ud589","text":"<p>Kafka \ubcf4\uc77c\ub7ec\ud50c\ub808\uc774\ud2b8 \ucf54\ub4dc \ubd88\ud544\uc694 - <code>@PublishEvent</code> \uc5b4\ub178\ud14c\uc774\uc158\ub9cc \ucd94\uac00. SpEL\uc744 \ud1b5\ud55c \uc720\uc5f0\ud55c \ud398\uc774\ub85c\ub4dc \ucd94\ucd9c \uc9c0\uc6d0.</p>"},{"location":"ko/#_4","title":"\ud83d\udce6 \ud45c\uc900\ud654\ub41c \uc774\ubca4\ud2b8 \uad6c\uc870","text":"<p>\ubaa8\ub4e0 \uc774\ubca4\ud2b8\uac00 \uba54\ud0c0\ub370\uc774\ud130(source, actor, trace, tags)\ub97c \ud3ec\ud568\ud55c \ud1b5\uc77c\ub41c \uc2a4\ud0a4\ub9c8 \uc0ac\uc6a9</p>"},{"location":"ko/#3","title":"\ud83d\udee1\ufe0f 3\ub2e8\uacc4 \uc7a5\uc560 \ubcf5\uad6c","text":"<p>Main Topic \u2192 DLQ \u2192 \ub85c\uceec \ud30c\uc77c \ubc31\uc5c5 Kafka\uac00 24\uc2dc\uac04 \uc7a5\uc560\uc5ec\ub3c4 \uc774\ubca4\ud2b8 \uc190\uc2e4 \uc81c\ub85c</p>"},{"location":"ko/#pii","title":"\ud83d\udd10 \uc790\ub3d9 PII \ubcf4\ud638","text":"<p><code>@PiiField</code> \uc5b4\ub178\ud14c\uc774\uc158\uc73c\ub85c \ubbfc\uac10 \ub370\uc774\ud130 \uc790\ub3d9 \ub9c8\uc2a4\ud0b9/\uc554\ud638\ud654</p>"},{"location":"ko/#_5","title":"\u26a1 \uace0\uc131\ub2a5","text":"<ul> <li>\ub3d9\uae30 \ubaa8\ub4dc: ~500 TPS</li> <li>\ube44\ub3d9\uae30 \ubaa8\ub4dc: ~10,000+ TPS (MDC \ucee8\ud14d\uc2a4\ud2b8 \uc804\ud30c \ud3ec\ud568)</li> <li>Transactional Outbox: \uc6d0\uc790\uc131 \ubc0f \uc77c\uad00\uc131 \ubcf4\uc7a5</li> </ul>"},{"location":"ko/#hexagonal-architecture","title":"\ud83c\udfd7\ufe0f Hexagonal Architecture","text":"<p>\ucd5c\ub300 \uc720\uc5f0\uc131\uc744 \uc704\ud55c \ud504\ub808\uc784\uc6cc\ud06c \ub3c5\ub9bd\uc801 \ucf54\uc5b4</p>"},{"location":"ko/#_6","title":"\ud83d\udcca \ub0b4\uc7a5 \uad00\ucc30\uc131","text":"<ul> <li>Spring Actuator Health Indicator</li> <li>\ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc5d4\ub4dc\ud3ec\uc778\ud2b8 (<code>/actuator/curve-metrics</code>)</li> <li>\uc0c1\uc138\ud55c \uc774\ubca4\ud2b8 \ucd94\uc801</li> <li>\ube44\ub3d9\uae30 \ucee8\ud14d\uc2a4\ud2b8 \uc804\ud30c: \ube44\ub3d9\uae30 \uc2a4\ub808\ub4dc\uc5d0\uc11c\ub3c4 MDC(Trace ID)\uac00 \uc720\uc9c0\ub429\ub2c8\ub2e4.</li> </ul>"},{"location":"ko/#_7","title":"\ud83e\uddea \ud14c\uc2a4\ud2b8 \uc6a9\uc774\uc131","text":"<ul> <li>Kafka \uc5c6\uc774 \ub2e8\uc704/\ud1b5\ud569 \ud14c\uc2a4\ud2b8\ub97c \ud560 \uc218 \uc788\ub294 <code>MockEventProducer</code> \uc81c\uacf5.</li> </ul>"},{"location":"ko/#_8","title":"\ud83d\ude80 \ube60\ub978 \uc2dc\uc791","text":""},{"location":"ko/#1","title":"1. \uc758\uc874\uc131 \ucd94\uac00","text":"<p>Gradle (build.gradle) <pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.1.2'\n}\n</code></pre></p> <p>Maven (pom.xml) <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.1.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p>"},{"location":"ko/#2","title":"2. \uc124\uc815","text":"<p>application.yml <pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9092\n\ncurve:\n  enabled: true\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n</code></pre></p>"},{"location":"ko/#3_1","title":"3. \uc0ac\uc6a9","text":"<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\nimport io.github.closeup1202.curve.core.type.EventSeverity;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(\n        eventType = \"ORDER_CREATED\",\n        severity = EventSeverity.INFO\n    )\n    public Order createOrder(OrderRequest request) {\n        // \ube44\uc988\ub2c8\uc2a4 \ub85c\uc9c1\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre>"},{"location":"ko/#4-kafka","title":"4. \ub85c\uceec Kafka \uc2e4\ud589","text":"<pre><code>docker-compose up -d\n</code></pre>"},{"location":"ko/#5","title":"5. \ud655\uc778","text":"<ul> <li>Kafka UI: http://localhost:8080</li> <li>Health Check: http://localhost:8081/actuator/health/curve</li> <li>\uba54\ud2b8\ub9ad: http://localhost:8081/actuator/curve-metrics</li> </ul> <p>\uc644\ub8cc! \ud83c\udf89</p>"},{"location":"ko/#_9","title":"\ud83d\udcca \ube44\uad50","text":"\uae30\ub2a5 Spring Events Spring Cloud Stream Curve Kafka \uc5f0\ub3d9 \u274c \u2705 \u2705 \uc120\uc5b8\uc801 \uc0ac\uc6a9 \u2705 \u25b3 \u2705 \ud45c\uc900\ud654\ub41c \uc2a4\ud0a4\ub9c8 \u274c \u274c \u2705 PII \ubcf4\ud638 \u274c \u274c \u2705 DLQ \uc9c0\uc6d0 \u274c \u2705 \u2705 \ub85c\uceec \ud30c\uc77c \ubc31\uc5c5 \u274c \u274c \u2705 Health Check \u274c \u274c \u2705 \ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \u274c \u274c \u2705 Snowflake ID \u274c \u274c \u2705 Transactional Outbox \u274c \u274c \u2705 \ubcf4\uc77c\ub7ec\ud50c\ub808\uc774\ud2b8 \uc911\uac04 \ub9ce\uc74c \ucd5c\uc18c"},{"location":"ko/#_10","title":"\ud83c\udfd7\ufe0f \uc544\ud0a4\ud14d\ucc98","text":""},{"location":"ko/#hexagonal-architecture-ports-adapters","title":"Hexagonal Architecture (Ports &amp; Adapters)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      \ub3c4\uba54\uc778 \uacc4\uce35 (Core)              \u2502\n\u2502  \u2022 EventEnvelope, EventMetadata     \u2502\n\u2502  \u2022 Validation, Exception            \u2502\n\u2502  \u2022 \ud504\ub808\uc784\uc6cc\ud06c \ub3c5\ub9bd\uc801                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                \u2502\n        \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Spring   \u2502      \u2502   Kafka    \u2502\n\u2502 (\uc5b4\ub311\ud130)   \u2502      \u2502  (\uc5b4\ub311\ud130)   \u2502\n\u2502  \u2022 AOP    \u2502      \u2502 \u2022 Producer \u2502\n\u2502  \u2022 Context\u2502      \u2502 \u2022 DLQ      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ko/#_11","title":"\ubaa8\ub4c8 \uad6c\uc870","text":"<pre><code>curve/\n\u251c\u2500\u2500 core/                          # \uc21c\uc218 \ub3c4\uba54\uc778 \ubaa8\ub378 (\ud504\ub808\uc784\uc6cc\ud06c \ub3c5\ub9bd)\n\u2502   \u251c\u2500\u2500 envelope/                  # EventEnvelope, EventMetadata\n\u2502   \u251c\u2500\u2500 port/                      # EventProducer, IdGenerator (\uc778\ud130\ud398\uc774\uc2a4)\n\u2502   \u251c\u2500\u2500 context/                   # ContextProvider (\uc778\ud130\ud398\uc774\uc2a4)\n\u2502   \u251c\u2500\u2500 validation/                # EventValidator\n\u2502   \u2514\u2500\u2500 exception/                 # \ub3c4\uba54\uc778 \uc608\uc678\n\u2502\n\u251c\u2500\u2500 spring/                        # Spring Framework \uc5b4\ub311\ud130\n\u2502   \u251c\u2500\u2500 aop/                       # @PublishEvent Aspect\n\u2502   \u251c\u2500\u2500 context/                   # Spring \uae30\ubc18 Context Provider \uad6c\ud604\n\u2502   \u251c\u2500\u2500 factory/                   # EventEnvelopeFactory\n\u2502   \u251c\u2500\u2500 infrastructure/            # SnowflakeIdGenerator, UtcClockProvider\n\u2502   \u251c\u2500\u2500 publisher/                 # AbstractEventPublisher\n\u2502   \u2514\u2500\u2500 test/                      # \ud14c\uc2a4\ud2b8 \uc720\ud2f8\ub9ac\ud2f0 (MockEventProducer)\n\u2502\n\u251c\u2500\u2500 kafka/                         # Kafka \uc5b4\ub311\ud130\n\u2502   \u251c\u2500\u2500 producer/                  # KafkaEventProducer\n\u2502   \u2514\u2500\u2500 dlq/                       # FailedEventRecord\n\u2502\n\u2514\u2500\u2500 spring-boot-autoconfigure/     # Spring Boot \uc790\ub3d9 \uc124\uc815\n    \u251c\u2500\u2500 CurveAutoConfiguration     # \uba54\uc778 \uc124\uc815\n    \u251c\u2500\u2500 CurveProperties            # \uc124\uc815 \uc18d\uc131\n    \u2514\u2500\u2500 health/                    # Health indicator &amp; \uba54\ud2b8\ub9ad\n</code></pre>"},{"location":"ko/#_12","title":"\ud575\uc2ec \uc124\uacc4 \uc6d0\uce59","text":"<ol> <li>\uc758\uc874\uc131 \uc5ed\uc804 \uc6d0\uce59 (DIP)</li> <li>Core \ubaa8\ub4c8\uc740 \ud504\ub808\uc784\uc6cc\ud06c \uc758\uc874\uc131 \uc81c\ub85c</li> <li> <p>Port \uc778\ud130\ud398\uc774\uc2a4\ub97c \ud1b5\ud574 \uc678\ubd80 \uc758\uc874\uc131 \uaca9\ub9ac</p> </li> <li> <p>\ub2e8\uc77c \ucc45\uc784 \uc6d0\uce59 (SRP)</p> </li> <li>\uac01 ContextProvider\ub294 \ud558\ub098\uc758 \ucc45\uc784\ub9cc \ucc98\ub9ac</li> <li> <p>EventValidator\ub294 \uac80\uc99d\ub9cc, EventProducer\ub294 \ubc1c\ud589\ub9cc</p> </li> <li> <p>\uac1c\ubc29-\ud3d0\uc1c4 \uc6d0\uce59 (OCP)</p> </li> <li>EventProducer \uc778\ud130\ud398\uc774\uc2a4\ub85c Kafka \uc678 \ub2e4\ub978 \ube0c\ub85c\ucee4 \uc0ac\uc6a9 \uac00\ub2a5</li> <li>ContextProvider \uad6c\ud604\uccb4 \uad50\uccb4 \uac00\ub2a5</li> </ol>"},{"location":"ko/#_13","title":"\ud83c\udfaf \uc0ac\uc6a9 \uc0ac\ub840","text":""},{"location":"ko/#1_1","title":"1. \uac10\uc0ac \ub85c\uae45","text":"<pre><code>@PublishEvent(eventType = \"USER_LOGIN\", severity = INFO)\npublic User login(String username, String password) {\n    return authService.authenticate(username, password);\n}\n</code></pre>"},{"location":"ko/#2_1","title":"2. \uc774\ubca4\ud2b8 \uae30\ubc18 \uc544\ud0a4\ud14d\ucc98","text":"<pre><code>@PublishEvent(eventType = \"ORDER_COMPLETED\")\npublic Order completeOrder(Long orderId) {\n    Order order = orderRepository.findById(orderId);\n    order.setStatus(OrderStatus.COMPLETED);\n    return orderRepository.save(order);\n}\n</code></pre>"},{"location":"ko/#3_2","title":"3. \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778","text":"<pre><code>@PublishEvent(eventType = \"CUSTOMER_REGISTERED\")\npublic Customer registerCustomer(CustomerRequest request) {\n    // \uc774\ubca4\ud2b8\uac00 \uc790\ub3d9\uc73c\ub85c \ub370\uc774\ud130 \ub808\uc774\ud06c/\uc6e8\uc5b4\ud558\uc6b0\uc2a4\ub85c \uc804\ub2ec\n    return customerRepository.save(new Customer(request));\n}\n</code></pre>"},{"location":"ko/#_14","title":"\ud83d\udee1\ufe0f \ubcf4\uc548 \uae30\ub2a5","text":""},{"location":"ko/#pii_1","title":"\uc790\ub3d9 PII \ubcf4\ud638","text":"<pre><code>public class UserEventPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;  // \"user@example.com\" \u2192 \"user@***.com\"\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;  // AES-256-GCM \uc554\ud638\ud654\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;   // HMAC-SHA256 \ud574\uc2f1\n}\n</code></pre> <p>\uc9c0\uc6d0\ub418\ub294 \uc804\ub7b5: - MASK: \ud328\ud134 \uae30\ubc18 \ub9c8\uc2a4\ud0b9 (\uc608: <code>j***@gm***.com</code>) - ENCRYPT: AES-256-GCM \uc554\ud638\ud654 (\ubcf5\uc6d0 \uac00\ub2a5, Base64 \uc778\ucf54\ub529\ub41c 32\ubc14\uc774\ud2b8 \ud0a4 \ud544\uc694) - HASH: HMAC-SHA256 \ud574\uc2f1 (\ubcf5\uc6d0 \ubd88\uac00, salt \uad8c\uc7a5)</p> <p>\uc124\uc815: <pre><code>curve:\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # \ud658\uacbd \ubcc0\uc218\n      salt: ${PII_HASH_SALT}\n</code></pre></p>"},{"location":"ko/#_15","title":"\ud83d\udcc8 \uad00\ucc30\uc131","text":""},{"location":"ko/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre> <p>\uc751\ub2f5: <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"clusterId\": \"lkc-abc123\",\n    \"nodeCount\": 3,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre></p>"},{"location":"ko/#_16","title":"\ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc5d4\ub4dc\ud3ec\uc778\ud2b8","text":"<pre><code>curl http://localhost:8081/actuator/curve-metrics\n</code></pre> <p>\uc751\ub2f5: <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\",\n    \"totalDlqEvents\": 3,\n    \"totalKafkaErrors\": 0\n  },\n  \"events\": {\n    \"published\": [...],\n    \"publishDuration\": [...]\n  },\n  \"dlq\": {...},\n  \"kafka\": {...}\n}\n</code></pre></p>"},{"location":"ko/#_17","title":"\u2699\ufe0f \uc124\uc815","text":""},{"location":"ko/#_18","title":"\uc804\uccb4 \uc124\uc815 \uc608\uc2dc","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1  # 0-1023, \uc778\uc2a4\ud134\uc2a4\ub9c8\ub2e4 \uace0\uc720\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    retries: 3\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n    async-mode: false  # \ub192\uc740 \ucc98\ub9ac\ub7c9\uc744 \uc704\ud574 true\n    async-timeout-ms: 5000\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  security:\n    use-forwarded-headers: false  # \ud504\ub85d\uc2dc \ub4a4\uc5d0\uc11c\ub294 true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n      salt: ${PII_HASH_SALT}\n\n  outbox:\n    enabled: true\n    poll-interval-ms: 1000\n    batch-size: 100\n    max-retries: 3\n    cleanup-enabled: true\n    retention-days: 7\n    cleanup-cron: \"0 0 2 * * *\"\n\n  serde:\n    type: JSON # JSON, AVRO, PROTOBUF\n</code></pre>"},{"location":"ko/#avro","title":"Avro \uc9c1\ub82c\ud654 (\uc120\ud0dd)","text":"<p>Avro \uc9c1\ub82c\ud654(<code>serde.type: AVRO</code>)\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 \ub2e4\uc74c \uc758\uc874\uc131\uc744 \ucd94\uac00\ud558\uc138\uc694:</p> <p>build.gradle: <pre><code>repositories {\n    mavenCentral()\n    maven { url 'https://packages.confluent.io/maven/' }\n}\n\ndependencies {\n    implementation 'org.apache.avro:avro:1.11.4'\n    implementation 'io.confluent:kafka-avro-serializer:7.5.0'\n}\n</code></pre></p> <p>\ucc38\uace0: JSON \uc9c1\ub82c\ud654\ub294 \ucd94\uac00 \uc758\uc874\uc131 \uc5c6\uc774 \ubc14\ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/#_19","title":"\ud658\uacbd\ubcc4 \ud504\ub85c\ud30c\uc77c","text":"<p>\uac1c\ubc1c: <pre><code>spring:\n  config:\n    activate:\n      on-profile: dev\n\ncurve:\n  kafka:\n    async-mode: true  # \ube60\ub978 \ubc18\ubcf5\n    topic: event.audit.dev.v1\n</code></pre></p> <p>\ud504\ub85c\ub355\uc158: <pre><code>spring:\n  config:\n    activate:\n      on-profile: prod\n\ncurve:\n  id-generator:\n    worker-id: ${POD_ORDINAL}  # Kubernetes StatefulSet\n  kafka:\n    async-mode: false  # \uc548\uc815\uc131 \uc6b0\uc120\n    retries: 5\n</code></pre></p> <p>\uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc124\uc815 \uac00\uc774\ub4dc\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"ko/#_20","title":"\ud83d\udd27 \uace0\uae09 \uae30\ub2a5","text":""},{"location":"ko/#1-snowflake-id-generator","title":"1. Snowflake ID Generator","text":"<p>\ucda9\ub3cc \uc5c6\ub294 \ubd84\uc0b0 \uace0\uc720 ID \uc0dd\uc131.</p> <p>\uad6c\uc870: <pre><code>| 42\ube44\ud2b8: \ud0c0\uc784\uc2a4\ud0ec\ud504 | 10\ube44\ud2b8: Worker ID | 12\ube44\ud2b8: Sequence |\n</code></pre></p> <p>\uc6a9\ub7c9: - \ucd5c\ub300 1,024 \uc6cc\ucee4 - \ubc00\ub9ac\ucd08\ub2f9 4,096\uac1c ID (\uc6cc\ucee4\ub2f9) - \uc2dc\uac04 \uc815\ub82c \uac00\ub2a5</p>"},{"location":"ko/#2-transactional-outbox-pattern","title":"2. Transactional Outbox Pattern","text":"<p>DB \ud2b8\ub79c\uc7ad\uc158\uacfc \uc774\ubca4\ud2b8 \ubc1c\ud589\uc758 \uc6d0\uc790\uc131\uc744 \ubcf4\uc7a5\ud569\ub2c8\ub2e4.</p> <ul> <li>\uc9c0\uc218 \ubc31\uc624\ud504(Exponential Backoff): \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8\ub97c 1\ucd08, 2\ucd08, 4\ucd08... \uac04\uaca9\uc73c\ub85c \uc7ac\uc2dc\ub3c4\ud558\uc5ec DB \ubd80\ud558\ub97c \uc904\uc785\ub2c8\ub2e4.</li> <li>SKIP LOCKED: \ub2e4\uc911 \uc778\uc2a4\ud134\uc2a4 \ud658\uacbd\uc5d0\uc11c \uc911\ubcf5 \ucc98\ub9ac\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \ube44\uad00\uc801 \ub77d\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</li> </ul> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.orderId\"\n)\npublic Order createOrder(OrderRequest req) {\n    return orderRepo.save(new Order(req));\n}\n</code></pre>"},{"location":"ko/#3-spel","title":"3. \uc720\uc5f0\ud55c \ud398\uc774\ub85c\ub4dc \ucd94\ucd9c (SpEL)","text":"<p>SpEL\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774\ubca4\ud2b8 \ud398\uc774\ub85c\ub4dc\ub85c \uc0ac\uc6a9\ud560 \ub370\uc774\ud130\ub97c \uc720\uc5f0\ud558\uac8c \ucd94\ucd9c\ud569\ub2c8\ub2e4.</p> <pre><code>@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#args[0].toEventDto()\"\n)\npublic User updateUser(UserUpdateRequest request) {\n    // ...\n}\n</code></pre>"},{"location":"ko/#4-producer","title":"4. \ucee4\uc2a4\ud140 \uc774\ubca4\ud2b8 Producer","text":"<p>Kafka\uac00 \uc544\ub2cc \ub2e4\ub978 \ube0c\ub85c\ucee4\ub97c \uc704\ud574 <code>EventProducer</code> \uc778\ud130\ud398\uc774\uc2a4 \uad6c\ud604:</p> <pre><code>@Component\npublic class RabbitMqEventProducer extends AbstractEventPublisher {\n\n    private final RabbitTemplate rabbitTemplate;\n\n    @Override\n    protected &lt;T extends DomainEventPayload&gt; void send(EventEnvelope&lt;T&gt; envelope) {\n        String json = objectMapper.writeValueAsString(envelope);\n        rabbitTemplate.convertAndSend(exchange, routingKey, json);\n    }\n}\n</code></pre>"},{"location":"ko/#5-dlq","title":"5. DLQ \ubcf5\uad6c","text":"<pre><code># \ubc31\uc5c5 \ud30c\uc77c \ubaa9\ub85d\n./scripts/dlq-recovery.sh --list\n\n# \ubaa8\ub4e0 \ud30c\uc77c \ubcf5\uad6c\n./scripts/dlq-recovery.sh --topic event.audit.v1 --broker localhost:9092\n\n# \ud2b9\uc815 \ud30c\uc77c \ubcf5\uad6c\n./scripts/dlq-recovery.sh --file 1234567890.json --topic event.audit.v1\n</code></pre>"},{"location":"ko/#_21","title":"\ud83d\udcda \ubb38\uc11c","text":"\ubb38\uc11c \uc124\uba85 \uc124\uc815 \uac00\uc774\ub4dc \uc0c1\uc138 \uc124\uc815 \uc635\uc158 \uc6b4\uc601 \uac00\uc774\ub4dc \ud504\ub85c\ub355\uc158 \uc6b4\uc601 \ubc0f \ubaa8\ubc94 \uc0ac\ub840 \ubb38\uc81c \ud574\uacb0 \uc77c\ubc18\uc801\uc778 \ubb38\uc81c \ubc0f \ud574\uacb0 \ubc29\ubc95 \ubaa8\ub2c8\ud130\ub9c1 \uac00\uc774\ub4dc \uba54\ud2b8\ub9ad, \ub300\uc2dc\ubcf4\ub4dc, \uc54c\ub9bc \uc124\uc815 \ub9c8\uc774\uadf8\ub808\uc774\uc158 \uac00\uc774\ub4dc \ubc84\uc804 \uc5c5\uadf8\ub808\uc774\ub4dc \uc9c0\uce68 \ubcc0\uacbd \uc774\ub825 \ubc84\uc804 \ud788\uc2a4\ud1a0\ub9ac \ubc0f \ubcc0\uacbd \uc0ac\ud56d \uc608\uc2dc \uc124\uc815 \uc124\uc815 \uc608\uc2dc \uc0d8\ud50c \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc644\uc804\ud55c \uc791\ub3d9 \uc608\uc2dc"},{"location":"ko/#_22","title":"\ud83e\udd1d \uae30\uc5ec\ud558\uae30","text":"<p>\uae30\uc5ec\ub97c \ud658\uc601\ud569\ub2c8\ub2e4! Pull Request\ub97c \uc790\uc720\ub86d\uac8c \uc81c\ucd9c\ud574\uc8fc\uc138\uc694.</p> <p>\uac00\uc774\ub4dc\ub77c\uc778\uc740 CONTRIBUTING.md\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"ko/#_23","title":"\ud83d\udcc4 \ub77c\uc774\uc120\uc2a4","text":"<p>\uc774 \ud504\ub85c\uc81d\ud2b8\ub294 MIT \ub77c\uc774\uc120\uc2a4\ub85c \ubc30\ud3ec\ub429\ub2c8\ub2e4 - \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 LICENSE \ud30c\uc77c\uc744 \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"ko/#_24","title":"\ud83d\ude4f \uac10\uc0ac\uc758 \ub9d0","text":"<ul> <li>Spring Cloud Stream\uacfc Spring Kafka\uc5d0\uc11c \uc601\uac10\uc744 \ubc1b\uc558\uc2b5\ub2c8\ub2e4</li> <li>Spring Boot\uc640 Apache Kafka\ub85c \uad6c\ucd95\ub418\uc5c8\uc2b5\ub2c8\ub2e4</li> <li>Alistair Cockburn\uc758 Hexagonal Architecture \ud328\ud134 \uc801\uc6a9</li> </ul>"},{"location":"ko/#_25","title":"\ud83d\udcec \uc5f0\ub77d\ucc98","text":"<ul> <li>\uc774\uc288: GitHub Issues</li> <li>\uc774\uba54\uc77c: closeup1202@gmail.com</li> </ul>   [\u2b06 \ub9e8 \uc704\ub85c](#curve)"},{"location":"ko/CONFIGURATION/","title":"Curve \uc124\uc815 \uac00\uc774\ub4dc","text":"<p>\uc774 \ubb38\uc11c\ub294 Curve \uc774\ubca4\ud2b8 \ubc1c\ud589 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \uc0c1\uc138\ud55c \uc124\uc815 \ubc29\ubc95\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#_1","title":"\ubaa9\ucc28","text":"<ul> <li>\uae30\ubcf8 \uc124\uc815</li> <li>\uc124\uc815 \uc720\ud6a8\uc131 \uac80\uc0ac</li> <li>Worker ID \uc124\uc815</li> <li>Kafka \uc804\uc1a1 \ubaa8\ub4dc \uc124\uc815</li> <li>DLQ \uc124\uc815</li> <li>\ubc31\uc5c5 \uc804\ub7b5 \uc124\uc815</li> <li>\uc7ac\uc2dc\ub3c4 \uc124\uc815</li> <li>AOP \uc124\uc815</li> <li>PII \ubcf4\ud638 \uc124\uc815</li> <li>Outbox \uc124\uc815</li> <li>\uc9c1\ub82c\ud654 \uc124\uc815</li> <li>Avro \uc9c1\ub82c\ud654 \uc124\uc815</li> <li>\ub85c\uae45 \uc124\uc815</li> </ul>"},{"location":"ko/CONFIGURATION/#_2","title":"\uae30\ubcf8 \uc124\uc815","text":""},{"location":"ko/CONFIGURATION/#applicationyml","title":"application.yml","text":"<pre><code>curve:\n  enabled: true  # Curve \ud65c\uc131\ud654 (\uae30\ubcf8\uac12: true)\n\n  kafka:\n    topic: event.audit.v1  # \uba54\uc778 \ud1a0\ud53d \uc774\ub984\n    dlq-topic: event.audit.dlq.v1  # DLQ \ud1a0\ud53d (\uc120\ud0dd)\n\n  id-generator:\n    worker-id: 1  # Snowflake Worker ID (0~1023)\n    auto-generate: false  # MAC \uc8fc\uc18c \uae30\ubc18 \uc790\ub3d9 \uc0dd\uc131\n</code></pre>"},{"location":"ko/CONFIGURATION/#_3","title":"\uc124\uc815 \uc720\ud6a8\uc131 \uac80\uc0ac","text":"<p>Curve\ub294 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc2dc\uc791 \uc2dc <code>@Validated</code>\ub97c \ud1b5\ud574 \uc124\uc815\uac12\uc744 \uc790\ub3d9\uc73c\ub85c \uac80\uc99d\ud569\ub2c8\ub2e4. \uc798\ubabb\ub41c \uc124\uc815\uac12\uc774 \uc785\ub825\ub418\uba74 \uba85\ud655\ud55c \uc5d0\ub7ec \uba54\uc2dc\uc9c0\uc640 \ud568\uaed8 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc2dc\uc791\uc774 \uc2e4\ud328\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#_4","title":"\uac80\uc99d \uaddc\uce59","text":"\uc124\uc815 \ud56d\ubaa9 \uac80\uc99d \uaddc\uce59 \uc5d0\ub7ec \uba54\uc2dc\uc9c0 <code>curve.kafka.topic</code> \ud544\uc218 (\ube48 \ubb38\uc790\uc5f4 \ubd88\uac00) \"Kafka topic is required\" <code>curve.kafka.retries</code> 0 \uc774\uc0c1 \"retries must be 0 or greater\" <code>curve.kafka.retry-backoff-ms</code> \uc591\uc218 \"retryBackoffMs must be positive\" <code>curve.kafka.request-timeout-ms</code> \uc591\uc218 \"requestTimeoutMs must be positive\" <code>curve.kafka.async-timeout-ms</code> \uc591\uc218 \"asyncTimeoutMs must be positive\" <code>curve.kafka.sync-timeout-seconds</code> \uc591\uc218 \"syncTimeoutSeconds must be positive\" <code>curve.kafka.dlq-executor-threads</code> 1 \uc774\uc0c1 \"dlqExecutorThreads must be 1 or greater\" <code>curve.id-generator.worker-id</code> 0 ~ 1023 \"workerId must be between 0 and 1023\" <code>curve.retry.max-attempts</code> 1 \uc774\uc0c1 \"maxAttempts must be 1 or greater\" <code>curve.retry.initial-interval</code> \uc591\uc218 \"initialInterval must be positive\" <code>curve.retry.multiplier</code> 1 \uc774\uc0c1 \"multiplier must be 1 or greater\" <code>curve.retry.max-interval</code> \uc591\uc218 \"maxInterval must be positive\" <code>curve.outbox.poll-interval-ms</code> \uc591\uc218 \"pollIntervalMs must be positive\" <code>curve.outbox.batch-size</code> 1 ~ 1000 \"batchSize must be between 1 and 1000\" <code>curve.outbox.max-retries</code> 1 \uc774\uc0c1 \"maxRetries must be 1 or greater\" <code>curve.outbox.send-timeout-seconds</code> \uc591\uc218 \"sendTimeoutSeconds must be positive\" <code>curve.outbox.retention-days</code> 1 \uc774\uc0c1 \"retentionDays must be 1 or greater\" <code>curve.async.core-pool-size</code> 1 \uc774\uc0c1 \"corePoolSize must be at least 1\" <code>curve.async.max-pool-size</code> 1 \uc774\uc0c1 \"maxPoolSize must be at least 1\" <code>curve.async.queue-capacity</code> 0 \uc774\uc0c1 \"queueCapacity must be at least 0\" <code>curve.kafka.backup.s3-bucket</code> s3Enabled=true\uc77c \ub54c \ud544\uc218 \"s3Bucket is required when s3Enabled=true\" <code>curve.serde.schema-registry-url</code> type=AVRO\uc77c \ub54c \ud544\uc218 \"schemaRegistryUrl is required when serde type is AVRO\""},{"location":"ko/CONFIGURATION/#_5","title":"\uac80\uc99d \uc2e4\ud328 \uc608\uc2dc","text":"<pre><code>***************************\nAPPLICATION FAILED TO START\n***************************\n\nDescription:\n\nBinding to target org.springframework.boot.context.properties.bind.BindException:\nFailed to bind properties under 'curve' to com.project.curve.autoconfigure.CurveProperties failed:\n\n    Property: curve.id-generator.worker-id\n    Value: \"2000\"\n    Reason: workerId must be 1023 or less\n</code></pre>"},{"location":"ko/CONFIGURATION/#worker-id","title":"Worker ID \uc124\uc815","text":"<p>Snowflake ID Generator\ub294 \ubd84\uc0b0 \ud658\uacbd\uc5d0\uc11c \uace0\uc720\ud55c ID\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud574 Worker ID\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#1-worker-id","title":"\ubc29\ubc95 1: \uba85\uc2dc\uc801 Worker ID \uc124\uc815 (\uad8c\uc7a5)","text":"<p>\uac01 \uc778\uc2a4\ud134\uc2a4\uc5d0 \uace0\uc720\ud55c Worker ID\ub97c \ubd80\uc5ec\ud569\ub2c8\ub2e4.</p> <pre><code>curve:\n  id-generator:\n    worker-id: 1  # \uc778\uc2a4\ud134\uc2a4 1\n    auto-generate: false\n</code></pre> <p>Kubernetes \ud658\uacbd \uc608\uc2dc:</p> <pre><code># deployment.yaml\nenv:\n  - name: CURVE_ID_GENERATOR_WORKER_ID\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.uid  # Pod UID \ud574\uc2dc\uac12 \uc0ac\uc6a9\n</code></pre> <p>Docker Compose \uc608\uc2dc:</p> <pre><code># docker-compose.yml\nservices:\n  app-1:\n    environment:\n      - CURVE_ID_GENERATOR_WORKER_ID=1\n  app-2:\n    environment:\n      - CURVE_ID_GENERATOR_WORKER_ID=2\n</code></pre>"},{"location":"ko/CONFIGURATION/#2","title":"\ubc29\ubc95 2: \uc790\ub3d9 \uc0dd\uc131 (\uc8fc\uc758)","text":"<p>MAC \uc8fc\uc18c\ub97c \uae30\ubc18\uc73c\ub85c Worker ID\ub97c \uc790\ub3d9 \uc0dd\uc131\ud569\ub2c8\ub2e4.</p> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre> <p>\u26a0\ufe0f \uc8fc\uc758: - \uac00\uc0c1 \ud658\uacbd\uc5d0\uc11c\ub294 MAC \uc8fc\uc18c\uac00 \ub3d9\uc77c\ud560 \uc218 \uc788\uc5b4 \ucda9\ub3cc \uac00\ub2a5\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4. - \ucee8\ud14c\uc774\ub108 \uc7ac\uc2dc\uc791 \uc2dc MAC \uc8fc\uc18c\uac00 \ubcc0\uacbd\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. - \ud504\ub85c\ub355\uc158 \ud658\uacbd\uc5d0\uc11c\ub294 \uba85\uc2dc\uc801 \uc124\uc815\uc744 \uad8c\uc7a5\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#worker-id_1","title":"Worker ID \ubc94\uc704","text":"<ul> <li>\ucd5c\uc18c\uac12: 0</li> <li>\ucd5c\ub300\uac12: 1023</li> <li>\uad8c\uc7a5: \ud658\uacbd \ubcc0\uc218 \ub610\ub294 \uc124\uc815 \uad00\ub9ac \uc2dc\uc2a4\ud15c(Consul, etcd)\uc744 \ud1b5\ud574 \uad00\ub9ac</li> </ul>"},{"location":"ko/CONFIGURATION/#kafka","title":"Kafka \uc804\uc1a1 \ubaa8\ub4dc \uc124\uc815","text":"<p>Curve\ub294 \ub3d9\uae30(Synchronous) \ubc0f \ube44\ub3d9\uae30(Asynchronous) \uc804\uc1a1 \ubaa8\ub4dc\ub97c \ubaa8\ub450 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#_6","title":"\ub3d9\uae30 \uc804\uc1a1 (\uae30\ubcf8\uac12)","text":"<pre><code>curve:\n  kafka:\n    async-mode: false  # \ub3d9\uae30 \uc804\uc1a1\n    request-timeout-ms: 30000  # 30\ucd08\n</code></pre> <p>\ud2b9\uc9d5: - \u2705 \ud655\uc2e4\ud55c \uc804\uc1a1 \ubcf4\uc7a5 (\uc131\uacf5/\uc2e4\ud328 \uc5ec\ubd80 \uba85\ud655) - \u2705 \uc5d0\ub7ec \ud578\ub4e4\ub9c1 \uc6a9\uc774 - \u274c \uc131\ub2a5 \uc800\ud558 (Blocking) - \u274c \ucc98\ub9ac\ub7c9 \uc81c\ud55c\uc801</p> <p>\uc801\ud569\ud55c \uacbd\uc6b0: - \uae08\uc735 \uac70\ub798, \uacb0\uc81c \ub4f1 \uc815\ud655\uc131\uc774 \uc911\uc694\ud55c \uacbd\uc6b0 - \uc774\ubca4\ud2b8 \uc720\uc2e4\uc774 \uc808\ub300 \ud5c8\uc6a9\ub418\uc9c0 \uc54a\ub294 \uacbd\uc6b0 - \ub0ae\uc740 \ucc98\ub9ac\ub7c9 (\uc218\uc2ed ~ \uc218\ubc31 TPS)</p>"},{"location":"ko/CONFIGURATION/#_7","title":"\ube44\ub3d9\uae30 \uc804\uc1a1","text":"<pre><code>curve:\n  kafka:\n    async-mode: true  # \ube44\ub3d9\uae30 \uc804\uc1a1\n    async-timeout-ms: 5000  # 5\ucd08 \ud0c0\uc784\uc544\uc6c3\n</code></pre> <p>\ud2b9\uc9d5: - \u2705 \ub192\uc740 \uc131\ub2a5 (Non-blocking) - \u2705 \ub300\ub7c9 \ucc98\ub9ac \uac00\ub2a5 - \u26a0\ufe0f \ucf5c\ubc31 \uae30\ubc18 \uc5d0\ub7ec \ud578\ub4e4\ub9c1 - \u26a0\ufe0f \uc804\uc1a1 \uc2e4\ud328 \uc2dc DLQ \uc758\uc874</p> <p>\uc801\ud569\ud55c \uacbd\uc6b0: - \ub85c\uadf8, \ubd84\uc11d \uc774\ubca4\ud2b8 \ub4f1 \uc77c\ubd80 \uc720\uc2e4\uc774 \ud5c8\uc6a9\ub418\ub294 \uacbd\uc6b0 - \ub192\uc740 \ucc98\ub9ac\ub7c9\uc774 \ud544\uc694\ud55c \uacbd\uc6b0 (\uc218\ucc9c ~ \uc218\ub9cc TPS) - Latency\uac00 \uc911\uc694\ud55c \uacbd\uc6b0</p>"},{"location":"ko/CONFIGURATION/#_8","title":"\uc131\ub2a5 \ube44\uad50","text":"\ud56d\ubaa9 \ub3d9\uae30 \uc804\uc1a1 \ube44\ub3d9\uae30 \uc804\uc1a1 \ucc98\ub9ac\ub7c9 (TPS) ~500 ~10,000+ Latency \ub192\uc74c (10-50ms) \ub0ae\uc74c (1-5ms) \uc804\uc1a1 \ubcf4\uc7a5 \uac15\ub825\ud568 \ubcf4\ud1b5 (DLQ \uc758\uc874) \ub9ac\uc18c\uc2a4 \uc0ac\uc6a9 \ub192\uc74c \ub0ae\uc74c"},{"location":"ko/CONFIGURATION/#dlq","title":"DLQ \uc124\uc815","text":"<p>Dead Letter Queue\ub294 \uc804\uc1a1\uc5d0 \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8\ub97c \uc800\uc7a5\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#dlq_1","title":"DLQ \ud65c\uc131\ud654","text":"<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # DLQ \ud65c\uc131\ud654\n</code></pre>"},{"location":"ko/CONFIGURATION/#dlq_2","title":"DLQ \ube44\ud65c\uc131\ud654","text":"<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic:  # \ube48 \uac12 \ub610\ub294 \uc124\uc815 \uc548 \ud568\n</code></pre> <p>\u26a0\ufe0f \uc8fc\uc758: DLQ\ub97c \ube44\ud65c\uc131\ud654\ud558\uba74 \uc804\uc1a1 \uc2e4\ud328 \uc2dc \uc774\ubca4\ud2b8\uac00 \uc720\uc2e4\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#dlq_3","title":"DLQ \uba54\uc2dc\uc9c0 \uad6c\uc870","text":"<pre><code>{\n  \"eventId\": \"123456789\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"originalPayload\": \"{...}\",\n  \"exceptionType\": \"org.apache.kafka.common.errors.TimeoutException\",\n  \"exceptionMessage\": \"Failed to send message after 3 retries\",\n  \"failedAt\": 1704067200000\n}\n</code></pre>"},{"location":"ko/CONFIGURATION/#_9","title":"\ubc31\uc5c5 \uc804\ub7b5 \uc124\uc815","text":"<p>DLQ \uc804\uc1a1\ub9c8\uc800 \uc2e4\ud328\ud560 \uacbd\uc6b0\ub97c \ub300\ube44\ud55c \ubc31\uc5c5 \uc804\ub7b5\uc744 \uc124\uc815\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#s3","title":"S3 \ubc31\uc5c5 (\ud074\ub77c\uc6b0\ub4dc \ud658\uacbd \uad8c\uc7a5)","text":"<pre><code>curve:\n  kafka:\n    backup:\n      s3-enabled: true\n      s3-bucket: \"my-event-backup-bucket\"\n      s3-prefix: \"dlq-backup\"\n</code></pre> <p>\uc694\uad6c\uc0ac\ud56d: - <code>software.amazon.awssdk:s3</code> \uc758\uc874\uc131 \ucd94\uac00 - Spring Context\uc5d0 <code>S3Client</code> \ube48 \ub4f1\ub85d</p>"},{"location":"ko/CONFIGURATION/#_10","title":"\ub85c\uceec \ud30c\uc77c \ubc31\uc5c5","text":"<pre><code>curve:\n  kafka:\n    backup:\n      local-enabled: true\n    dlq-backup-path: \"./dlq-backup\"\n</code></pre>"},{"location":"ko/CONFIGURATION/#_11","title":"\uc7ac\uc2dc\ub3c4 \uc124\uc815","text":"<p>\uc804\uc1a1 \uc2e4\ud328 \uc2dc \uc790\ub3d9 \uc7ac\uc2dc\ub3c4 \uc124\uc815\uc785\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#_12","title":"\uae30\ubcf8 \uc124\uc815","text":"<pre><code>curve:\n  retry:\n    enabled: true  # \uc7ac\uc2dc\ub3c4 \ud65c\uc131\ud654\n    max-attempts: 3  # \ucd5c\ub300 3\ud68c \uc2dc\ub3c4\n    initial-interval: 1000  # \ucd08\uae30 1\ucd08 \ub300\uae30\n    multiplier: 2.0  # 2\ubc30\uc529 \uc99d\uac00 (1\ucd08 -&gt; 2\ucd08 -&gt; 4\ucd08)\n    max-interval: 10000  # \ucd5c\ub300 10\ucd08\n</code></pre>"},{"location":"ko/CONFIGURATION/#exponential-backoff","title":"Exponential Backoff \uc608\uc2dc","text":"\uc2dc\ub3c4 \ud69f\uc218 \ub300\uae30 \uc2dc\uac04 1\ud68c\ucc28 0ms (\uc989\uc2dc) 2\ud68c\ucc28 1,000ms (1\ucd08) 3\ud68c\ucc28 2,000ms (2\ucd08) 4\ud68c\ucc28 4,000ms (4\ucd08)"},{"location":"ko/CONFIGURATION/#_13","title":"\uc7ac\uc2dc\ub3c4 \ube44\ud65c\uc131\ud654","text":"<pre><code>curve:\n  retry:\n    enabled: false\n</code></pre>"},{"location":"ko/CONFIGURATION/#aop","title":"AOP \uc124\uc815","text":"<p><code>@PublishEvent</code> \uc5b4\ub178\ud14c\uc774\uc158 \uae30\ubc18 AOP \uc124\uc815\uc785\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#aop_1","title":"AOP \ud65c\uc131\ud654 (\uae30\ubcf8\uac12)","text":"<pre><code>curve:\n  aop:\n    enabled: true\n</code></pre>"},{"location":"ko/CONFIGURATION/#aop_2","title":"AOP \ube44\ud65c\uc131\ud654","text":"<pre><code>curve:\n  aop:\n    enabled: false\n</code></pre>"},{"location":"ko/CONFIGURATION/#_14","title":"\ube44\ub3d9\uae30 \uc2e4\ud589\uae30 \uc124\uc815","text":"<p>Curve\ub294 \ube44\ub3d9\uae30 \uc774\ubca4\ud2b8 \ucc98\ub9ac\ub97c \uc704\ud55c \uc804\uc6a9 <code>curveAsyncExecutor</code> \ube48\uc744 \ub4f1\ub85d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p> <p>\ucc38\uace0: \uc774 \uc124\uc815\uc740 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc5d0 <code>@EnableAsync</code>\ub97c \uac15\uc81c \uc801\uc6a9\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. <code>@EnableAsync</code>\uac00 \ud544\uc694\ud558\uba74 \ubcc4\ub3c4\uc758 \uc124\uc815\uc5d0\uc11c \ud65c\uc131\ud654\ud558\uc138\uc694.</p>"},{"location":"ko/CONFIGURATION/#_15","title":"\ube44\ub3d9\uae30 \uc2e4\ud589\uae30 \ud65c\uc131\ud654","text":"<pre><code>curve:\n  async:\n    enabled: true  # curveAsyncExecutor \ube48 \ub4f1\ub85d\n    core-pool-size: 2  # \ucf54\uc5b4 \uc2a4\ub808\ub4dc \ud480 \ud06c\uae30 (\uae30\ubcf8\uac12: 2)\n    max-pool-size: 10  # \ucd5c\ub300 \uc2a4\ub808\ub4dc \ud480 \ud06c\uae30 (\uae30\ubcf8\uac12: 10)\n    queue-capacity: 500  # \uc791\uc5c5 \ud050 \uc6a9\ub7c9 (\uae30\ubcf8\uac12: 500)\n</code></pre>"},{"location":"ko/CONFIGURATION/#_16","title":"\ube44\ub3d9\uae30 \uc2e4\ud589\uae30 \ube44\ud65c\uc131\ud654 (\uae30\ubcf8\uac12)","text":"<pre><code>curve:\n  async:\n    enabled: false\n</code></pre>"},{"location":"ko/CONFIGURATION/#pii","title":"PII \ubcf4\ud638 \uc124\uc815","text":"<p>PII(\uac1c\uc778\uc815\ubcf4) \ubcf4\ud638 \uae30\ub2a5\uc744 \ud1b5\ud574 \ubbfc\uac10\ud55c \ub370\uc774\ud130\ub97c \uc790\ub3d9\uc73c\ub85c \ub9c8\uc2a4\ud0b9, \uc554\ud638\ud654, \ud574\uc2f1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#_17","title":"\uae30\ubcf8 \uc124\uc815","text":"<pre><code>curve:\n  pii:\n    enabled: true  # PII \ubcf4\ud638 \ud65c\uc131\ud654 (\uae30\ubcf8\uac12: true)\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # \uc554\ud638\ud654 \ud0a4 (\ud658\uacbd\ubcc0\uc218 \ud544\uc218)\n      salt: ${PII_HASH_SALT}              # \ud574\uc2f1 \uc194\ud2b8 (\ud658\uacbd\ubcc0\uc218 \uad8c\uc7a5)\n</code></pre>"},{"location":"ko/CONFIGURATION/#_18","title":"\uc554\ud638\ud654 \ud0a4 \uc124\uc815 (\ud544\uc218)","text":"<p><code>@PiiField(strategy = PiiStrategy.ENCRYPT)</code> \uc0ac\uc6a9 \uc2dc \uc554\ud638\ud654 \ud0a4\uac00 \ubc18\ub4dc\uc2dc \ud544\uc694\ud569\ub2c8\ub2e4.</p> <p>1. \ud0a4 \uc0dd\uc131 <pre><code># 32\ubc14\uc774\ud2b8 AES-256 \ud0a4 \uc0dd\uc131\nopenssl rand -base64 32\n# \ucd9c\ub825 \uc608\uc2dc: K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\n</code></pre></p> <p>2. \ud658\uacbd \ubcc0\uc218 \uc124\uc815 (\uad8c\uc7a5) <pre><code># Linux/macOS\nexport PII_ENCRYPTION_KEY=K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\nexport PII_HASH_SALT=your-random-salt-value\n\n# Windows PowerShell\n$env:PII_ENCRYPTION_KEY=\"K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\"\n$env:PII_HASH_SALT=\"your-random-salt-value\"\n</code></pre></p> <p>3. application.yml \uc124\uc815 <pre><code>curve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n      salt: ${PII_HASH_SALT}\n</code></pre></p> <p>\u26a0\ufe0f \uc8fc\uc758: - \uc554\ud638\ud654 \ud0a4\ub97c application.yml\uc5d0 \uc9c1\uc811 \ud558\ub4dc\ucf54\ub529\ud558\uc9c0 \ub9c8\uc138\uc694. - \ud504\ub85c\ub355\uc158 \ud658\uacbd\uc5d0\uc11c\ub294 \ud658\uacbd \ubcc0\uc218 \ub610\ub294 \uc678\ubd80 \uc2dc\ud06c\ub9bf \uad00\ub9ac \uc2dc\uc2a4\ud15c(Vault, AWS Secrets Manager)\uc744 \uc0ac\uc6a9\ud558\uc138\uc694. - \ud0a4\uac00 \uc124\uc815\ub418\uc9c0 \uc54a\uc73c\uba74 ENCRYPT \uc804\ub7b5 \uc0ac\uc6a9 \uc2dc \uc608\uc678\uac00 \ubc1c\uc0dd\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#pii_1","title":"PII \uc804\ub7b5 \uc885\ub958","text":"\uc804\ub7b5 \uc124\uba85 \ubcf5\ud638\ud654 \uac00\ub2a5 \uc5ec\ubd80 \uc608\uc2dc <code>MASK</code> \ud328\ud134 \uae30\ubc18 \ub9c8\uc2a4\ud0b9 \ubd88\uac00\ub2a5 <code>\ud64d\uae38\ub3d9</code> \u2192 <code>\ud64d**</code> <code>ENCRYPT</code> AES-256-GCM \uc554\ud638\ud654 \uac00\ub2a5 (\ud0a4 \ud544\uc694) \uc554\ud638\ud654\ub41c Base64 \ubb38\uc790\uc5f4 <code>HASH</code> HMAC-SHA256 \ud574\uc2f1 \ubd88\uac00\ub2a5 \ud574\uc2f1\ub41c Base64 \ubb38\uc790\uc5f4"},{"location":"ko/CONFIGURATION/#pii_2","title":"PII \ud0c0\uc785\ubcc4 \ub9c8\uc2a4\ud0b9 \ud328\ud134","text":"\ud0c0\uc785 \ub9c8\uc2a4\ud0b9 \ud328\ud134 \uc608\uc2dc <code>NAME</code> \uccab \uae00\uc790 \uc720\uc9c0, \ub098\uba38\uc9c0 \ub9c8\uc2a4\ud0b9 <code>\ud64d\uae38\ub3d9</code> \u2192 <code>\ud64d**</code> <code>EMAIL</code> \ub85c\uceec \ud30c\ud2b8 \uc720\uc9c0, \ub3c4\uba54\uc778 \ub9c8\uc2a4\ud0b9 <code>user@example.com</code> \u2192 <code>user@***.com</code> <code>PHONE</code> \uc55e 3\uc790\ub9ac, \ub4a4 4\uc790\ub9ac\ub9cc \uc720\uc9c0 <code>010-1234-5678</code> \u2192 <code>010****5678</code> <code>DEFAULT</code> \uc55e 30% \uc720\uc9c0, \ub098\uba38\uc9c0 \ub9c8\uc2a4\ud0b9 <code>\uc11c\uc6b8\uc2dc \uac15\ub0a8\uad6c</code> \u2192 <code>\uc11c\uc6b8\uc2dc***</code>"},{"location":"ko/CONFIGURATION/#_19","title":"\uc0ac\uc6a9 \uc608\uc2dc","text":"<pre><code>public class CustomerInfo {\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.MASK)\n    private String name;\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(strategy = PiiStrategy.HASH)\n    private String ssn;  // \uc8fc\ubbfc\ub4f1\ub85d\ubc88\ud638\n}\n</code></pre>"},{"location":"ko/CONFIGURATION/#kubernetes","title":"Kubernetes \ud658\uacbd \uc124\uc815","text":"<pre><code># deployment.yaml\nenv:\n  - name: PII_ENCRYPTION_KEY\n    valueFrom:\n      secretKeyRef:\n        name: curve-secrets\n        key: pii-encryption-key\n  - name: PII_HASH_SALT\n    valueFrom:\n      secretKeyRef:\n        name: curve-secrets\n        key: pii-hash-salt\n</code></pre> <pre><code># Secret \uc0dd\uc131\nkubectl create secret generic curve-secrets \\\n  --from-literal=pii-encryption-key=$(openssl rand -base64 32) \\\n  --from-literal=pii-hash-salt=$(openssl rand -base64 16)\n</code></pre>"},{"location":"ko/CONFIGURATION/#outbox","title":"Outbox \uc124\uc815","text":"<p>Transactional Outbox \ud328\ud134\uc744 \uc0ac\uc6a9\ud558\uc5ec DB \ud2b8\ub79c\uc7ad\uc158\uacfc \uc774\ubca4\ud2b8 \ubc1c\ud589 \uac04\uc758 \uc6d0\uc790\uc131\uc744 \ubcf4\uc7a5\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#_20","title":"\uae30\ubcf8 \uc124\uc815","text":"<pre><code>curve:\n  outbox:\n    enabled: true  # Outbox \ud65c\uc131\ud654\n    poll-interval-ms: 1000  # \ud3f4\ub9c1 \uac04\uaca9 (1\ucd08)\n    batch-size: 100  # \ubc30\uce58 \ud06c\uae30\n    max-retries: 3  # \ucd5c\ub300 \uc7ac\uc2dc\ub3c4 \ud69f\uc218\n    send-timeout-seconds: 10  # \uc804\uc1a1 \ud0c0\uc784\uc544\uc6c3\n    cleanup-enabled: true  # \uc624\ub798\ub41c \uc774\ubca4\ud2b8 \uc815\ub9ac \ud65c\uc131\ud654\n    retention-days: 7  # \ubcf4\uad00 \uae30\uac04 (7\uc77c)\n    cleanup-cron: \"0 0 2 * * *\"  # \uc815\ub9ac \uc791\uc5c5 \uc2e4\ud589 \uc2dc\uac04 (\ub9e4\uc77c \uc0c8\ubcbd 2\uc2dc)\n    initialize-schema: embedded  # \uc2a4\ud0a4\ub9c8 \ucd08\uae30\ud654 \ubaa8\ub4dc (embedded, always, never)\n</code></pre>"},{"location":"ko/CONFIGURATION/#_21","title":"\uc2a4\ud0a4\ub9c8 \ucd08\uae30\ud654 \ubaa8\ub4dc","text":"<ul> <li><code>embedded</code>: H2, HSQLDB \ub4f1 \uc784\ubca0\ub514\ub4dc DB\uc77c \ub54c\ub9cc \ud14c\uc774\ube14 \uc790\ub3d9 \uc0dd\uc131 (\uae30\ubcf8\uac12)</li> <li><code>always</code>: \ud56d\uc0c1 \ud14c\uc774\ube14 \uc0dd\uc131 \uc2dc\ub3c4 (\uc5c6\uc744 \uacbd\uc6b0)</li> <li><code>never</code>: \uc790\ub3d9 \uc0dd\uc131 \uc548 \ud568 (Flyway/Liquibase \uc0ac\uc6a9 \uc2dc \uad8c\uc7a5)</li> </ul>"},{"location":"ko/CONFIGURATION/#_22","title":"\uc9c1\ub82c\ud654 \uc124\uc815","text":"<p>\uc774\ubca4\ud2b8 \ud398\uc774\ub85c\ub4dc \uc9c1\ub82c\ud654 \ubc29\uc2dd\uc744 \uc124\uc815\ud569\ub2c8\ub2e4.</p> <pre><code>curve:\n  serde:\n    type: JSON  # JSON (\uae30\ubcf8\uac12), AVRO, PROTOBUF\n</code></pre>"},{"location":"ko/CONFIGURATION/#avro","title":"Avro \uc9c1\ub82c\ud654 \uc124\uc815","text":"<p>Avro\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubca4\ud2b8\ub97c \uc9c1\ub82c\ud654\ud558\ub824\uba74 \ucd94\uac00 \uc124\uc815\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/CONFIGURATION/#1-curve","title":"1. Curve \uc124\uc815","text":"<pre><code>curve:\n  serde:\n    type: AVRO\n    schema-registry-url: http://localhost:8081  # Schema Registry \uc8fc\uc18c\n</code></pre>"},{"location":"ko/CONFIGURATION/#2-spring-kafka","title":"2. Spring Kafka \uc124\uc815 (\ud544\uc218)","text":"<p>Spring Kafka\uc758 Producer \uc124\uc815\uc5d0\uc11c <code>value-serializer</code>\ub97c \uba85\uc2dc\uc801\uc73c\ub85c \uc9c0\uc815\ud574\uc57c \ud569\ub2c8\ub2e4.</p> <pre><code>spring:\n  kafka:\n    producer:\n      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer\n    properties:\n      schema.registry.url: http://localhost:8081\n</code></pre> <p>\u26a0\ufe0f \uc8fc\uc758: - <code>curve.serde.type=AVRO</code> \uc124\uc815 \uc2dc, Curve\ub294 \ub0b4\ubd80\uc801\uc73c\ub85c <code>GenericRecord</code> \uac1d\uccb4\ub97c \uc0dd\uc131\ud558\uc5ec KafkaTemplate\uc5d0 \uc804\ub2ec\ud569\ub2c8\ub2e4. - \ub530\ub77c\uc11c KafkaTemplate\uc774 <code>GenericRecord</code>\ub97c \uc9c1\ub82c\ud654\ud560 \uc218 \uc788\ub3c4\ub85d \ubc18\ub4dc\uc2dc <code>KafkaAvroSerializer</code>\ub97c \uc0ac\uc6a9\ud574\uc57c \ud569\ub2c8\ub2e4. - <code>schema.registry.url</code>\uc740 <code>curve.serde</code>\uc640 <code>spring.kafka.properties</code> \uc591\ucabd\uc5d0 \uc124\uc815\uc774 \ud544\uc694\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4 (Curve \ub0b4\ubd80 \ub85c\uc9c1\uc6a9 \ubc0f Kafka Serializer\uc6a9).</p>"},{"location":"ko/CONFIGURATION/#avro_1","title":"Avro \uc2a4\ud0a4\ub9c8 \uad6c\uc870","text":"<p>Curve\ub294 \ub0b4\ubd80\uc801\uc73c\ub85c \ub2e4\uc74c\uacfc \uac19\uc740 \uace0\uc815\ub41c Avro \uc2a4\ud0a4\ub9c8\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. <code>payload</code>\uc640 <code>metadata</code>\uc758 \uc77c\ubd80 \ud544\ub4dc\ub294 \uc720\uc5f0\uc131\uc744 \uc704\ud574 JSON \ubb38\uc790\uc5f4\ub85c \uc800\uc7a5\ub429\ub2c8\ub2e4.</p> <pre><code>{\n  \"type\": \"record\",\n  \"name\": \"EventEnvelope\",\n  \"namespace\": \"com.project.curve.core.envelope\",\n  \"fields\": [\n    {\"name\": \"eventId\", \"type\": \"string\"},\n    {\"name\": \"eventType\", \"type\": \"string\"},\n    {\"name\": \"severity\", \"type\": \"string\"},\n    {\"name\": \"metadata\", \"type\": { ... }},\n    {\"name\": \"payload\", \"type\": \"string\"}, // JSON String\n    {\"name\": \"occurredAt\", \"type\": \"long\", \"logicalType\": \"timestamp-millis\"},\n    {\"name\": \"publishedAt\", \"type\": \"long\", \"logicalType\": \"timestamp-millis\"}\n  ]\n}\n</code></pre>"},{"location":"ko/CONFIGURATION/#_23","title":"\uc804\uccb4 \uc124\uc815 \uc608\uc2dc","text":""},{"location":"ko/CONFIGURATION/#_24","title":"\ud504\ub85c\ub355\uc158 \ud658\uacbd (\uc548\uc815\uc131 \uc911\uc2dc)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${INSTANCE_ID}  # \ud658\uacbd \ubcc0\uc218\uc5d0\uc11c \uc8fc\uc785\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # \ub3d9\uae30 \uc804\uc1a1\n    retries: 5\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n    # \ubc31\uc5c5 \uc804\ub7b5\n    backup:\n      s3-enabled: true\n      s3-bucket: \"prod-event-backups\"\n      local-enabled: false\n\n  retry:\n    enabled: true\n    max-attempts: 5\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  aop:\n    enabled: true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # \ud658\uacbd \ubcc0\uc218 \ud544\uc218\n      salt: ${PII_HASH_SALT}\n\n  async:\n    enabled: true\n    core-pool-size: 4\n    max-pool-size: 20\n    queue-capacity: 1000\n\n  outbox:\n    enabled: true\n    initialize-schema: never  # Flyway \uc0ac\uc6a9\n    cleanup-enabled: true\n    retention-days: 14\n</code></pre>"},{"location":"ko/CONFIGURATION/#_25","title":"\uac1c\ubc1c/\ud14c\uc2a4\ud2b8 \ud658\uacbd (\uc131\ub2a5 \uc911\uc2dc)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.dev.v1\n    dlq-topic: event.audit.dlq.dev.v1\n    async-mode: true  # \ube44\ub3d9\uae30 \uc804\uc1a1\n    async-timeout-ms: 3000\n    retries: 3\n\n    backup:\n      local-enabled: true\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 500\n    multiplier: 1.5\n\n  aop:\n    enabled: true\n\n  outbox:\n    enabled: true\n    initialize-schema: always\n\n  async:\n    enabled: true\n</code></pre>"},{"location":"ko/CONFIGURATION/#_26","title":"\uace0\uc131\ub2a5 \ud658\uacbd","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${WORKER_ID}\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: true  # \ube44\ub3d9\uae30 \uc804\uc1a1\n    async-timeout-ms: 5000\n    retries: 1  # \ucd5c\uc18c \uc7ac\uc2dc\ub3c4\n\n  retry:\n    enabled: false  # \uc7ac\uc2dc\ub3c4 \ube44\ud65c\uc131\ud654 (\uc131\ub2a5 \uc6b0\uc120)\n\n  aop:\n    enabled: true\n\n  async:\n    enabled: true\n    core-pool-size: 8\n    max-pool-size: 32\n    queue-capacity: 2000\n</code></pre>"},{"location":"ko/CONFIGURATION/#_27","title":"\ud658\uacbd\ubcc4 \uad8c\uc7a5 \uc124\uc815","text":""},{"location":"ko/CONFIGURATION/#_28","title":"\ub85c\uceec \uac1c\ubc1c","text":"<ul> <li>Worker ID: 1 (\uace0\uc815)</li> <li>\uc804\uc1a1 \ubaa8\ub4dc: \ub3d9\uae30 (\ub514\ubc84\uae45 \ud3b8\uc758\uc131)</li> <li>DLQ: \ud65c\uc131\ud654</li> <li>\uc7ac\uc2dc\ub3c4: \ucd5c\uc18c\ud654 (\ube60\ub978 \uc2e4\ud328)</li> <li>Outbox: \ud65c\uc131\ud654 (\uc2a4\ud0a4\ub9c8 \uc790\ub3d9 \uc0dd\uc131)</li> <li>\ubc31\uc5c5: \ub85c\uceec \ud30c\uc77c</li> </ul>"},{"location":"ko/CONFIGURATION/#_29","title":"\uc2a4\ud14c\uc774\uc9d5","text":"<ul> <li>Worker ID: \ud658\uacbd \ubcc0\uc218</li> <li>\uc804\uc1a1 \ubaa8\ub4dc: \ube44\ub3d9\uae30</li> <li>DLQ: \ud65c\uc131\ud654</li> <li>\uc7ac\uc2dc\ub3c4: \uc911\uac04 \uc218\uc900</li> <li>Outbox: \ud65c\uc131\ud654</li> <li>\ubc31\uc5c5: S3 (\uac00\ub2a5\ud55c \uacbd\uc6b0) \ub610\ub294 \ub85c\uceec</li> </ul>"},{"location":"ko/CONFIGURATION/#_30","title":"\ud504\ub85c\ub355\uc158","text":"<ul> <li>Worker ID: \uc911\uc559 \uad00\ub9ac (Consul/etcd)</li> <li>\uc804\uc1a1 \ubaa8\ub4dc: \ube44\uc988\ub2c8\uc2a4 \uc694\uac74\uc5d0 \ub530\ub77c \uacb0\uc815</li> <li>DLQ: \ud544\uc218 \ud65c\uc131\ud654</li> <li>\uc7ac\uc2dc\ub3c4: \ub192\uc740 \uc218\uc900</li> <li>Outbox: \ud544\uc218 \ud65c\uc131\ud654 (\ub370\uc774\ud130 \uc815\ud569\uc131)</li> <li>\ubc31\uc5c5: S3 (K8s \ud658\uacbd \ud544\uc218)</li> </ul>"},{"location":"ko/CONFIGURATION/#_31","title":"\ud2b8\ub7ec\ube14\uc288\ud305","text":""},{"location":"ko/CONFIGURATION/#worker-id_2","title":"Worker ID \ucda9\ub3cc","text":"<p>\uc99d\uc0c1: \ub3d9\uc77c\ud55c ID\uac00 \uc0dd\uc131\ub428</p> <p>\ud574\uacb0: <pre><code>curve:\n  id-generator:\n    worker-id: ${UNIQUE_INSTANCE_ID}\n</code></pre></p>"},{"location":"ko/CONFIGURATION/#_32","title":"\uc804\uc1a1 \ud0c0\uc784\uc544\uc6c3","text":"<p>\uc99d\uc0c1: <code>TimeoutException</code> \ubc1c\uc0dd</p> <p>\ud574\uacb0: <pre><code>curve:\n  kafka:\n    request-timeout-ms: 60000  # \ud0c0\uc784\uc544\uc6c3 \uc99d\uac00\n</code></pre></p>"},{"location":"ko/CONFIGURATION/#latency","title":"\ub192\uc740 Latency","text":"<p>\uc99d\uc0c1: \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc18d\ub3c4\uac00 \ub290\ub9bc</p> <p>\ud574\uacb0: <pre><code>curve:\n  kafka:\n    async-mode: true  # \ube44\ub3d9\uae30 \ubaa8\ub4dc\ub85c \uc804\ud658\n</code></pre></p>"},{"location":"ko/CONFIGURATION/#pii_3","title":"PII \uc554\ud638\ud654 \ud0a4 \ubbf8\uc124\uc815","text":"<p>\uc99d\uc0c1: <pre><code>ERROR: PII encryption key is not configured!\nERROR: An exception will occur when using @PiiField(strategy = PiiStrategy.ENCRYPT).\n</code></pre></p> <p>\ud574\uacb0: <pre><code># 1. \ud0a4 \uc0dd\uc131\nopenssl rand -base64 32\n\n# 2. \ud658\uacbd \ubcc0\uc218 \uc124\uc815\nexport PII_ENCRYPTION_KEY=generated_key_value\n\n# 3. application.yml \uc124\uc815\ncurve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n</code></pre></p>"},{"location":"ko/CONFIGURATION/#_33","title":"\uc124\uc815 \uc720\ud6a8\uc131 \uac80\uc0ac \uc2e4\ud328","text":"<p>\uc99d\uc0c1: <pre><code>APPLICATION FAILED TO START\nReason: workerId must be 1023 or less\n</code></pre></p> <p>\ud574\uacb0: - \uc124\uc815\uac12\uc774 \uac80\uc99d \uaddc\uce59\uc5d0 \ub9de\ub294\uc9c0 \ud655\uc778 - \uc124\uc815 \uc720\ud6a8\uc131 \uac80\uc0ac \uc139\uc158\uc758 \uaddc\uce59 \ucc38\uc870</p>"},{"location":"ko/CONFIGURATION/#_34","title":"\ub85c\uae45 \uc124\uc815","text":"<p>Curve\ub294 \uae30\ubcf8\uc801\uc73c\ub85c \ucd5c\uc18c\ud55c\uc758 \ub85c\uadf8\ub9cc \ucd9c\ub825\ud569\ub2c8\ub2e4. \uc0c1\uc138\ud55c \uc124\uc815 \uc815\ubcf4\ub098 \ub0b4\ubd80 \ub3d9\uc791\uc744 \ud655\uc778\ud558\ub824\uba74 DEBUG \ub808\ubca8\uc744 \ud65c\uc131\ud654\ud558\uc138\uc694.</p>"},{"location":"ko/CONFIGURATION/#info","title":"\uae30\ubcf8 \ub85c\uae45 (INFO)","text":"<p>\uae30\ubcf8 \uc124\uc815\uc5d0\uc11c\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \ub85c\uadf8\ub9cc \ucd9c\ub825\ub429\ub2c8\ub2e4:</p> <pre><code>INFO  c.p.c.a.CurveAutoConfiguration : Curve auto-configuration enabled (disable with curve.enabled=false)\n</code></pre>"},{"location":"ko/CONFIGURATION/#debug","title":"DEBUG \ub85c\uae45 \ud65c\uc131\ud654","text":"<pre><code>logging:\n  level:\n    com.project.curve: DEBUG\n</code></pre>"},{"location":"ko/CONFIGURATION/#debug_1","title":"DEBUG \ub808\ubca8\uc5d0\uc11c \ud655\uc778 \uac00\ub2a5\ud55c \uc815\ubcf4","text":"\ud56d\ubaa9 \uc124\uba85 Kafka Producer \uc124\uc815 retries, timeout, async-mode \ub4f1 \uc0c1\uc138 \uc124\uc815\uac12 RetryTemplate \uc124\uc815 max-attempts, backoff \uc815\ucc45 \uc0c1\uc138 SnowflakeIdGenerator Worker ID \ubc0f \ucd08\uae30\ud654 \uc815\ubcf4 DLQ ExecutorService \uc2a4\ub808\ub4dc \ud480 \ud06c\uae30, \uc885\ub8cc \ud0c0\uc784\uc544\uc6c3 PII \ubaa8\ub4c8 \uc554\ud638\ud654/\uc194\ud2b8 \uc124\uc815 \uc0c1\ud0dc, \ubaa8\ub4c8 \ub4f1\ub85d \uc5ec\ubd80 \uc774\ubca4\ud2b8 \uc804\uc1a1 \uc774\ubca4\ud2b8\ubcc4 \uc804\uc1a1 \ub0b4\uc5ed (eventId, topic, partition, offset) Outbox Publisher \ud3f4\ub9c1, \ubc1c\ud589, \uc815\ub9ac \uc791\uc5c5 \ub85c\uadf8"},{"location":"ko/CONFIGURATION/#debug_2","title":"\ud2b9\uc815 \ubaa8\ub4c8\ub9cc DEBUG \ud65c\uc131\ud654","text":"<pre><code>logging:\n  level:\n    # Kafka \uc804\uc1a1 \uad00\ub828\ub9cc DEBUG\n    com.project.curve.kafka: DEBUG\n\n    # Auto-Configuration \uad00\ub828\ub9cc DEBUG\n    com.project.curve.autoconfigure: DEBUG\n\n    # PII \ucc98\ub9ac \uad00\ub828\ub9cc DEBUG\n    com.project.curve.spring.pii: DEBUG\n\n    # Outbox \uad00\ub828\ub9cc DEBUG\n    com.project.curve.spring.outbox: DEBUG\n</code></pre>"},{"location":"ko/CONFIGURATION/#_35","title":"\ucd94\uac00 \uc815\ubcf4","text":"<ul> <li>Snowflake ID \uc54c\uace0\ub9ac\uc998</li> <li>Kafka Producer \uc124\uc815</li> <li>Spring Retry</li> <li>Transactional Outbox \ud328\ud134</li> </ul>"},{"location":"ko/OPERATIONS/","title":"Curve \uc6b4\uc601 \uac00\uc774\ub4dc","text":"<p>\uc774 \ubb38\uc11c\ub294 Curve \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc2dc\uc2a4\ud15c\uc758 \ubaa8\ub2c8\ud130\ub9c1, \ud2b8\ub7ec\ube14\uc288\ud305, \ubcf5\uad6c \uc808\ucc28\ub97c \uc124\uba85\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/OPERATIONS/#_1","title":"\ubaa9\ucc28","text":"<ul> <li>DLQ \ubaa8\ub2c8\ud130\ub9c1</li> <li>\uba54\ud2b8\ub9ad \ud574\uc11d</li> <li>\ud2b8\ub7ec\ube14\uc288\ud305 \ub9e4\ud2b8\ub9ad\uc2a4</li> <li>\ubcf5\uad6c \uc808\ucc28</li> <li>\uc54c\ub9bc \uc124\uc815</li> <li>Runbook \uccb4\ud06c\ub9ac\uc2a4\ud2b8</li> </ul>"},{"location":"ko/OPERATIONS/#dlq","title":"DLQ \ubaa8\ub2c8\ud130\ub9c1","text":""},{"location":"ko/OPERATIONS/#3","title":"3\ub2e8\uacc4 \uc7a5\uc560 \ubcf5\uad6c \uc774\ud574","text":"<p>Curve\ub294 \uc774\ubca4\ud2b8 \uc720\uc2e4\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574 3\ub2e8\uacc4 \uc7a5\uc560 \ubcf5\uad6c \uc2dc\uc2a4\ud15c\uc744 \uad6c\ud604\ud569\ub2c8\ub2e4:</p> <pre><code>\uc774\ubca4\ud2b8 \uc804\uc1a1 \uc2dc\ub3c4\n        \u2502\n        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  1\ub2e8\uacc4: \uba54\uc778    \u2502\u2500\u2500\u2500\u2500 \uc131\uacf5 \u2500\u2500\u2500\u25b6 \uc774\ubca4\ud2b8 \ubc1c\ud589\ub428\n\u2502     \ud1a0\ud53d        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 \uc2e4\ud328\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  2\ub2e8\uacc4: DLQ     \u2502\u2500\u2500\u2500\u2500 \uc131\uacf5 \u2500\u2500\u2500\u25b6 DLQ \ud1a0\ud53d\uc5d0 \uc800\uc7a5\n\u2502     \ud1a0\ud53d        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 \uc2e4\ud328\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3\ub2e8\uacc4: \ub85c\uceec     \u2502\u2500\u2500\u2500\u2500 \uc131\uacf5 \u2500\u2500\u2500\u25b6 JSON \ud30c\uc77c \ubc31\uc5c5\n\u2502     \ubc31\uc5c5        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 \uc2e4\ud328\n         \u25bc\n    \uc774\ubca4\ud2b8 \uc720\uc2e4 + \uc54c\ub9bc\n</code></pre> \ub2e8\uacc4 \uad6c\uc131 \uc694\uc18c \ud2b8\ub9ac\uac70 \uc124\uba85 1 \uba54\uc778 \ud1a0\ud53d \uc815\uc0c1 \ub3d9\uc791 \uc124\uc815\ub41c Kafka \ud1a0\ud53d\uc73c\ub85c \uc774\ubca4\ud2b8 \ubc1c\ud589 2 DLQ \ud1a0\ud53d \uba54\uc778 \ud1a0\ud53d \uc2e4\ud328 \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8\ub97c Dead Letter Queue\ub85c \uc804\uc1a1 3 \ub85c\uceec \ud30c\uc77c DLQ \uc2e4\ud328 \uc774\ubca4\ud2b8\ub97c <code>./dlq-backup/</code> \ub514\ub809\ud1a0\ub9ac\uc5d0 \ubc31\uc5c5"},{"location":"ko/OPERATIONS/#dlq_1","title":"DLQ \uc774\ubca4\ud2b8 \ubaa8\ub2c8\ud130\ub9c1","text":""},{"location":"ko/OPERATIONS/#kafka-ui","title":"Kafka UI \uc0ac\uc6a9","text":"<ol> <li>Kafka UI \uc811\uc18d (\uae30\ubcf8: http://localhost:8080)</li> <li>\uba54\ub274\uc5d0\uc11c Topics \uc120\ud0dd</li> <li><code>event.audit.dlq.v1</code> (\ub610\ub294 \uc124\uc815\ub41c DLQ \ud1a0\ud53d) \ucc3e\uae30</li> <li>Messages \ud0ed\uc5d0\uc11c \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8 \ud655\uc778</li> </ol>"},{"location":"ko/OPERATIONS/#actuator","title":"Actuator \uc5d4\ub4dc\ud3ec\uc778\ud2b8 \uc0ac\uc6a9","text":"<pre><code># DLQ \uba54\ud2b8\ub9ad \uc870\ud68c\ncurl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n</code></pre> <p>\uc751\ub2f5: <pre><code>{\n  \"totalEventsPublished\": 1523,\n  \"successfulEvents\": 1520,\n  \"failedEvents\": 3,\n  \"successRate\": \"99.80%\",\n  \"totalDlqEvents\": 3,\n  \"totalKafkaErrors\": 0\n}\n</code></pre></p>"},{"location":"ko/OPERATIONS/#kafka-cli","title":"Kafka CLI \uc0ac\uc6a9","text":"<pre><code># DLQ \ud1a0\ud53d \uba54\uc2dc\uc9c0 \uc218 \ud655\uc778\nkafka-run-class.sh kafka.tools.GetOffsetShell \\\n  --broker-list localhost:9092 \\\n  --topic event.audit.dlq.v1\n\n# DLQ \uba54\uc2dc\uc9c0 \uc18c\ube44\nkafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic event.audit.dlq.v1 \\\n  --from-beginning\n</code></pre>"},{"location":"ko/OPERATIONS/#dlq_2","title":"DLQ \uba54\uc2dc\uc9c0 \uad6c\uc870","text":"<pre><code>{\n  \"eventId\": \"123456789012345678\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"originalPayload\": \"{\\\"eventType\\\":\\\"ORDER_CREATED\\\",...}\",\n  \"exceptionType\": \"org.apache.kafka.common.errors.TimeoutException\",\n  \"exceptionMessage\": \"Failed to send message after 3 retries\",\n  \"failedAt\": 1704067200000\n}\n</code></pre> \ud544\ub4dc \uc124\uba85 <code>eventId</code> \uace0\uc720 \uc774\ubca4\ud2b8 \uc2dd\ubcc4\uc790 (Snowflake ID) <code>originalTopic</code> \uc774\ubca4\ud2b8\uac00 \uc804\uc1a1\ub418\ub824\ub358 \ud1a0\ud53d <code>originalPayload</code> \uc804\uccb4 \uc774\ubca4\ud2b8 \ud398\uc774\ub85c\ub4dc (JSON \ubb38\uc790\uc5f4) <code>exceptionType</code> \uc2e4\ud328\ub97c \uc720\ubc1c\ud55c Java \uc608\uc678 \ud074\ub798\uc2a4 <code>exceptionMessage</code> \uc0ac\ub78c\uc774 \uc77d\uc744 \uc218 \uc788\ub294 \uc5d0\ub7ec \uba54\uc2dc\uc9c0 <code>failedAt</code> \uc2e4\ud328 \ubc1c\uc0dd \uc2dc\uac01 (epoch milliseconds)"},{"location":"ko/OPERATIONS/#_2","title":"\ub85c\uceec \ubc31\uc5c5 \ud30c\uc77c","text":"<p>\uc704\uce58: <code>./dlq-backup/</code> (<code>curve.kafka.dlq-backup-path</code>\ub85c \uc124\uc815 \uac00\ub2a5)</p> <pre><code># \ubc31\uc5c5 \ud30c\uc77c \ubaa9\ub85d\nls -la ./dlq-backup/\n\n# \uc608\uc2dc \ucd9c\ub825:\n# -rw------- 1 user user 2048 Jan 20 10:30 123456789012345678.json\n# -rw------- 1 user user 1856 Jan 20 10:31 123456789012345679.json\n</code></pre> <p>\ud30c\uc77c\uba85: <code>{eventId}.json</code></p> <p>\ud30c\uc77c \uad8c\ud55c: - POSIX \uc2dc\uc2a4\ud15c: <code>600</code> (rw-------) - Windows: \uc18c\uc720\uc790\ub9cc \uc811\uadfc \uac00\ub2a5\ud55c ACL</p>"},{"location":"ko/OPERATIONS/#_3","title":"\uba54\ud2b8\ub9ad \ud574\uc11d","text":""},{"location":"ko/OPERATIONS/#_4","title":"\uba54\ud2b8\ub9ad \uc811\uadfc","text":"<pre><code># \uc804\uccb4 \uba54\ud2b8\ub9ad \ub9ac\ud3ec\ud2b8\ncurl http://localhost:8081/actuator/curve-metrics\n\n# \uc694\uc57d \uc815\ubcf4\ub9cc\ncurl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n\n# \ud2b9\uc815 \uba54\ud2b8\ub9ad\ncurl http://localhost:8081/actuator/curve-metrics | jq '.events.published'\n</code></pre>"},{"location":"ko/OPERATIONS/#_5","title":"\uc8fc\uc694 \uba54\ud2b8\ub9ad \ucc38\uc870","text":"\uba54\ud2b8\ub9ad \uc124\uba85 \uacbd\uace0 \uc784\uacc4\uac12 \uc704\ud5d8 \uc784\uacc4\uac12 <code>successRate</code> \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc131\uacf5\ub960 &lt; 99% &lt; 95% <code>totalDlqEvents</code> DLQ\ub85c \uc804\uc1a1\ub41c \uc774\ubca4\ud2b8 \uc218 &gt; 0 &gt; 10 (\uc99d\uac00 \ucd94\uc138) <code>totalKafkaErrors</code> Kafka \ud504\ub85c\ub4c0\uc11c \uc5d0\ub7ec \uc218 &gt; 0 &gt; 5 <code>curve.events.retry.count</code> \uc7ac\uc2dc\ub3c4 \ud69f\uc218 \uc99d\uac00\ud568 \uae09\uaca9\ud788 \uc99d\uac00\ud568 <code>curve.events.publish.duration</code> \ubc1c\ud589 \uc9c0\uc5f0 \uc2dc\uac04 &gt; 100ms \ud3c9\uade0 &gt; 500ms \ud3c9\uade0"},{"location":"ko/OPERATIONS/#_6","title":"\uc0c1\ud0dc \ud574\uc11d","text":"\uc0c1\ud0dc \uc9c0\ud45c \uc758\ubbf8 \uc870\uce58 \uc815\uc0c1 successRate &gt;= 99.5%, totalDlqEvents = 0 \uc815\uc0c1 \ub3d9\uc791 \ubaa8\ub2c8\ud130\ub9c1 \uacbd\uace0 successRate 95-99.5%, totalDlqEvents &gt; 0 \uc548\uc815\uc801 \uac04\ud5d0\uc801 \ubb38\uc81c \uc870\uc0ac \ud544\uc694 \uc704\ud5d8 successRate &lt; 95%, totalDlqEvents \uc99d\uac00 \uc911 \uc2dc\uc2a4\ud15c \uc7a5\uc560 \uc989\uc2dc \uc870\uce58"},{"location":"ko/OPERATIONS/#outbox-publisher","title":"Outbox Publisher \uba54\ud2b8\ub9ad","text":"<p>Transactional Outbox \ud328\ud134 \uc0ac\uc6a9\uc790\uc6a9:</p> \uba54\ud2b8\ub9ad \uc124\uba85 \ube44\uc815\uc0c1 \uc2dc \uc870\uce58 <code>circuitBreakerState</code> CLOSED/OPEN/HALF-OPEN OPEN = Kafka \uc5f0\uacb0 \ubb38\uc81c <code>consecutiveFailures</code> \uc5f0\uc18d \uc2e4\ud328 \ud69f\uc218 &gt; 3 = \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc5f4\ub9b4 \uac00\ub2a5\uc131 <code>timeSinceLastSuccessMs</code> \ub9c8\uc9c0\ub9c9 \uc131\uacf5 \uc774\ud6c4 \uc2dc\uac04 &gt; 60000 = Kafka \ud655\uc778 <code>totalPending</code> \ub300\uae30 \uc911\uc778 outbox \uc774\ubca4\ud2b8 0\uc73c\ub85c \uc218\ub834\ud574\uc57c \ud568 <code>totalFailed</code> \uc601\uad6c\uc801\uc73c\ub85c \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8 \uc218\ub3d9 \uac1c\uc785 \ud544\uc694"},{"location":"ko/OPERATIONS/#_7","title":"\uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc0c1\ud0dc","text":"\uc0c1\ud0dc \ub3d9\uc791 \uc9c0\uc18d \uc2dc\uac04 \uc804\uc774 CLOSED \uc815\uc0c1 \ub3d9\uc791 - 5\ud68c \uc5f0\uc18d \uc2e4\ud328 \uc2dc \uc5f4\ub9bc OPEN \ubaa8\ub4e0 \uc694\uccad \ucc28\ub2e8 60\ucd08 HALF-OPEN\uc73c\ub85c \uc804\uc774 HALF-OPEN \ud14c\uc2a4\ud2b8 \uc694\uccad \ud5c8\uc6a9 \uc131\uacf5/\uc2e4\ud328 \uc2dc\uae4c\uc9c0 \uc131\uacf5\u2192CLOSED, \uc2e4\ud328\u2192OPEN"},{"location":"ko/OPERATIONS/#_8","title":"\ud2b8\ub7ec\ube14\uc288\ud305 \ub9e4\ud2b8\ub9ad\uc2a4","text":""},{"location":"ko/OPERATIONS/#_9","title":"\uc99d\uc0c1 \ubc0f \ud574\uacb0\ucc45","text":"\uc99d\uc0c1 \uac00\ub2a5\ud55c \uc6d0\uc778 \ud655\uc778 \ubc29\ubc95 \ud574\uacb0\ucc45 \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc548 \ub428 AOP \ube44\ud65c\uc131\ud654 \uc124\uc815 <code>curve.aop.enabled</code> \ud655\uc778 <code>true</code>\ub85c \uc124\uc815 \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc548 \ub428 \uba54\uc11c\ub4dc\uac00 public \uc544\ub2d8 \uba54\uc11c\ub4dc \uc2dc\uadf8\ub2c8\ucc98 \ud655\uc778 \uba54\uc11c\ub4dc\ub97c <code>public</code>\uc73c\ub85c \ubcc0\uacbd <code>TimeoutException</code> Kafka \uc751\ub2f5 \uc5c6\uc74c <code>docker-compose ps kafka</code> Kafka \uc7ac\uc2dc\uc791 <code>TimeoutException</code> \ub124\ud2b8\uc6cc\ud06c \uc9c0\uc5f0 \ube0c\ub85c\ucee4 \ud551 \ud14c\uc2a4\ud2b8 <code>request-timeout-ms</code> \uc99d\uac00 \ub192\uc740 DLQ \uce74\uc6b4\ud2b8 Kafka \ube0c\ub85c\ucee4 \ub2e4\uc6b4 \ube0c\ub85c\ucee4 \ub85c\uadf8 \ud655\uc778 Kafka \ubcf5\uad6c, DLQ \ubcf5\uad6c \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 OPEN 5\ud68c \uc774\uc0c1 \uc5f0\uc18d \uc2e4\ud328 Kafka \uc0c1\ud0dc \ud655\uc778 60\ucd08 \ub300\uae30 \ub610\ub294 Kafka \uc218\uc815 \ub85c\uceec \ubc31\uc5c5 \ud30c\uc77c \uc874\uc7ac \uba54\uc778 \ubc0f DLQ \ubaa8\ub450 \uc2e4\ud328 \ubaa8\ub4e0 Kafka \uc5f0\uacb0 \ud655\uc778 \uc218\ub3d9 \ubcf5\uad6c \ud544\uc694 PII \uc554\ud638\ud654 \uc5d0\ub7ec \uc554\ud638\ud654 \ud0a4 \ub204\ub77d <code>PII_ENCRYPTION_KEY</code> \ud658\uacbd\ubcc0\uc218 \ud655\uc778 \ud658\uacbd \ubcc0\uc218 \uc124\uc815 Worker ID \ucda9\ub3cc \uc911\ubcf5\ub41c Worker ID \uc778\uc2a4\ud134\uc2a4 \uc124\uc815 \ud655\uc778 \uace0\uc720 ID \ud560\ub2f9 Outbox \uc774\ubca4\ud2b8 PENDING \uace0\ucc29 Kafka \ub3c4\ub2ec \ubd88\uac00 \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc0c1\ud0dc \ud655\uc778 Kafka \uc5f0\uacb0 \uc218\uc815 \ub290\ub9b0 \uc774\ubca4\ud2b8 \ubc1c\ud589 \ub192\uc740 \ubd80\ud558\uc5d0\uc11c \ub3d9\uae30 \ubaa8\ub4dc <code>async-mode</code> \ud655\uc778 \ube44\ub3d9\uae30 \ubaa8\ub4dc \ud65c\uc131\ud654 <code>ClockMovedBackwardsException</code> \uc2dc\uc2a4\ud15c \uc2dc\uac04 \ubcc0\uacbd NTP \ub3d9\uae30\ud654 \ud655\uc778 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc7ac\uc2dc\uc791"},{"location":"ko/OPERATIONS/#_10","title":"\uc77c\ubc18\uc801\uc778 \uc5d0\ub7ec \uba54\uc2dc\uc9c0","text":"\uc5d0\ub7ec \uba54\uc2dc\uc9c0 \uc6d0\uc778 \ud574\uacb0\ucc45 <code>Kafka topic is required</code> \ud1a0\ud53d \uc124\uc815 \ub204\ub77d <code>curve.kafka.topic</code> \uc124\uc815 <code>workerId must be between 0 and 1023</code> \uc798\ubabb\ub41c Worker ID \uc720\ud6a8\ud55c \ubc94\uc704 \uc0ac\uc6a9 <code>PII encryption key is not configured</code> \uc554\ud638\ud654 \ud0a4 \ub204\ub77d <code>PII_ENCRYPTION_KEY</code> \ud658\uacbd\ubcc0\uc218 \uc124\uc815 <code>Failed to send message after N retries</code> Kafka \uc5f0\uacb0 \ubb38\uc81c \ube0c\ub85c\ucee4 \uc0c1\ud0dc \ud655\uc778 <code>Circuit breaker is OPEN</code> \ub108\ubb34 \ub9ce\uc740 \uc5f0\uc18d \uc2e4\ud328 Half-open \ub300\uae30 \ub610\ub294 Kafka \uc218\uc815"},{"location":"ko/OPERATIONS/#_11","title":"\ud5ec\uc2a4 \uccb4\ud06c \uc751\ub2f5","text":"<pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre> \uc0c1\ud0dc \uc0c1\uc138 \uc758\ubbf8 \uc870\uce58 UP <code>clusterId</code>, <code>nodeCount</code> \ud3ec\ud568 \uc815\uc0c1, \ube0c\ub85c\ucee4 \uc5f0\uacb0\ub428 \uc5c6\uc74c DOWN \uc5d0\ub7ec \uba54\uc2dc\uc9c0 \ube0c\ub85c\ucee4 \ub3c4\ub2ec \ubd88\uac00 \ub610\ub294 \uc5f0\uacb0 \ubb38\uc81c Kafka \uc124\uc815 \ubc0f \ub124\ud2b8\uc6cc\ud06c \ud655\uc778"},{"location":"ko/OPERATIONS/#_12","title":"\ubcf5\uad6c \uc808\ucc28","text":""},{"location":"ko/OPERATIONS/#1-dlq","title":"\uc808\ucc28 1: DLQ \uc774\ubca4\ud2b8 \ubcf5\uad6c","text":"<p>\uc0ac\uc6a9 \uc2dc\uae30: \uc77c\uc2dc\uc801\uc778 Kafka \ubb38\uc81c\uac00 \ud574\uacb0\ub41c \ud6c4 DLQ \ud1a0\ud53d\uc5d0 \uc774\ubca4\ud2b8\uac00 \uc313\uc5ec\uc788\uc744 \ub54c.</p> <p>\uc804\uc81c \uc870\uac74: - Kafka\uac00 \uc815\uc0c1 \uc0c1\ud0dc\uc784 - <code>kafka-console-producer.sh</code>\uac00 PATH\uc5d0 \uc788\uc74c - DLQ \ud1a0\ud53d \uc811\uadfc \uac00\ub2a5</p> <p>\ub2e8\uacc4:</p> <ol> <li> <p>Kafka \uc0c1\ud0dc \ud655\uc778: <pre><code># Kafka \ucee8\ud14c\uc774\ub108 \ud655\uc778\ndocker-compose ps kafka\n\n# Curve \ud5ec\uc2a4 \uccb4\ud06c\ncurl http://localhost:8081/actuator/health/curve\n</code></pre></p> </li> <li> <p>\ubcf5\uad6c\ud560 DLQ \uc774\ubca4\ud2b8 \ubaa9\ub85d \ud655\uc778: <pre><code>./scripts/dlq-recovery.sh --list\n</code></pre></p> </li> <li> <p>\ubcf5\uad6c \uc2e4\ud589: <pre><code>./scripts/dlq-recovery.sh \\\n  --topic event.audit.v1 \\\n  --broker localhost:9092 \\\n  --dir ./dlq-backup\n</code></pre></p> </li> <li> <p>\ud2b9\uc815 \ud30c\uc77c \ubcf5\uad6c: <pre><code>./scripts/dlq-recovery.sh \\\n  --file 123456789012345678.json \\\n  --topic event.audit.v1 \\\n  --broker localhost:9092\n</code></pre></p> </li> <li> <p>\ubcf5\uad6c \ud655\uc778:</p> </li> <li>Kafka UI\uc5d0\uc11c \ubcf5\uad6c\ub41c \uc774\ubca4\ud2b8 \ud655\uc778</li> <li>\ubc31\uc5c5 \ud30c\uc77c\uc774 \ucc98\ub9ac\ub418\uc5c8\ub294\uc9c0 \ud655\uc778 (<code>recovered/</code> \ud558\uc704 \ub514\ub809\ud1a0\ub9ac\ub85c \uc774\ub3d9\ub428)</li> </ol>"},{"location":"ko/OPERATIONS/#2","title":"\uc808\ucc28 2: \ub85c\uceec \ubc31\uc5c5 \ud30c\uc77c \ubcf5\uad6c","text":"<p>\uc0ac\uc6a9 \uc2dc\uae30: \uba54\uc778 \ud1a0\ud53d\uacfc DLQ \ubaa8\ub450 \uc2e4\ud328\ud558\uc5ec \ub85c\uceec \ud30c\uc77c\uc5d0 \ubc31\uc5c5\ub418\uc5c8\uc744 \ub54c.</p> <p>\ub2e8\uacc4:</p> <ol> <li> <p>\ubc31\uc5c5 \ud30c\uc77c \ubaa9\ub85d \ud655\uc778: <pre><code>ls -la ./dlq-backup/*.json\n</code></pre></p> </li> <li> <p>JSON \ud615\uc2dd \uac80\uc99d: <pre><code># \ubaa8\ub4e0 \ud30c\uc77c \ud655\uc778\nfor f in ./dlq-backup/*.json; do\n  jq empty \"$f\" 2&gt;/dev/null || echo \"Invalid: $f\"\ndone\n</code></pre></p> </li> <li> <p>\ubcf5\uad6c \uc2a4\ud06c\ub9bd\ud2b8 \uc0ac\uc6a9: <pre><code>./scripts/dlq-recovery.sh \\\n  --dir ./dlq-backup \\\n  --topic event.audit.v1 \\\n  --broker localhost:9092\n</code></pre></p> </li> <li> <p>\uc218\ub3d9 \ubcf5\uad6c (\uc2a4\ud06c\ub9bd\ud2b8 \uc2e4\ud328 \uc2dc): <pre><code># \uac01 \ubc31\uc5c5 \ud30c\uc77c\uc5d0 \ub300\ud574\nEVENT_ID=\"123456789012345678\"\n\ncat ./dlq-backup/${EVENT_ID}.json | \\\n  kafka-console-producer.sh \\\n  --broker-list localhost:9092 \\\n  --topic event.audit.v1\n</code></pre></p> </li> <li> <p>\ubcf5\uad6c\ub41c \ud30c\uc77c \uc544\uce74\uc774\ube59: <pre><code>mkdir -p ./dlq-backup/recovered\nmv ./dlq-backup/*.json ./dlq-backup/recovered/\n</code></pre></p> </li> </ol>"},{"location":"ko/OPERATIONS/#3-outbox","title":"\uc808\ucc28 3: Outbox \uc774\ubca4\ud2b8 \ubcf5\uad6c","text":"<p>\uc0ac\uc6a9 \uc2dc\uae30: \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \ubb38\uc81c \ud6c4 Outbox \uc774\ubca4\ud2b8\uac00 FAILED \uc0c1\ud0dc\ub85c \uace0\ucc29\ub418\uc5c8\uc744 \ub54c.</p> <p>\ub2e8\uacc4:</p> <ol> <li> <p>Outbox \ud1b5\uacc4 \ud655\uc778: <pre><code>curl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n</code></pre></p> </li> <li> <p>\uc2e4\ud328\ud55c \uc774\ubca4\ud2b8 \uc870\ud68c (DB \uc811\uadfc \ud544\uc694): <pre><code>-- \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8 \ubaa9\ub85d\nSELECT id, event_id, aggregate_type, aggregate_id, status, retry_count, last_error\nFROM curve_outbox_event\nWHERE status = 'FAILED'\nORDER BY occurred_at DESC\nLIMIT 100;\n\n-- \uc0c1\ud0dc\ubcc4 \uce74\uc6b4\ud2b8\nSELECT status, COUNT(*) as count\nFROM curve_outbox_event\nGROUP BY status;\n</code></pre></p> </li> <li> <p>\uc7ac\uc2dc\ub3c4\ub97c \uc704\ud574 \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8 \ub9ac\uc14b: <pre><code>-- \ud2b9\uc815 \uc774\ubca4\ud2b8 \ub9ac\uc14b\nUPDATE curve_outbox_event\nSET status = 'PENDING', retry_count = 0, last_error = NULL, next_retry_at = NOW()\nWHERE id = 'specific-event-id';\n\n-- \ubaa8\ub4e0 \uc2e4\ud328 \uc774\ubca4\ud2b8 \ub9ac\uc14b (\uc8fc\uc758\ud574\uc11c \uc0ac\uc6a9)\nUPDATE curve_outbox_event\nSET status = 'PENDING', retry_count = 0, last_error = NULL, next_retry_at = NOW()\nWHERE status = 'FAILED';\n</code></pre></p> </li> <li> <p>\ubcf5\uad6c \ubaa8\ub2c8\ud130\ub9c1: <pre><code>watch -n 5 'curl -s http://localhost:8081/actuator/curve-metrics | jq \".summary\"'\n</code></pre></p> </li> </ol>"},{"location":"ko/OPERATIONS/#4","title":"\uc808\ucc28 4: \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \ub9ac\uc14b","text":"<p>\uc0ac\uc6a9 \uc2dc\uae30: Kafka \ubcf5\uad6c \ud6c4\uc5d0\ub3c4 \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4\uac00 OPEN \uc0c1\ud0dc\ub85c \uc720\uc9c0\ub420 \ub54c.</p> <p>\ub2e8\uacc4:</p> <ol> <li> <p>Kafka \uc815\uc0c1 \ud655\uc778: <pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre></p> </li> <li> <p>\uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc0c1\ud0dc \ud655\uc778: <pre><code>curl http://localhost:8081/actuator/curve-metrics | jq '.summary.circuitBreakerState'\n</code></pre></p> </li> <li> <p>\uc790\ub3d9 Half-Open \ub300\uae30 (60\ucd08)</p> </li> </ol> <p>\uc11c\ud0b7 \ube0c\ub808\uc774\ucee4\ub294 60\ucd08 \ud6c4 \uc790\ub3d9\uc73c\ub85c HALF-OPEN \uc0c1\ud0dc\ub85c \uc804\ud658\ub418\uc5b4 \ud14c\uc2a4\ud2b8 \uc694\uccad\uc744 \ud5c8\uc6a9\ud569\ub2c8\ub2e4.</p> <ol> <li> <p>\ub300\uc548: \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc7ac\uc2dc\uc791: <pre><code># \uc6b0\uc544\ud55c \uc885\ub8cc\nkill -TERM $(pgrep -f 'your-application')\n\n# \ub610\ub294 actuator \uc0ac\uc6a9 (\ud65c\uc131\ud654\ub41c \uacbd\uc6b0)\ncurl -X POST http://localhost:8081/actuator/shutdown\n</code></pre></p> </li> <li> <p>\uc0c1\ud0dc \uc804\uc774 \ubaa8\ub2c8\ud130\ub9c1: <pre><code>watch -n 10 'curl -s http://localhost:8081/actuator/curve-metrics | jq \".summary.circuitBreakerState\"'\n</code></pre></p> </li> </ol>"},{"location":"ko/OPERATIONS/#_13","title":"\uc54c\ub9bc \uc124\uc815","text":""},{"location":"ko/OPERATIONS/#prometheus","title":"Prometheus \uc54c\ub9bc \uaddc\uce59","text":"<pre><code>groups:\n  - name: curve-alerts\n    rules:\n      # DLQ \uc774\ubca4\ud2b8 \uc54c\ub9bc\n      - alert: CurveDlqEventsHigh\n        expr: curve_events_dlq_count_total &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"\ub192\uc740 DLQ \uc774\ubca4\ud2b8 \uc218\"\n          description: \"{{ $value }}\uac1c\uc758 \uc774\ubca4\ud2b8\uac00 DLQ\uc5d0 \uc313\uc600\uc2b5\ub2c8\ub2e4.\"\n\n      # \uc131\uacf5\ub960 \uc54c\ub9bc\n      - alert: CurveSuccessRateLow\n        expr: (curve_events_published_success_total / curve_events_published_total) &lt; 0.95\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"\ub0ae\uc740 \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc131\uacf5\ub960\"\n          description: \"\uc131\uacf5\ub960\uc774 {{ $value | humanizePercentage }} \uc785\ub2c8\ub2e4.\"\n\n      # \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc54c\ub9bc\n      - alert: CurveCircuitBreakerOpen\n        expr: curve_circuit_breaker_state == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"\uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 OPEN\"\n          description: \"Outbox \ud37c\ube14\ub9ac\uc154 \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4\uac00 \uc5f4\ub824 \uc774\ubca4\ud2b8\uac00 \ubc1c\ud589\ub418\uc9c0 \uc54a\uace0 \uc788\uc2b5\ub2c8\ub2e4.\"\n\n      # Kafka \ud504\ub85c\ub4c0\uc11c \ub2e4\uc6b4\n      - alert: CurveKafkaProducerDown\n        expr: curve_health_status == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Curve Kafka \ud504\ub85c\ub4c0\uc11c \ub2e4\uc6b4\"\n          description: \"Kafka \ud504\ub85c\ub4c0\uc11c \ucd08\uae30\ud654 \uc2e4\ud328 \ub610\ub294 \ube44\uc815\uc0c1 \uc0c1\ud0dc\uc785\ub2c8\ub2e4.\"\n\n      # \ub192\uc740 \uc9c0\uc5f0 \uc2dc\uac04 \uc54c\ub9bc\n      - alert: CurvePublishLatencyHigh\n        expr: histogram_quantile(0.95, curve_events_publish_duration_seconds_bucket) &gt; 0.5\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"\ub192\uc740 \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc9c0\uc5f0 \uc2dc\uac04\"\n          description: \"95\ubd84\uc704 \uc9c0\uc5f0 \uc2dc\uac04\uc774 {{ $value }}\ucd08 \uc785\ub2c8\ub2e4.\"\n\n      # Outbox \ubc31\ub85c\uadf8 \uc54c\ub9bc\n      - alert: CurveOutboxBacklogHigh\n        expr: curve_outbox_pending_total &gt; 1000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"\ub192\uc740 Outbox \ubc31\ub85c\uadf8\"\n          description: \"{{ $value }}\uac1c\uc758 \uc774\ubca4\ud2b8\uac00 Outbox\uc5d0 \ub300\uae30 \uc911\uc785\ub2c8\ub2e4.\"\n</code></pre>"},{"location":"ko/OPERATIONS/#grafana","title":"Grafana \ub300\uc2dc\ubcf4\ub4dc \ud328\ub110","text":"<p>Curve \ubaa8\ub2c8\ud130\ub9c1 \ub300\uc2dc\ubcf4\ub4dc \ucd94\ucc9c \ud328\ub110:</p> <ol> <li>\uc774\ubca4\ud2b8 \ubc1c\ud589\ub960 - <code>rate(curve_events_published_total[5m])</code></li> <li>\uc131\uacf5\ub960 \uac8c\uc774\uc9c0 - \ud604\uc7ac \uc131\uacf5 \ubc31\ubd84\uc728</li> <li>DLQ \uc774\ubca4\ud2b8 \uc218 - <code>curve_events_dlq_count_total</code> \uc2dc\uac04\ubcc4 \ucd94\uc774</li> <li>\ubc1c\ud589 \uc9c0\uc5f0 \uc2dc\uac04 - <code>histogram_quantile(0.95, curve_events_publish_duration_seconds_bucket)</code></li> <li>\uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc0c1\ud0dc - \ud604\uc7ac \uc0c1\ud0dc \ud45c\uc2dc\uae30 (CLOSED/OPEN/HALF-OPEN)</li> <li>Outbox \ud050 \uae4a\uc774 - <code>curve_outbox_pending_total</code> \uc2dc\uac04\ubcc4 \ucd94\uc774</li> <li>\uc7ac\uc2dc\ub3c4 \ud69f\uc218 - <code>rate(curve_events_retry_count_total[5m])</code></li> <li>Kafka \uc5d0\ub7ec - <code>curve_kafka_producer_errors_total</code> \uc2dc\uac04\ubcc4 \ucd94\uc774</li> </ol>"},{"location":"ko/OPERATIONS/#runbook","title":"Runbook \uccb4\ud06c\ub9ac\uc2a4\ud2b8","text":""},{"location":"ko/OPERATIONS/#_14","title":"\uc77c\uc77c \uc6b4\uc601","text":"<ul> <li>[ ] <code>/actuator/health/curve</code> \uc0c1\ud0dc \ud655\uc778</li> <li>[ ] <code>/actuator/curve-metrics</code> \uc694\uc57d \uac80\ud1a0</li> <li>[ ] DLQ \ud1a0\ud53d\uc774 \ube44\uc5b4\uc788\uac70\ub098 \uc548\uc815\uc801\uc778\uc9c0 \ud655\uc778</li> <li>[ ] <code>./dlq-backup/</code>\uc5d0 \ub85c\uceec \ubc31\uc5c5 \ud30c\uc77c\uc774 \uc788\ub294\uc9c0 \ud655\uc778</li> <li>[ ] \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub85c\uadf8\uc5d0\uc11c WARN/ERROR \ud56d\ubaa9 \uac80\ud1a0</li> </ul>"},{"location":"ko/OPERATIONS/#_15","title":"\uc8fc\uac04 \uc6b4\uc601","text":"<ul> <li>[ ] DLQ \uc774\ubca4\ud2b8 \ud328\ud134 \ubc0f \uadfc\ubcf8 \uc6d0\uc778 \ubd84\uc11d</li> <li>[ ] \ubc1c\ud589 \uc9c0\uc5f0 \uc2dc\uac04 \ucd94\uc138 \ubd84\uc11d</li> <li>[ ] Outbox \uc815\ub9ac \uc791\uc5c5(cleanup job) \uc131\uacf5 \uc5ec\ubd80 \ud655\uc778</li> <li>[ ] \uc624\ub798\ub41c \ubc31\uc5c5 \ud30c\uc77c \uc544\uce74\uc774\ube59 (\uc788\ub294 \uacbd\uc6b0)</li> <li>[ ] \ub85c\uadf8 \uac80\ud1a0 \ubc0f \ub85c\ud14c\uc774\uc158 \ud655\uc778</li> </ul>"},{"location":"ko/OPERATIONS/#_16","title":"\uc0ac\uace0 \ub300\uc751","text":"<ul> <li>[ ] \uc601\ud5a5 \ubc1b\uc740 \uc2dc\uac04 \ubc94\uc704 \uc2dd\ubcc4</li> <li>[ ] \uc11c\ud0b7 \ube0c\ub808\uc774\ucee4 \uc0c1\ud0dc \uc774\ub825 \ud655\uc778</li> <li>[ ] DLQ \ubc0f \ub85c\uceec \ubc31\uc5c5\uc758 \uc774\ubca4\ud2b8 \uc218 \ud655\uc778</li> <li>[ ] \uadfc\ubcf8 \uc6d0\uc778 \ud30c\uc545 (Kafka, \ub124\ud2b8\uc6cc\ud06c, \uc124\uc815)</li> <li>[ ] \uc801\uc808\ud55c \ubcf5\uad6c \uc808\ucc28 \uc2e4\ud589</li> <li>[ ] \uc18c\ube44\uc790\uc5d0\uac8c \uc774\ubca4\ud2b8 \uc804\ub2ec \ud655\uc778</li> <li>[ ] \uc0ac\ud6c4 \ubd84\uc11d(Post-mortem) \ubb38\uc11c\ud654</li> </ul>"},{"location":"ko/OPERATIONS/#_17","title":"\uc6d4\uac04 \uc6b4\uc601","text":"<ul> <li>[ ] \uc54c\ub9bc \uc784\uacc4\uac12 \uac80\ud1a0 \ubc0f \uc870\uc815</li> <li>[ ] \uc131\uacf5\ub960 \ucd94\uc138 \ubd84\uc11d</li> <li>[ ] \uc774\ubca4\ud2b8 \ubcfc\ub968 \uae30\ubc18 \uc6a9\ub7c9 \uacc4\ud68d</li> <li>[ ] \ud544\uc694 \uc2dc \uc774 Runbook \uc5c5\ub370\uc774\ud2b8</li> </ul>"},{"location":"ko/OPERATIONS/#_18","title":"\ucd94\uac00 \ub9ac\uc18c\uc2a4","text":"<ul> <li>\uc124\uc815 \uac00\uc774\ub4dc - \uc0c1\uc138 \uc124\uc815 \uc635\uc158</li> <li>DLQ \ubcf5\uad6c \uc2a4\ud06c\ub9bd\ud2b8 - \uc790\ub3d9\ud654\ub41c \ubcf5\uad6c \ub3c4\uad6c</li> <li>\uc0d8\ud50c \uc560\ud50c\ub9ac\ucf00\uc774\uc158 - \uc791\ub3d9 \uc608\uc2dc</li> <li>README - \ud504\ub85c\uc81d\ud2b8 \uac1c\uc694 \ubc0f \ube60\ub978 \uc2dc\uc791</li> </ul>"}]}