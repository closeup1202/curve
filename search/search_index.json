{"config":{"lang":["en","ko"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Curve","text":"<p>Declarative Event Publishing Library for Spring Boot Microservices</p> <p>Curve is a production-ready library that simplifies event-driven architecture in Spring Boot applications. With a single annotation, you get automatic Kafka publishing, PII masking, DLQ handling, and comprehensive observability.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"GradleMaven <pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.0.2'\n}\n</code></pre> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.0.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"#configuration","title":"Configuration","text":"application.yml<pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9094\n\ncurve:\n  enabled: true\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n</code></pre>"},{"location":"#usage","title":"Usage","text":"OrderService.java<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(eventType = \"ORDER_CREATED\")\n    public Order createOrder(OrderRequest request) {\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre> <p>That's it!  Curve automatically handles:</p> <ul> <li> Event ID generation (Snowflake)</li> <li> Metadata extraction (trace ID, user, IP)</li> <li> PII masking/encryption</li> <li> Kafka publishing with retries</li> <li> Dead Letter Queue (DLQ)</li> <li> Metrics collection</li> </ul> <p>Get Started \u2192 View on GitHub \u2192</p>"},{"location":"#why-curve","title":"Why Curve?","text":""},{"location":"#before-vs-after","title":"Before vs After","text":"<ul> <li> <p> Before (50+ lines)</p> <pre><code>@Service\npublic class UserService {\n    @Autowired KafkaTemplate kafka;\n\n    public User createUser(UserRequest req) {\n        User user = repo.save(new User(req));\n\n        try {\n            // Manual event creation\n            EventEnvelope event = EventEnvelope.builder()\n                .eventId(UUID.randomUUID().toString())\n                .eventType(\"USER_CREATED\")\n                .occurredAt(Instant.now())\n                .metadata(/* ... */)\n                .payload(/* ... */)\n                .build();\n\n            // Manual PII masking\n            String json = maskPii(\n                objectMapper.writeValueAsString(event)\n            );\n\n            // Manual Kafka send\n            kafka.send(\"user-events\", json)\n                .get(30, TimeUnit.SECONDS);\n\n        } catch (Exception e) {\n            log.error(\"Failed\", e);\n            sendToDlq(event);\n        }\n\n        return user;\n    }\n}\n</code></pre> </li> <li> <p> After (1 annotation)</p> <pre><code>@Service\npublic class UserService {\n\n    @PublishEvent(eventType = \"USER_CREATED\")\n    public User createUser(UserRequest req) {\n        return repo.save(new User(req));\n    }\n}\n</code></pre> <p>90% less code </p> </li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p> Declarative Publishing</p> <p>No Kafka boilerplate - just add <code>@PublishEvent</code> annotation. Supports SpEL for flexible payload extraction.</p> <p> Learn more</p> </li> <li> <p> Standardized Events</p> <p>All events follow a unified schema with metadata (source, actor, trace, tags).</p> <p> Event Structure</p> </li> <li> <p> 3-Tier Failure Recovery</p> <p>Main Topic \u2192 DLQ \u2192 Local File Backup</p> <p>Zero event loss even when Kafka is down.</p> <p> Failure Recovery</p> </li> <li> <p> Automatic PII Protection</p> <p><code>@PiiField</code> annotation automatically masks/encrypts sensitive data.</p> <p> PII Protection</p> </li> <li> <p> High Performance</p> <ul> <li>Sync: ~500 TPS</li> <li>Async: ~10,000+ TPS</li> <li>Transactional Outbox: Atomicity guaranteed</li> </ul> <p> Performance</p> </li> <li> <p> Built-in Observability</p> <p>Health checks, custom metrics, and detailed event tracking out of the box.</p> <p> Observability</p> </li> </ul>"},{"location":"#comparison","title":"Comparison","text":"Feature Spring Events Spring Cloud Stream Curve Kafka Integration Declarative Usage  Partial Standardized Schema PII Protection DLQ Support Local File Backup Health Check Transactional Outbox Boilerplate Code Medium High Minimal"},{"location":"#architecture","title":"Architecture","text":"<p>Curve follows Hexagonal Architecture (Ports &amp; Adapters) for maximum flexibility:</p> <pre><code>graph TB\n    A[Domain Layer Core] --&gt; B[Spring Adapter]\n    A --&gt; C[Kafka Adapter]\n    B --&gt; D[AOP / Context]\n    C --&gt; E[Producer / DLQ]\n\n    style A fill:#4051b5\n    style B fill:#00897b\n    style C fill:#00897b\n</code></pre> <p>Core Principles:</p> <ul> <li> Framework-independent domain model</li> <li> Dependency Inversion (DIP)</li> <li> Easy to test and extend</li> </ul> <p> Architecture Details</p>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#1-audit-logging","title":"1. Audit Logging","text":"<pre><code>@PublishEvent(eventType = \"USER_LOGIN\", severity = INFO)\npublic User login(String username, String password) {\n    return authService.authenticate(username, password);\n}\n</code></pre>"},{"location":"#2-event-driven-architecture","title":"2. Event-Driven Architecture","text":"<pre><code>@PublishEvent(eventType = \"ORDER_COMPLETED\")\npublic Order completeOrder(Long orderId) {\n    Order order = orderRepository.findById(orderId);\n    order.setStatus(OrderStatus.COMPLETED);\n    return orderRepository.save(order);\n}\n</code></pre>"},{"location":"#3-data-pipeline","title":"3. Data Pipeline","text":"<pre><code>@PublishEvent(eventType = \"CUSTOMER_REGISTERED\")\npublic Customer registerCustomer(CustomerRequest request) {\n    // Event automatically flows to data lake/warehouse\n    return customerRepository.save(new Customer(request));\n}\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> <p> Getting Started</p> <p>Quick setup guide and your first event in 5 minutes</p> <p> Quick Start</p> </li> <li> <p> Configuration</p> <p>Comprehensive configuration guide for production</p> <p> Configuration</p> </li> <li> <p> Operations</p> <p>Production deployment and best practices</p> <p> Operations</p> </li> <li> <p> Troubleshooting</p> <p>Common issues and solutions</p> <p> Troubleshooting</p> </li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub: closeup1202/curve</li> <li>Issues: Report a bug</li> <li>Email: closeup1202@gmail.com</li> </ul> <p> Contributing Guide</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#ready-to-simplify-your-event-driven-architecture","title":"Ready to simplify your event-driven architecture?","text":"<p>Get Started Now \u2192 View Examples \u2192</p>"},{"location":"CONFIGURATION/","title":"Curve Configuration Guide","text":"<p>This document describes the detailed configuration methods for the Curve event publishing library.</p>"},{"location":"CONFIGURATION/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Basic Configuration</li> <li>Configuration Validation</li> <li>Worker ID Configuration</li> <li>Kafka Transmission Mode Configuration</li> <li>DLQ Configuration</li> <li>Retry Configuration</li> <li>AOP Configuration</li> <li>PII Protection Configuration</li> <li>Outbox Configuration</li> <li>Serialization Configuration</li> <li>Avro Serialization Configuration</li> <li>Logging Configuration</li> </ul>"},{"location":"CONFIGURATION/#basic-configuration","title":"Basic Configuration","text":""},{"location":"CONFIGURATION/#applicationyml","title":"application.yml","text":"<pre><code>curve:\n  enabled: true  # Enable Curve (default: true)\n\n  kafka:\n    topic: event.audit.v1  # Main topic name\n    dlq-topic: event.audit.dlq.v1  # DLQ topic (optional)\n\n  id-generator:\n    worker-id: 1  # Snowflake Worker ID (0~1023)\n    auto-generate: false  # Auto-generate based on MAC address\n</code></pre>"},{"location":"CONFIGURATION/#configuration-validation","title":"Configuration Validation","text":"<p>Curve automatically validates configuration values at application startup using <code>@Validated</code>. If invalid configuration values are entered, the application will fail to start with a clear error message.</p>"},{"location":"CONFIGURATION/#validation-rules","title":"Validation Rules","text":"Configuration Item Validation Rule Error Message <code>curve.kafka.topic</code> Required (non-empty string) \"Kafka topic is required\" <code>curve.kafka.retries</code> 0 or greater \"retries must be 0 or greater\" <code>curve.kafka.retry-backoff-ms</code> Positive number \"retryBackoffMs must be positive\" <code>curve.kafka.request-timeout-ms</code> Positive number \"requestTimeoutMs must be positive\" <code>curve.kafka.async-timeout-ms</code> Positive number \"asyncTimeoutMs must be positive\" <code>curve.kafka.sync-timeout-seconds</code> Positive number \"syncTimeoutSeconds must be positive\" <code>curve.kafka.dlq-executor-threads</code> 1 or greater \"dlqExecutorThreads must be 1 or greater\" <code>curve.id-generator.worker-id</code> 0 ~ 1023 \"workerId must be between 0 and 1023\" <code>curve.retry.max-attempts</code> 1 or greater \"maxAttempts must be 1 or greater\" <code>curve.retry.initial-interval</code> Positive number \"initialInterval must be positive\" <code>curve.retry.multiplier</code> 1 or greater \"multiplier must be 1 or greater\" <code>curve.retry.max-interval</code> Positive number \"maxInterval must be positive\" <code>curve.outbox.poll-interval-ms</code> Positive number \"pollIntervalMs must be positive\" <code>curve.outbox.batch-size</code> 1 ~ 1000 \"batchSize must be between 1 and 1000\" <code>curve.outbox.max-retries</code> 1 or greater \"maxRetries must be 1 or greater\" <code>curve.outbox.send-timeout-seconds</code> Positive number \"sendTimeoutSeconds must be positive\" <code>curve.outbox.retention-days</code> 1 or greater \"retentionDays must be 1 or greater\""},{"location":"CONFIGURATION/#validation-error-example","title":"Validation Error Example","text":"<pre><code>***************************\nAPPLICATION FAILED TO START\n***************************\n\nDescription:\n\nBinding to target org.springframework.boot.context.properties.bind.BindException:\nFailed to bind properties under 'curve' to com.project.curve.autoconfigure.CurveProperties failed:\n\n    Property: curve.id-generator.worker-id\n    Value: \"2000\"\n    Reason: workerId must be 1023 or less\n</code></pre>"},{"location":"CONFIGURATION/#worker-id-configuration","title":"Worker ID Configuration","text":"<p>The Snowflake ID Generator uses a Worker ID to generate unique IDs in a distributed environment.</p>"},{"location":"CONFIGURATION/#method-1-explicit-worker-id-configuration-recommended","title":"Method 1: Explicit Worker ID Configuration (Recommended)","text":"<p>Assign a unique Worker ID to each instance.</p> <pre><code>curve:\n  id-generator:\n    worker-id: 1  # Instance 1\n    auto-generate: false\n</code></pre> <p>Kubernetes Environment Example:</p> <pre><code># deployment.yaml\nenv:\n  - name: CURVE_ID_GENERATOR_WORKER_ID\n    valueFrom:\n      fieldRef:\n        fieldPath: metadata.uid  # Use hashed Pod UID\n</code></pre> <p>Docker Compose Example:</p> <pre><code># docker-compose.yml\nservices:\n  app-1:\n    environment:\n      - CURVE_ID_GENERATOR_WORKER_ID=1\n  app-2:\n    environment:\n      - CURVE_ID_GENERATOR_WORKER_ID=2\n</code></pre>"},{"location":"CONFIGURATION/#method-2-auto-generation-caution","title":"Method 2: Auto-Generation (Caution)","text":"<p>Auto-generate Worker ID based on MAC address.</p> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre> <p>\u26a0\ufe0f Caution: - In virtual environments, MAC addresses may be identical, leading to conflicts - MAC addresses may change when containers restart - Explicit configuration is recommended for production environments</p>"},{"location":"CONFIGURATION/#worker-id-range","title":"Worker ID Range","text":"<ul> <li>Minimum value: 0</li> <li>Maximum value: 1023</li> <li>Recommended: Manage using environment variables or configuration management systems (Consul, etcd)</li> </ul>"},{"location":"CONFIGURATION/#kafka-transmission-mode-configuration","title":"Kafka Transmission Mode Configuration","text":"<p>Curve supports both synchronous and asynchronous transmission modes.</p>"},{"location":"CONFIGURATION/#synchronous-transmission-default","title":"Synchronous Transmission (Default)","text":"<pre><code>curve:\n  kafka:\n    async-mode: false  # Synchronous transmission\n    request-timeout-ms: 30000  # 30 seconds\n</code></pre> <p>Characteristics: - \u2705 Guaranteed transmission (clear success/failure confirmation) - \u2705 Easy error handling - \u274c Performance degradation (blocking) - \u274c Limited throughput</p> <p>Suitable for: - Financial transactions, payments, etc. where accuracy is critical - Cases where event loss is not acceptable - Low throughput (tens to hundreds of TPS)</p>"},{"location":"CONFIGURATION/#asynchronous-transmission","title":"Asynchronous Transmission","text":"<pre><code>curve:\n  kafka:\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000  # 5 seconds timeout\n</code></pre> <p>Characteristics: - \u2705 High performance (non-blocking) - \u2705 High throughput capability - \u26a0\ufe0f Callback-based error handling - \u26a0\ufe0f Relies on DLQ in case of transmission failure</p> <p>Suitable for: - Logs, analytics events, etc. where some loss is acceptable - High throughput required (thousands to tens of thousands of TPS) - Cases where latency is critical</p>"},{"location":"CONFIGURATION/#performance-comparison","title":"Performance Comparison","text":"Item Synchronous Transmission Asynchronous Transmission Throughput (TPS) ~500 ~10,000+ Latency High (10-50ms) Low (1-5ms) Transmission Guarantee Strong Moderate (DLQ dependent) Resource Usage High Low"},{"location":"CONFIGURATION/#dlq-configuration","title":"DLQ Configuration","text":"<p>The Dead Letter Queue stores events that fail to be transmitted.</p>"},{"location":"CONFIGURATION/#enable-dlq","title":"Enable DLQ","text":"<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # Enable DLQ\n</code></pre>"},{"location":"CONFIGURATION/#disable-dlq","title":"Disable DLQ","text":"<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic:  # Empty value or not configured\n</code></pre> <p>\u26a0\ufe0f Caution: Disabling DLQ may result in event loss in case of transmission failure.</p>"},{"location":"CONFIGURATION/#dlq-message-structure","title":"DLQ Message Structure","text":"<pre><code>{\n  \"eventId\": \"123456789\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"originalPayload\": \"{...}\",\n  \"exceptionType\": \"org.apache.kafka.common.errors.TimeoutException\",\n  \"exceptionMessage\": \"Failed to send message after 3 retries\",\n  \"failedAt\": 1704067200000\n}\n</code></pre>"},{"location":"CONFIGURATION/#retry-configuration","title":"Retry Configuration","text":"<p>Automatic retry configuration in case of transmission failure.</p>"},{"location":"CONFIGURATION/#basic-configuration_1","title":"Basic Configuration","text":"<pre><code>curve:\n  retry:\n    enabled: true  # Enable retry\n    max-attempts: 3  # Maximum 3 attempts\n    initial-interval: 1000  # Initial 1 second wait\n    multiplier: 2.0  # Increase by 2x (1s -&gt; 2s -&gt; 4s)\n    max-interval: 10000  # Maximum 10 seconds\n</code></pre>"},{"location":"CONFIGURATION/#exponential-backoff-example","title":"Exponential Backoff Example","text":"Attempt Wait Time 1st 0ms (immediate) 2nd 1,000ms (1 second) 3rd 2,000ms (2 seconds) 4th 4,000ms (4 seconds)"},{"location":"CONFIGURATION/#disable-retry","title":"Disable Retry","text":"<pre><code>curve:\n  retry:\n    enabled: false\n</code></pre>"},{"location":"CONFIGURATION/#aop-configuration","title":"AOP Configuration","text":"<p>AOP configuration based on <code>@PublishEvent</code> annotation.</p>"},{"location":"CONFIGURATION/#enable-aop-default","title":"Enable AOP (Default)","text":"<pre><code>curve:\n  aop:\n    enabled: true\n</code></pre>"},{"location":"CONFIGURATION/#disable-aop","title":"Disable AOP","text":"<pre><code>curve:\n  aop:\n    enabled: false\n</code></pre>"},{"location":"CONFIGURATION/#pii-protection-configuration","title":"PII Protection Configuration","text":"<p>Through PII (Personally Identifiable Information) protection features, sensitive data can be automatically masked, encrypted, or hashed.</p>"},{"location":"CONFIGURATION/#basic-configuration_2","title":"Basic Configuration","text":"<pre><code>curve:\n  pii:\n    enabled: true  # Enable PII protection (default: true)\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Encryption key (environment variable required)\n      salt: ${PII_HASH_SALT}              # Hashing salt (environment variable recommended)\n</code></pre>"},{"location":"CONFIGURATION/#encryption-key-configuration-required","title":"Encryption Key Configuration (Required)","text":"<p>When using <code>@PiiField(strategy = PiiStrategy.ENCRYPT)</code>, an encryption key is mandatory.</p> <p>1. Generate Key <pre><code># Generate 32-byte AES-256 key\nopenssl rand -base64 32\n# Output example: K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\n</code></pre></p> <p>2. Set Environment Variable (Recommended) <pre><code># Linux/macOS\nexport PII_ENCRYPTION_KEY=K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\nexport PII_HASH_SALT=your-random-salt-value\n\n# Windows PowerShell\n$env:PII_ENCRYPTION_KEY=\"K7gNU3sdo+OL0wNhqoVWhr3g6s1xYv72ol/pe/Unols=\"\n$env:PII_HASH_SALT=\"your-random-salt-value\"\n</code></pre></p> <p>3. application.yml Configuration <pre><code>curve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n      salt: ${PII_HASH_SALT}\n</code></pre></p> <p>\u26a0\ufe0f Caution: - Do not hardcode the encryption key directly in application.yml - For production environments, use environment variables or external secret management systems (Vault, AWS Secrets Manager) - If the key is not configured, an exception will occur when using the ENCRYPT strategy</p>"},{"location":"CONFIGURATION/#pii-strategies","title":"PII Strategies","text":"Strategy Description Reversible Example <code>MASK</code> Pattern-based masking Not possible <code>John Doe</code> \u2192 <code>John **</code> <code>ENCRYPT</code> AES-256-GCM encryption Possible (key required) Encrypted Base64 string <code>HASH</code> SHA-256 hashing Not possible Hashed Base64 string"},{"location":"CONFIGURATION/#masking-patterns-by-pii-type","title":"Masking Patterns by PII Type","text":"Type Masking Pattern Example <code>NAME</code> Keep first character, mask rest <code>John Doe</code> \u2192 <code>J*** ***</code> <code>EMAIL</code> Keep local part, mask domain <code>user@example.com</code> \u2192 <code>user@***.com</code> <code>PHONE</code> Keep first 3 and last 4 digits only <code>010-1234-5678</code> \u2192 <code>010****5678</code> <code>DEFAULT</code> Keep first 30%, mask rest <code>Seoul Gangnam</code> \u2192 <code>Seou***</code>"},{"location":"CONFIGURATION/#usage-example","title":"Usage Example","text":"<pre><code>public class CustomerInfo {\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.MASK)\n    private String name;\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(strategy = PiiStrategy.HASH)\n    private String ssn;  // Social Security Number\n}\n</code></pre>"},{"location":"CONFIGURATION/#kubernetes-environment-configuration","title":"Kubernetes Environment Configuration","text":"<pre><code># deployment.yaml\nenv:\n  - name: PII_ENCRYPTION_KEY\n    valueFrom:\n      secretKeyRef:\n        name: curve-secrets\n        key: pii-encryption-key\n  - name: PII_HASH_SALT\n    valueFrom:\n      secretKeyRef:\n        name: curve-secrets\n        key: pii-hash-salt\n</code></pre> <pre><code># Create Secret\nkubectl create secret generic curve-secrets \\\n  --from-literal=pii-encryption-key=$(openssl rand -base64 32) \\\n  --from-literal=pii-hash-salt=$(openssl rand -base64 16)\n</code></pre>"},{"location":"CONFIGURATION/#outbox-configuration","title":"Outbox Configuration","text":"<p>Use the Transactional Outbox Pattern to ensure atomicity between DB transactions and event publishing.</p>"},{"location":"CONFIGURATION/#basic-configuration_3","title":"Basic Configuration","text":"<pre><code>curve:\n  outbox:\n    enabled: true  # Enable Outbox\n    poll-interval-ms: 1000  # Polling interval (1 second)\n    batch-size: 100  # Batch size\n    max-retries: 3  # Maximum retry count\n    send-timeout-seconds: 10  # Send timeout\n    cleanup-enabled: true  # Enable old event cleanup\n    retention-days: 7  # Retention period (7 days)\n    cleanup-cron: \"0 0 2 * * *\"  # Cleanup job execution time (2 AM daily)\n    initialize-schema: embedded  # Schema initialization mode (embedded, always, never)\n</code></pre>"},{"location":"CONFIGURATION/#schema-initialization-modes","title":"Schema Initialization Modes","text":"<ul> <li><code>embedded</code>: Automatically create tables only for embedded DBs like H2, HSQLDB (default)</li> <li><code>always</code>: Always attempt to create tables (if they don't exist)</li> <li><code>never</code>: No automatic creation (recommended when using Flyway/Liquibase)</li> </ul>"},{"location":"CONFIGURATION/#serialization-configuration","title":"Serialization Configuration","text":"<p>Configure the event payload serialization method.</p> <pre><code>curve:\n  serde:\n    type: JSON  # JSON (default), AVRO, PROTOBUF\n</code></pre>"},{"location":"CONFIGURATION/#avro-serialization-configuration","title":"Avro Serialization Configuration","text":"<p>Additional configuration is required to serialize events using Avro.</p>"},{"location":"CONFIGURATION/#1-curve-configuration","title":"1. Curve Configuration","text":"<pre><code>curve:\n  serde:\n    type: AVRO\n    schema-registry-url: http://localhost:8081  # Schema Registry address\n</code></pre>"},{"location":"CONFIGURATION/#2-spring-kafka-configuration-required","title":"2. Spring Kafka Configuration (Required)","text":"<p>You must explicitly specify the <code>value-serializer</code> in Spring Kafka's Producer configuration.</p> <pre><code>spring:\n  kafka:\n    producer:\n      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer\n    properties:\n      schema.registry.url: http://localhost:8081\n</code></pre> <p>\u26a0\ufe0f Caution: - When <code>curve.serde.type=AVRO</code> is configured, Curve internally creates a <code>GenericRecord</code> object and passes it to KafkaTemplate. - Therefore, you must use <code>KafkaAvroSerializer</code> so that KafkaTemplate can serialize <code>GenericRecord</code>. - <code>schema.registry.url</code> may need to be configured in both <code>curve.serde</code> and <code>spring.kafka.properties</code> (for Curve internal logic and Kafka Serializer).</p>"},{"location":"CONFIGURATION/#avro-schema-structure","title":"Avro Schema Structure","text":"<p>Curve internally uses the following fixed Avro schema. Some fields in <code>payload</code> and <code>metadata</code> are stored as JSON strings for flexibility.</p> <pre><code>{\n  \"type\": \"record\",\n  \"name\": \"EventEnvelope\",\n  \"namespace\": \"com.project.curve.core.envelope\",\n  \"fields\": [\n    {\"name\": \"eventId\", \"type\": \"string\"},\n    {\"name\": \"eventType\", \"type\": \"string\"},\n    {\"name\": \"severity\", \"type\": \"string\"},\n    {\"name\": \"metadata\", \"type\": { ... }},\n    {\"name\": \"payload\", \"type\": \"string\"}, // JSON String\n    {\"name\": \"occurredAt\", \"type\": \"long\", \"logicalType\": \"timestamp-millis\"},\n    {\"name\": \"publishedAt\", \"type\": \"long\", \"logicalType\": \"timestamp-millis\"}\n  ]\n}\n</code></pre>"},{"location":"CONFIGURATION/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"CONFIGURATION/#production-environment-stability-focused","title":"Production Environment (Stability-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${INSTANCE_ID}  # Injected from environment variable\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # Synchronous transmission\n    retries: 5\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n  retry:\n    enabled: true\n    max-attempts: 5\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  aop:\n    enabled: true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Environment variable required\n      salt: ${PII_HASH_SALT}\n\n  outbox:\n    enabled: true\n    initialize-schema: never  # Use Flyway\n    cleanup-enabled: true\n    retention-days: 14\n</code></pre>"},{"location":"CONFIGURATION/#developmenttest-environment-performance-focused","title":"Development/Test Environment (Performance-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.dev.v1\n    dlq-topic: event.audit.dlq.dev.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 3000\n    retries: 3\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 500\n    multiplier: 1.5\n\n  aop:\n    enabled: true\n\n  outbox:\n    enabled: true\n    initialize-schema: always\n</code></pre>"},{"location":"CONFIGURATION/#high-performance-environment","title":"High-Performance Environment","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${WORKER_ID}\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000\n    retries: 1  # Minimum retry\n\n  retry:\n    enabled: false  # Disable retry (performance priority)\n\n  aop:\n    enabled: true\n</code></pre>"},{"location":"CONFIGURATION/#environment-specific-configuration-recommendations","title":"Environment-specific Configuration Recommendations","text":""},{"location":"CONFIGURATION/#local-development","title":"Local Development","text":"<ul> <li>Worker ID: 1 (fixed)</li> <li>Transmission Mode: Synchronous (debugging convenience)</li> <li>DLQ: Enabled</li> <li>Retry: Minimum (fast failure)</li> <li>Outbox: Enabled (auto schema generation)</li> </ul>"},{"location":"CONFIGURATION/#staging","title":"Staging","text":"<ul> <li>Worker ID: Environment variable</li> <li>Transmission Mode: Asynchronous</li> <li>DLQ: Enabled</li> <li>Retry: Medium level</li> <li>Outbox: Enabled</li> </ul>"},{"location":"CONFIGURATION/#production","title":"Production","text":"<ul> <li>Worker ID: Centrally managed (Consul/etcd)</li> <li>Transmission Mode: Based on business requirements</li> <li>DLQ: Mandatory enabled</li> <li>Retry: High level</li> <li>Outbox: Mandatory enabled (data consistency)</li> </ul>"},{"location":"CONFIGURATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"CONFIGURATION/#worker-id-conflict","title":"Worker ID Conflict","text":"<p>Symptom: Identical IDs are being generated</p> <p>Solution: <pre><code>curve:\n  id-generator:\n    worker-id: ${UNIQUE_INSTANCE_ID}\n</code></pre></p>"},{"location":"CONFIGURATION/#transmission-timeout","title":"Transmission Timeout","text":"<p>Symptom: <code>TimeoutException</code> occurs</p> <p>Solution: <pre><code>curve:\n  kafka:\n    request-timeout-ms: 60000  # Increase timeout\n</code></pre></p>"},{"location":"CONFIGURATION/#high-latency","title":"High Latency","text":"<p>Symptom: Event publishing is slow</p> <p>Solution: <pre><code>curve:\n  kafka:\n    async-mode: true  # Switch to asynchronous mode\n</code></pre></p>"},{"location":"CONFIGURATION/#pii-encryption-key-not-configured","title":"PII Encryption Key Not Configured","text":"<p>Symptom: <pre><code>ERROR: PII encryption key is not configured!\nERROR: An exception will occur when using @PiiField(strategy = PiiStrategy.ENCRYPT).\n</code></pre></p> <p>Solution: <pre><code># 1. Generate key\nopenssl rand -base64 32\n\n# 2. Set environment variable\nexport PII_ENCRYPTION_KEY=generated_key_value\n\n# 3. Configure application.yml\ncurve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n</code></pre></p>"},{"location":"CONFIGURATION/#configuration-validation-failure","title":"Configuration Validation Failure","text":"<p>Symptom: <pre><code>APPLICATION FAILED TO START\nReason: workerId must be 1023 or less\n</code></pre></p> <p>Solution: - Check if configuration values meet validation rules - Refer to validation rules in the Configuration Validation section</p>"},{"location":"CONFIGURATION/#logging-configuration","title":"Logging Configuration","text":"<p>By default, Curve outputs minimal logs. To see detailed configuration information or internal operations, enable the DEBUG level.</p>"},{"location":"CONFIGURATION/#basic-logging-info","title":"Basic Logging (INFO)","text":"<p>In the default configuration, only the following log is output:</p> <pre><code>INFO  c.p.c.a.CurveAutoConfiguration : Curve auto-configuration enabled (disable with curve.enabled=false)\n</code></pre>"},{"location":"CONFIGURATION/#enable-debug-logging","title":"Enable DEBUG Logging","text":"<pre><code>logging:\n  level:\n    com.project.curve: DEBUG\n</code></pre>"},{"location":"CONFIGURATION/#information-available-at-debug-level","title":"Information Available at DEBUG Level","text":"Item Description Kafka Producer Configuration Detailed configuration such as retries, timeout, async-mode RetryTemplate Configuration max-attempts, detailed backoff policy SnowflakeIdGenerator Worker ID and initialization information DLQ ExecutorService Thread pool size, shutdown timeout PII Module Encryption/salt configuration status, module registration Event Transmission Transmission details per event (eventId, topic, partition, offset) Outbox Publisher Polling, publishing, cleanup job logs"},{"location":"CONFIGURATION/#enable-debug-for-specific-modules-only","title":"Enable DEBUG for Specific Modules Only","text":"<pre><code>logging:\n  level:\n    # DEBUG for Kafka transmission only\n    com.project.curve.kafka: DEBUG\n\n    # DEBUG for Auto-Configuration only\n    com.project.curve.autoconfigure: DEBUG\n\n    # DEBUG for PII processing only\n    com.project.curve.spring.pii: DEBUG\n\n    # DEBUG for Outbox only\n    com.project.curve.spring.outbox: DEBUG\n</code></pre>"},{"location":"CONFIGURATION/#additional-information","title":"Additional Information","text":"<ul> <li>Snowflake ID Algorithm</li> <li>Kafka Producer Configuration</li> <li>Spring Retry</li> <li>Transactional Outbox Pattern</li> </ul>"},{"location":"MIGRATION/","title":"Migration Guide","text":"<p>This guide helps you upgrade between Curve versions safely.</p>"},{"location":"MIGRATION/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Versioning Strategy</li> <li>Version Compatibility Matrix</li> <li>Upgrade Checklist</li> <li>Migration: 0.0.x to 0.1.x</li> <li>Configuration Changes</li> <li>Breaking Changes Log</li> <li>Rollback Procedures</li> </ul>"},{"location":"MIGRATION/#versioning-strategy","title":"Versioning Strategy","text":"<p>Curve follows Semantic Versioning 2.0.0:</p> <pre><code>MAJOR.MINOR.PATCH\n\nExample: 1.2.3\n         \u2502 \u2502 \u2514\u2500\u2500 Patch: Bug fixes, no API changes\n         \u2502 \u2514\u2500\u2500\u2500\u2500 Minor: New features, backward compatible\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500 Major: Breaking changes\n</code></pre>"},{"location":"MIGRATION/#version-guidelines","title":"Version Guidelines","text":"Version Type Changes Action Required Patch (x.x.1) Bug fixes only Safe to upgrade immediately Minor (x.1.x) New features, deprecations Review changelog, test in staging Major (1.x.x) Breaking changes Follow migration guide carefully"},{"location":"MIGRATION/#pre-release-versions","title":"Pre-release Versions","text":"<ul> <li><code>0.x.x</code>: Initial development, API may change</li> <li><code>x.x.x-alpha</code>: Early testing, unstable</li> <li><code>x.x.x-beta</code>: Feature complete, testing phase</li> <li><code>x.x.x-rc.1</code>: Release candidate</li> </ul>"},{"location":"MIGRATION/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"Curve Version Spring Boot Java Kafka Client 0.0.1 3.2.x - 3.5.x 17, 21 3.0+ 0.1.x (planned) 3.2.x - 3.6.x 17, 21 3.0+"},{"location":"MIGRATION/#dependency-compatibility","title":"Dependency Compatibility","text":"<pre><code>// build.gradle\ndependencies {\n    // Curve 0.0.1 compatible versions\n    implementation 'org.springframework.boot:spring-boot-starter:3.5.9'\n    implementation 'org.springframework.kafka:spring-kafka:3.3.0'\n}\n</code></pre>"},{"location":"MIGRATION/#upgrade-checklist","title":"Upgrade Checklist","text":"<p>Before upgrading to a new version:</p>"},{"location":"MIGRATION/#pre-upgrade","title":"Pre-Upgrade","text":"<ul> <li>[ ] Read the CHANGELOG for the target version</li> <li>[ ] Check for breaking changes</li> <li>[ ] Review deprecated features you're using</li> <li>[ ] Backup database (especially outbox table)</li> <li>[ ] Test upgrade in staging environment</li> </ul>"},{"location":"MIGRATION/#during-upgrade","title":"During Upgrade","text":"<ul> <li>[ ] Update dependency version</li> <li>[ ] Update configuration if required</li> <li>[ ] Update code for any API changes</li> <li>[ ] Run tests</li> </ul>"},{"location":"MIGRATION/#post-upgrade","title":"Post-Upgrade","text":"<ul> <li>[ ] Verify application starts successfully</li> <li>[ ] Check <code>/actuator/health/curve</code> endpoint</li> <li>[ ] Monitor metrics for anomalies</li> <li>[ ] Verify events are being published</li> <li>[ ] Check outbox table processing (if enabled)</li> </ul>"},{"location":"MIGRATION/#migration-00x-to-01x","title":"Migration: 0.0.x to 0.1.x","text":"<p>Note: Version 0.1.x is not yet released. This section will be updated with specific migration steps when available.</p>"},{"location":"MIGRATION/#expected-changes-tentative","title":"Expected Changes (Tentative)","text":"<ol> <li>Configuration Namespace</li> <li> <p>No changes expected</p> </li> <li> <p>API Changes</p> </li> <li><code>EventEnvelope</code> may have additional fields</li> <li> <p>New methods in <code>EventProducer</code> interface</p> </li> <li> <p>Database Schema</p> </li> <li>Outbox table may require new columns</li> <li>Migration script will be provided</li> </ol>"},{"location":"MIGRATION/#preparation-steps","title":"Preparation Steps","text":"<pre><code># Ensure you're on latest 0.0.x before upgrading\ncurve:\n  version: 0.0.x  # Update to latest patch first\n</code></pre>"},{"location":"MIGRATION/#configuration-changes","title":"Configuration Changes","text":""},{"location":"MIGRATION/#configuration-changelog","title":"Configuration Changelog","text":""},{"location":"MIGRATION/#version-001-initial","title":"Version 0.0.1 (Initial)","text":"<p>All configurations introduced. See CONFIGURATION.md.</p>"},{"location":"MIGRATION/#version-01x-planned","title":"Version 0.1.x (Planned)","text":"Old Property New Property Notes TBD TBD Will be documented"},{"location":"MIGRATION/#deprecated-properties","title":"Deprecated Properties","text":"<p>Currently, no properties are deprecated.</p> <p>When properties are deprecated: <pre><code># Deprecated in 0.2.0, removed in 1.0.0\ncurve:\n  kafka:\n    old-property: value  # DEPRECATED: Use 'new-property' instead\n    new-property: value\n</code></pre></p>"},{"location":"MIGRATION/#breaking-changes-log","title":"Breaking Changes Log","text":""},{"location":"MIGRATION/#version-001","title":"Version 0.0.1","text":"<p>Initial release - no breaking changes (baseline).</p>"},{"location":"MIGRATION/#future-versions","title":"Future Versions","text":"<p>Breaking changes will be documented here with: - What changed - Why it changed - How to migrate</p>"},{"location":"MIGRATION/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"MIGRATION/#quick-rollback","title":"Quick Rollback","text":"<ol> <li> <p>Revert dependency version <pre><code>// build.gradle\nimplementation 'com.project:curve-spring-boot-autoconfigure:0.0.1'  // Previous version\n</code></pre></p> </li> <li> <p>Revert configuration changes (if any)</p> </li> <li> <p>Redeploy application</p> </li> </ol>"},{"location":"MIGRATION/#database-rollback-outbox","title":"Database Rollback (Outbox)","text":"<p>If schema changed, you may need to rollback database:</p> <pre><code>-- Example rollback script (adjust based on actual changes)\n-- WARNING: This may cause data loss\n\n-- Backup first\nCREATE TABLE curve_outbox_events_backup AS\nSELECT * FROM curve_outbox_events;\n\n-- Rollback schema (example)\nALTER TABLE curve_outbox_events DROP COLUMN IF EXISTS new_column;\n</code></pre>"},{"location":"MIGRATION/#rollback-checklist","title":"Rollback Checklist","text":"<ul> <li>[ ] Revert application version</li> <li>[ ] Revert configuration</li> <li>[ ] Revert database schema (if changed)</li> <li>[ ] Clear any cached data</li> <li>[ ] Restart all instances</li> <li>[ ] Verify health checks</li> <li>[ ] Monitor for issues</li> </ul>"},{"location":"MIGRATION/#upgrading-dependencies","title":"Upgrading Dependencies","text":""},{"location":"MIGRATION/#spring-boot-upgrade","title":"Spring Boot Upgrade","text":"<p>When upgrading Spring Boot:</p> <ol> <li>Check Curve compatibility in the matrix above</li> <li>Upgrade Spring Boot first</li> <li>Test thoroughly</li> <li>Then upgrade Curve if needed</li> </ol> <pre><code>// Upgrade order\nplugins {\n    id 'org.springframework.boot' version '3.5.9'  // Step 1\n}\n\ndependencies {\n    implementation 'com.project:curve-spring-boot-autoconfigure:0.0.1'  // Step 2\n}\n</code></pre>"},{"location":"MIGRATION/#kafka-client-upgrade","title":"Kafka Client Upgrade","text":"<p>Curve is compatible with Kafka Client 3.0+. When upgrading:</p> <ol> <li>Check Spring Kafka compatibility</li> <li>Test producer functionality</li> <li>Verify serialization works correctly</li> </ol>"},{"location":"MIGRATION/#getting-help","title":"Getting Help","text":"<p>If you encounter issues during migration:</p> <ol> <li>Check TROUBLESHOOTING.md</li> <li>Search existing issues</li> <li>Open a new issue with:</li> <li>Source version</li> <li>Target version</li> <li>Error messages</li> <li>Configuration (sanitized)</li> </ol>"},{"location":"MIGRATION/#version-history","title":"Version History","text":"<p>See CHANGELOG.md for complete version history.</p>"},{"location":"MONITORING/","title":"Monitoring &amp; Dashboard Guide","text":"<p>This guide explains how to monitor Curve event publishing and set up dashboards for failed event tracking.</p>"},{"location":"MONITORING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Available Metrics</li> <li>Health Indicators</li> <li>Prometheus Integration</li> <li>Grafana Dashboards</li> <li>Alerting Rules</li> <li>Log Monitoring</li> </ul>"},{"location":"MONITORING/#available-metrics","title":"Available Metrics","text":""},{"location":"MONITORING/#curve-custom-endpoint","title":"Curve Custom Endpoint","text":"<p>Access Curve-specific metrics: <pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre></p> <p>Response: <pre><code>{\n  \"eventsPublished\": 1523,\n  \"eventsFailed\": 12,\n  \"dlqEvents\": 8,\n  \"outboxPending\": 3,\n  \"lastPublishTime\": \"2024-01-15T10:30:45Z\"\n}\n</code></pre></p>"},{"location":"MONITORING/#micrometer-metrics","title":"Micrometer Metrics","text":"<p>Curve exposes the following metrics via Micrometer:</p> Metric Name Type Description <code>curve.events.published</code> Counter Total successfully published events <code>curve.events.failed</code> Counter Total failed event publications <code>curve.events.dlq</code> Counter Events sent to DLQ <code>curve.events.publish.duration</code> Timer Event publishing duration <code>curve.outbox.pending</code> Gauge Current pending outbox events <code>curve.outbox.processed</code> Counter Processed outbox events <code>curve.circuit.state</code> Gauge Circuit breaker state (0=closed, 1=open, 2=half-open)"},{"location":"MONITORING/#enabling-metrics","title":"Enabling Metrics","text":"<pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,prometheus,curve-metrics\n  metrics:\n    tags:\n      application: ${spring.application.name}\n</code></pre>"},{"location":"MONITORING/#health-indicators","title":"Health Indicators","text":""},{"location":"MONITORING/#curve-health-check","title":"Curve Health Check","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <p>Healthy Response: <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafka\": \"connected\",\n    \"outboxPublisher\": \"running\",\n    \"circuitBreaker\": \"CLOSED\",\n    \"pendingEvents\": 0,\n    \"failedEventsLast5Min\": 0\n  }\n}\n</code></pre></p> <p>Unhealthy Response: <pre><code>{\n  \"status\": \"DOWN\",\n  \"details\": {\n    \"kafka\": \"disconnected\",\n    \"error\": \"Connection refused\",\n    \"circuitBreaker\": \"OPEN\",\n    \"pendingEvents\": 1523,\n    \"failedEventsLast5Min\": 47\n  }\n}\n</code></pre></p>"},{"location":"MONITORING/#health-configuration","title":"Health Configuration","text":"<pre><code>management:\n  health:\n    curve:\n      enabled: true\n  endpoint:\n    health:\n      show-details: always\n</code></pre>"},{"location":"MONITORING/#prometheus-integration","title":"Prometheus Integration","text":""},{"location":"MONITORING/#configuration","title":"Configuration","text":"<p>Add to your <code>application.yml</code>: <pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: prometheus\n  prometheus:\n    metrics:\n      export:\n        enabled: true\n</code></pre></p>"},{"location":"MONITORING/#scrape-configuration","title":"Scrape Configuration","text":"<p>Add to <code>prometheus.yml</code>: <pre><code>scrape_configs:\n  - job_name: 'curve-app'\n    metrics_path: '/actuator/prometheus'\n    static_configs:\n      - targets: ['app-host:8080']\n    scrape_interval: 15s\n</code></pre></p>"},{"location":"MONITORING/#key-prometheus-queries","title":"Key Prometheus Queries","text":"<p>Event Publishing Rate: <pre><code>rate(curve_events_published_total[5m])\n</code></pre></p> <p>Error Rate: <pre><code>rate(curve_events_failed_total[5m]) / rate(curve_events_published_total[5m]) * 100\n</code></pre></p> <p>Publishing Latency (p99): <pre><code>histogram_quantile(0.99, rate(curve_events_publish_duration_seconds_bucket[5m]))\n</code></pre></p> <p>Outbox Queue Depth: <pre><code>curve_outbox_pending\n</code></pre></p> <p>Circuit Breaker State: <pre><code>curve_circuit_state\n</code></pre></p>"},{"location":"MONITORING/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"MONITORING/#dashboard-json","title":"Dashboard JSON","text":"<p>Import this dashboard into Grafana:</p> <pre><code>{\n  \"title\": \"Curve Event Publishing\",\n  \"panels\": [\n    {\n      \"title\": \"Events Published per Second\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(curve_events_published_total[1m])\",\n          \"legendFormat\": \"{{instance}}\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Failed Events\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(curve_events_failed_total[1h])\"\n        }\n      ],\n      \"thresholds\": {\n        \"steps\": [\n          {\"color\": \"green\", \"value\": 0},\n          {\"color\": \"yellow\", \"value\": 10},\n          {\"color\": \"red\", \"value\": 50}\n        ]\n      }\n    },\n    {\n      \"title\": \"Publishing Latency\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.50, rate(curve_events_publish_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p50\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.95, rate(curve_events_publish_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p95\"\n        },\n        {\n          \"expr\": \"histogram_quantile(0.99, rate(curve_events_publish_duration_seconds_bucket[5m]))\",\n          \"legendFormat\": \"p99\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Outbox Queue Depth\",\n      \"type\": \"graph\",\n      \"targets\": [\n        {\n          \"expr\": \"curve_outbox_pending\",\n          \"legendFormat\": \"{{instance}}\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Circuit Breaker State\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"curve_circuit_state\"\n        }\n      ],\n      \"mappings\": [\n        {\"value\": 0, \"text\": \"CLOSED\"},\n        {\"value\": 1, \"text\": \"OPEN\"},\n        {\"value\": 2, \"text\": \"HALF-OPEN\"}\n      ]\n    },\n    {\n      \"title\": \"DLQ Events (Last 24h)\",\n      \"type\": \"stat\",\n      \"targets\": [\n        {\n          \"expr\": \"increase(curve_events_dlq_total[24h])\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"MONITORING/#dashboard-panels-explained","title":"Dashboard Panels Explained","text":"Panel Purpose Action When High Events/sec Publishing throughput Normal operation Failed Events Publication failures Check Kafka connectivity Latency Publishing performance Enable async mode Queue Depth Outbox backlog Scale up or fix Kafka Circuit State Failure protection Check underlying issue DLQ Events Unrecoverable failures Manual review required"},{"location":"MONITORING/#alerting-rules","title":"Alerting Rules","text":""},{"location":"MONITORING/#prometheus-alerting-rules","title":"Prometheus Alerting Rules","text":"<p>Create <code>curve-alerts.yml</code>:</p> <pre><code>groups:\n  - name: curve\n    rules:\n      # High error rate\n      - alert: CurveHighErrorRate\n        expr: |\n          rate(curve_events_failed_total[5m]) /\n          rate(curve_events_published_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event publishing error rate\"\n          description: \"Error rate is {{ $value | humanizePercentage }} over last 5 minutes\"\n\n      # Circuit breaker open\n      - alert: CurveCircuitBreakerOpen\n        expr: curve_circuit_state == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Curve circuit breaker is OPEN\"\n          description: \"Event publishing circuit breaker has opened due to failures\"\n\n      # Outbox queue growing\n      - alert: CurveOutboxQueueGrowing\n        expr: curve_outbox_pending &gt; 1000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Outbox queue is growing\"\n          description: \"{{ $value }} events pending in outbox\"\n\n      # High latency\n      - alert: CurveHighLatency\n        expr: |\n          histogram_quantile(0.99, rate(curve_events_publish_duration_seconds_bucket[5m])) &gt; 1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event publishing latency\"\n          description: \"p99 latency is {{ $value }}s\"\n\n      # No events published\n      - alert: CurveNoEventsPublished\n        expr: |\n          increase(curve_events_published_total[15m]) == 0\n          and increase(curve_events_failed_total[15m]) == 0\n        for: 15m\n        labels:\n          severity: info\n        annotations:\n          summary: \"No events published\"\n          description: \"No events have been published in the last 15 minutes\"\n\n      # DLQ spike\n      - alert: CurveDLQSpike\n        expr: increase(curve_events_dlq_total[1h]) &gt; 100\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High number of DLQ events\"\n          description: \"{{ $value }} events sent to DLQ in the last hour\"\n</code></pre>"},{"location":"MONITORING/#slack-alert-example","title":"Slack Alert Example","text":"<p>Configure Alertmanager for Slack: <pre><code>receivers:\n  - name: 'curve-alerts'\n    slack_configs:\n      - channel: '#alerts'\n        send_resolved: true\n        title: '{{ .Status | toUpper }}: {{ .CommonAnnotations.summary }}'\n        text: '{{ .CommonAnnotations.description }}'\n</code></pre></p>"},{"location":"MONITORING/#log-monitoring","title":"Log Monitoring","text":""},{"location":"MONITORING/#important-log-patterns","title":"Important Log Patterns","text":"<p>Event Published Successfully: <pre><code>INFO  c.p.c.k.producer.KafkaEventProducer - Event published: id=1234567890, topic=event.audit.v1\n</code></pre></p> <p>Event Failed: <pre><code>ERROR c.p.c.k.producer.KafkaEventProducer - Failed to publish event: id=1234567890, error=Connection refused\n</code></pre></p> <p>DLQ Event: <pre><code>WARN  c.p.c.k.producer.KafkaEventProducer - Event sent to DLQ: id=1234567890, originalError=Timeout\n</code></pre></p> <p>Circuit Breaker State Change: <pre><code>WARN  c.p.c.s.outbox.publisher.OutboxEventPublisher - Circuit breaker state changed: CLOSED -&gt; OPEN\n</code></pre></p>"},{"location":"MONITORING/#elk-stack-integration","title":"ELK Stack Integration","text":"<p>Logstash Filter: <pre><code>filter {\n  if [logger_name] =~ /curve/ {\n    grok {\n      match =&gt; {\n        \"message\" =&gt; \"Event %{WORD:event_action}: id=%{NUMBER:event_id}\"\n      }\n    }\n    if [event_action] == \"published\" {\n      mutate { add_tag =&gt; [\"curve_success\"] }\n    } else if [event_action] == \"failed\" {\n      mutate { add_tag =&gt; [\"curve_failure\"] }\n    }\n  }\n}\n</code></pre></p> <p>Kibana Saved Searches:</p> <ol> <li> <p>Failed Events: <pre><code>logger_name:*curve* AND level:ERROR\n</code></pre></p> </li> <li> <p>DLQ Events: <pre><code>message:\"sent to DLQ\"\n</code></pre></p> </li> <li> <p>Circuit Breaker Events: <pre><code>message:\"Circuit breaker\"\n</code></pre></p> </li> </ol>"},{"location":"MONITORING/#structured-logging","title":"Structured Logging","text":"<p>Enable JSON logging for better parsing:</p> <pre><code>logging:\n  pattern:\n    console: '{\"timestamp\":\"%d\",\"level\":\"%level\",\"logger\":\"%logger\",\"message\":\"%msg\"}%n'\n</code></pre> <p>Or use Logback with JSON encoder: <pre><code>&lt;appender name=\"JSON\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;\n    &lt;encoder class=\"net.logstash.logback.encoder.LogstashEncoder\"/&gt;\n&lt;/appender&gt;\n</code></pre></p>"},{"location":"MONITORING/#quick-reference","title":"Quick Reference","text":""},{"location":"MONITORING/#endpoints","title":"Endpoints","text":"Endpoint Description <code>/actuator/health/curve</code> Curve health status <code>/actuator/curve-metrics</code> Curve-specific metrics <code>/actuator/prometheus</code> Prometheus metrics"},{"location":"MONITORING/#key-metrics-to-watch","title":"Key Metrics to Watch","text":"Metric Normal Warning Critical Error Rate &lt; 1% 1-5% &gt; 5% Latency (p99) &lt; 100ms 100-500ms &gt; 500ms Outbox Queue &lt; 100 100-1000 &gt; 1000 Circuit State CLOSED HALF-OPEN OPEN"},{"location":"MONITORING/#emergency-commands","title":"Emergency Commands","text":"<pre><code># Check Kafka connectivity\nnc -zv kafka-host 9094\n\n# View recent DLQ events\nkafka-console-consumer --bootstrap-server localhost:9094 \\\n  --topic event.audit.dlq.v1 --from-beginning --max-messages 10\n\n# Check outbox table\npsql -c \"SELECT status, COUNT(*) FROM curve_outbox_events GROUP BY status;\"\n\n# Force close circuit breaker (if supported)\ncurl -X POST http://localhost:8080/actuator/curve/circuit-breaker/reset\n</code></pre>"},{"location":"OPERATIONS/","title":"Curve Operations Guide","text":"<p>This document describes operational procedures for monitoring, troubleshooting, and recovery in the Curve event publishing system.</p>"},{"location":"OPERATIONS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>DLQ Monitoring</li> <li>Metrics Interpretation</li> <li>Troubleshooting Matrix</li> <li>Recovery Procedures</li> <li>Alert Configuration</li> <li>Runbook Checklist</li> </ul>"},{"location":"OPERATIONS/#dlq-monitoring","title":"DLQ Monitoring","text":""},{"location":"OPERATIONS/#understanding-the-3-tier-failure-recovery","title":"Understanding the 3-Tier Failure Recovery","text":"<p>Curve implements a 3-tier failure recovery system to prevent event loss:</p> <pre><code>Event Send Attempt\n        \u2502\n        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 1: Main   \u2502\u2500\u2500\u2500\u2500 Success \u2500\u2500\u2500\u25b6 Event Published\n\u2502     Topic       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 Failure\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Tier 2: DLQ    \u2502\u2500\u2500\u2500\u2500 Success \u2500\u2500\u2500\u25b6 Event in DLQ Topic\n\u2502     Topic       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 Failure\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Tier 3: Local   \u2502\u2500\u2500\u2500\u2500 Success \u2500\u2500\u2500\u25b6 JSON File Backup\n\u2502     Backup      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 Failure\n         \u25bc\n    Event Lost + Alert\n</code></pre> Tier Component Trigger Description 1 Main Topic Normal operation Events published to configured Kafka topic 2 DLQ Topic Main topic failure Failed events sent to Dead Letter Queue 3 Local File DLQ failure Events backed up to <code>./dlq-backup/</code> directory"},{"location":"OPERATIONS/#monitoring-dlq-events","title":"Monitoring DLQ Events","text":""},{"location":"OPERATIONS/#via-kafka-ui","title":"Via Kafka UI","text":"<ol> <li>Navigate to Kafka UI (default: http://localhost:8080)</li> <li>Select Topics from the menu</li> <li>Find <code>event.audit.dlq.v1</code> (or your configured DLQ topic)</li> <li>View Messages tab for failed events</li> </ol>"},{"location":"OPERATIONS/#via-actuator-endpoint","title":"Via Actuator Endpoint","text":"<pre><code># Get DLQ metrics\ncurl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n</code></pre> <p>Response: <pre><code>{\n  \"totalEventsPublished\": 1523,\n  \"successfulEvents\": 1520,\n  \"failedEvents\": 3,\n  \"successRate\": \"99.80%\",\n  \"totalDlqEvents\": 3,\n  \"totalKafkaErrors\": 0\n}\n</code></pre></p>"},{"location":"OPERATIONS/#via-kafka-cli","title":"Via Kafka CLI","text":"<pre><code># Count messages in DLQ topic\nkafka-run-class.sh kafka.tools.GetOffsetShell \\\n  --broker-list localhost:9094 \\\n  --topic event.audit.dlq.v1\n\n# Consume DLQ messages\nkafka-console-consumer.sh \\\n  --bootstrap-server localhost:9094 \\\n  --topic event.audit.dlq.v1 \\\n  --from-beginning\n</code></pre>"},{"location":"OPERATIONS/#dlq-message-structure","title":"DLQ Message Structure","text":"<pre><code>{\n  \"eventId\": \"123456789012345678\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"originalPayload\": \"{\\\"eventType\\\":\\\"ORDER_CREATED\\\",...}\",\n  \"exceptionType\": \"org.apache.kafka.common.errors.TimeoutException\",\n  \"exceptionMessage\": \"Failed to send message after 3 retries\",\n  \"failedAt\": 1704067200000\n}\n</code></pre> Field Description <code>eventId</code> Unique event identifier (Snowflake ID) <code>originalTopic</code> Topic where the event was supposed to be sent <code>originalPayload</code> Complete event payload as JSON string <code>exceptionType</code> Java exception class that caused the failure <code>exceptionMessage</code> Human-readable error message <code>failedAt</code> Timestamp (epoch milliseconds) when failure occurred"},{"location":"OPERATIONS/#local-backup-files","title":"Local Backup Files","text":"<p>Location: <code>./dlq-backup/</code> (configurable via <code>curve.kafka.dlq-backup-path</code>)</p> <pre><code># List backup files\nls -la ./dlq-backup/\n\n# Example output:\n# -rw------- 1 user user 2048 Jan 20 10:30 123456789012345678.json\n# -rw------- 1 user user 1856 Jan 20 10:31 123456789012345679.json\n</code></pre> <p>File naming: <code>{eventId}.json</code></p> <p>File permissions: - POSIX systems: <code>600</code> (rw-------) - Windows: ACL restricted to owner only</p>"},{"location":"OPERATIONS/#metrics-interpretation","title":"Metrics Interpretation","text":""},{"location":"OPERATIONS/#accessing-metrics","title":"Accessing Metrics","text":"<pre><code># Full metrics report\ncurl http://localhost:8081/actuator/curve-metrics\n\n# Summary only\ncurl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n\n# Specific metric\ncurl http://localhost:8081/actuator/curve-metrics | jq '.events.published'\n</code></pre>"},{"location":"OPERATIONS/#key-metrics-reference","title":"Key Metrics Reference","text":"Metric Description Warning Threshold Critical Threshold <code>successRate</code> Event publishing success percentage &lt; 99% &lt; 95% <code>totalDlqEvents</code> Events sent to DLQ &gt; 0 &gt; 10 (increasing) <code>totalKafkaErrors</code> Kafka producer errors &gt; 0 &gt; 5 <code>curve.events.retry.count</code> Retry attempts Increasing Rapidly increasing <code>curve.events.publish.duration</code> Publishing latency &gt; 100ms avg &gt; 500ms avg"},{"location":"OPERATIONS/#health-status-interpretation","title":"Health Status Interpretation","text":"Status Indicators Meaning Action Healthy successRate &gt;= 99.5%, totalDlqEvents = 0 Normal operation Monitor Warning successRate 95-99.5%, totalDlqEvents &gt; 0 stable Intermittent issues Investigate Critical successRate &lt; 95%, totalDlqEvents increasing System failure Immediate action"},{"location":"OPERATIONS/#outbox-publisher-metrics","title":"Outbox Publisher Metrics","text":"<p>For Transactional Outbox Pattern users:</p> Metric Description Action if Abnormal <code>circuitBreakerState</code> CLOSED/OPEN/HALF-OPEN OPEN = Kafka connectivity issue <code>consecutiveFailures</code> Consecutive failure count &gt; 3 = circuit breaker may open <code>timeSinceLastSuccessMs</code> Time since last success &gt; 60000 = check Kafka <code>totalPending</code> Pending outbox events Should trend toward 0 <code>totalFailed</code> Permanently failed events Requires manual intervention"},{"location":"OPERATIONS/#circuit-breaker-states","title":"Circuit Breaker States","text":"State Behavior Duration Transition CLOSED Normal operation - Opens after 5 consecutive failures OPEN All requests blocked 60 seconds Transitions to HALF-OPEN HALF-OPEN Allows test requests Until success/failure Success\u2192CLOSED, Failure\u2192OPEN"},{"location":"OPERATIONS/#troubleshooting-matrix","title":"Troubleshooting Matrix","text":""},{"location":"OPERATIONS/#symptoms-and-solutions","title":"Symptoms and Solutions","text":"Symptom Possible Cause Verification Solution Events not published AOP disabled Check <code>curve.aop.enabled</code> in config Set to <code>true</code> Events not published Method not public Review method signature Make method <code>public</code> <code>TimeoutException</code> Kafka unresponsive <code>docker-compose ps kafka</code> Restart Kafka <code>TimeoutException</code> Network latency Ping broker Increase <code>request-timeout-ms</code> High DLQ count Kafka broker down Check broker logs Restore Kafka, recover DLQ Circuit breaker OPEN 5+ consecutive failures Check Kafka health Wait 60s or fix Kafka Local backup files exist Both main and DLQ failed Check all Kafka connectivity Manual recovery required PII encryption error Missing encryption key Check <code>PII_ENCRYPTION_KEY</code> env Set environment variable Worker ID conflict Duplicate worker IDs Check instance configurations Assign unique IDs Outbox events stuck PENDING Kafka unreachable Check circuit breaker state Fix Kafka connectivity Slow event publishing Sync mode under high load Check <code>async-mode</code> Enable async mode <code>ClockMovedBackwardsException</code> System time changed Check NTP sync Restart application"},{"location":"OPERATIONS/#common-error-messages","title":"Common Error Messages","text":"Error Message Cause Solution <code>Kafka topic is required</code> Missing topic configuration Set <code>curve.kafka.topic</code> <code>workerId must be between 0 and 1023</code> Invalid worker ID Use valid range <code>PII encryption key is not configured</code> Missing encryption key Set <code>PII_ENCRYPTION_KEY</code> env var <code>Failed to send message after N retries</code> Kafka connectivity issue Check broker status <code>Circuit breaker is OPEN</code> Too many consecutive failures Wait for half-open or fix Kafka"},{"location":"OPERATIONS/#health-check-responses","title":"Health Check Responses","text":"<pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre> Status kafkaProducerInitialized Meaning Action UP true Healthy None DOWN false KafkaTemplate not initialized Check Kafka configuration DOWN true (with error) Runtime issue Check exception details"},{"location":"OPERATIONS/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"OPERATIONS/#procedure-1-dlq-event-recovery","title":"Procedure 1: DLQ Event Recovery","text":"<p>When to use: Events accumulated in DLQ topic after temporary Kafka issues have been resolved.</p> <p>Prerequisites: - Kafka is now healthy - <code>kafka-console-producer.sh</code> available in PATH - Access to DLQ topic</p> <p>Steps:</p> <ol> <li> <p>Verify Kafka is healthy: <pre><code># Check Kafka container\ndocker-compose ps kafka\n\n# Check Curve health\ncurl http://localhost:8081/actuator/health/curve\n</code></pre></p> </li> <li> <p>List DLQ events to recover: <pre><code>./scripts/dlq-recovery.sh --list\n</code></pre></p> </li> <li> <p>Execute recovery: <pre><code>./scripts/dlq-recovery.sh \\\n  --topic event.audit.v1 \\\n  --broker localhost:9094 \\\n  --dir ./dlq-backup\n</code></pre></p> </li> <li> <p>Recover specific file: <pre><code>./scripts/dlq-recovery.sh \\\n  --file 123456789012345678.json \\\n  --topic event.audit.v1 \\\n  --broker localhost:9094\n</code></pre></p> </li> <li> <p>Verify recovery:</p> </li> <li>Check Kafka UI for recovered events</li> <li>Verify backup files are processed (moved to <code>recovered/</code> subdirectory)</li> </ol>"},{"location":"OPERATIONS/#procedure-2-local-backup-file-recovery","title":"Procedure 2: Local Backup File Recovery","text":"<p>When to use: Both main topic and DLQ failed, events backed up to local files.</p> <p>Steps:</p> <ol> <li> <p>List backup files: <pre><code>ls -la ./dlq-backup/*.json\n</code></pre></p> </li> <li> <p>Validate JSON format: <pre><code># Check all files\nfor f in ./dlq-backup/*.json; do\n  jq empty \"$f\" 2&gt;/dev/null || echo \"Invalid: $f\"\ndone\n</code></pre></p> </li> <li> <p>Use recovery script: <pre><code>./scripts/dlq-recovery.sh \\\n  --dir ./dlq-backup \\\n  --topic event.audit.v1 \\\n  --broker localhost:9094\n</code></pre></p> </li> <li> <p>Manual recovery (if script fails): <pre><code># For each backup file\nEVENT_ID=\"123456789012345678\"\n\ncat ./dlq-backup/${EVENT_ID}.json | \\\n  kafka-console-producer.sh \\\n  --broker-list localhost:9094 \\\n  --topic event.audit.v1\n</code></pre></p> </li> <li> <p>Archive recovered files: <pre><code>mkdir -p ./dlq-backup/recovered\nmv ./dlq-backup/*.json ./dlq-backup/recovered/\n</code></pre></p> </li> </ol>"},{"location":"OPERATIONS/#procedure-3-outbox-event-recovery","title":"Procedure 3: Outbox Event Recovery","text":"<p>When to use: Outbox events stuck in FAILED status after circuit breaker issues.</p> <p>Steps:</p> <ol> <li> <p>Check outbox statistics: <pre><code>curl http://localhost:8081/actuator/curve-metrics | jq '.summary'\n</code></pre></p> </li> <li> <p>Query failed events (requires database access): <pre><code>-- List failed events\nSELECT id, event_id, aggregate_type, aggregate_id, status, retry_count, last_error\nFROM curve_outbox_event\nWHERE status = 'FAILED'\nORDER BY occurred_at DESC\nLIMIT 100;\n\n-- Count by status\nSELECT status, COUNT(*) as count\nFROM curve_outbox_event\nGROUP BY status;\n</code></pre></p> </li> <li> <p>Reset failed events for retry: <pre><code>-- Reset specific event\nUPDATE curve_outbox_event\nSET status = 'PENDING', retry_count = 0, last_error = NULL, next_retry_at = NOW()\nWHERE id = 'specific-event-id';\n\n-- Reset all failed events (use with caution)\nUPDATE curve_outbox_event\nSET status = 'PENDING', retry_count = 0, last_error = NULL, next_retry_at = NOW()\nWHERE status = 'FAILED';\n</code></pre></p> </li> <li> <p>Monitor recovery: <pre><code>watch -n 5 'curl -s http://localhost:8081/actuator/curve-metrics | jq \".summary\"'\n</code></pre></p> </li> </ol>"},{"location":"OPERATIONS/#procedure-4-circuit-breaker-reset","title":"Procedure 4: Circuit Breaker Reset","text":"<p>When to use: Circuit breaker stuck in OPEN state after Kafka recovery.</p> <p>Steps:</p> <ol> <li> <p>Verify Kafka is healthy: <pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre></p> </li> <li> <p>Check circuit breaker state: <pre><code>curl http://localhost:8081/actuator/curve-metrics | jq '.summary.circuitBreakerState'\n</code></pre></p> </li> <li> <p>Wait for automatic half-open (60 seconds)</p> </li> </ol> <p>The circuit breaker will automatically transition to HALF-OPEN state after 60 seconds, allowing test requests.</p> <ol> <li> <p>Alternative: Restart application: <pre><code># Graceful shutdown\nkill -TERM $(pgrep -f 'your-application')\n\n# Or via actuator (if enabled)\ncurl -X POST http://localhost:8081/actuator/shutdown\n</code></pre></p> </li> <li> <p>Monitor state transition: <pre><code>watch -n 10 'curl -s http://localhost:8081/actuator/curve-metrics | jq \".summary.circuitBreakerState\"'\n</code></pre></p> </li> </ol>"},{"location":"OPERATIONS/#alert-configuration","title":"Alert Configuration","text":""},{"location":"OPERATIONS/#prometheus-alert-rules","title":"Prometheus Alert Rules","text":"<pre><code>groups:\n  - name: curve-alerts\n    rules:\n      # DLQ Events Alert\n      - alert: CurveDlqEventsHigh\n        expr: curve_events_dlq_count_total &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High DLQ event count\"\n          description: \"{{ $value }} events accumulated in DLQ\"\n\n      # Success Rate Alert\n      - alert: CurveSuccessRateLow\n        expr: (curve_events_published_success_total / curve_events_published_total) &lt; 0.95\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Low event publishing success rate\"\n          description: \"Success rate is {{ $value | humanizePercentage }}\"\n\n      # Circuit Breaker Alert\n      - alert: CurveCircuitBreakerOpen\n        expr: curve_circuit_breaker_state == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Circuit breaker is OPEN\"\n          description: \"Outbox publisher circuit breaker is open, events are not being published\"\n\n      # Kafka Producer Down\n      - alert: CurveKafkaProducerDown\n        expr: curve_health_status == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Curve Kafka producer is down\"\n          description: \"Kafka producer failed to initialize or is unhealthy\"\n\n      # High Latency Alert\n      - alert: CurvePublishLatencyHigh\n        expr: histogram_quantile(0.95, curve_events_publish_duration_seconds_bucket) &gt; 0.5\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event publishing latency\"\n          description: \"95th percentile latency is {{ $value }}s\"\n\n      # Outbox Backlog Alert\n      - alert: CurveOutboxBacklogHigh\n        expr: curve_outbox_pending_total &gt; 1000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High outbox backlog\"\n          description: \"{{ $value }} events pending in outbox\"\n</code></pre>"},{"location":"OPERATIONS/#grafana-dashboard-panels","title":"Grafana Dashboard Panels","text":"<p>Recommended panels for Curve monitoring dashboard:</p> <ol> <li>Event Publishing Rate - <code>rate(curve_events_published_total[5m])</code></li> <li>Success Rate Gauge - Current success percentage</li> <li>DLQ Event Count - <code>curve_events_dlq_count_total</code> over time</li> <li>Publishing Latency - <code>histogram_quantile(0.95, curve_events_publish_duration_seconds_bucket)</code></li> <li>Circuit Breaker State - Current state indicator (CLOSED/OPEN/HALF-OPEN)</li> <li>Outbox Queue Depth - <code>curve_outbox_pending_total</code> over time</li> <li>Retry Count - <code>rate(curve_events_retry_count_total[5m])</code></li> <li>Kafka Errors - <code>curve_kafka_producer_errors_total</code> over time</li> </ol>"},{"location":"OPERATIONS/#runbook-checklist","title":"Runbook Checklist","text":""},{"location":"OPERATIONS/#daily-operations","title":"Daily Operations","text":"<ul> <li>[ ] Check <code>/actuator/health/curve</code> status</li> <li>[ ] Review <code>/actuator/curve-metrics</code> summary</li> <li>[ ] Verify DLQ topic is empty or stable</li> <li>[ ] Check for local backup files in <code>./dlq-backup/</code></li> <li>[ ] Review application logs for WARN/ERROR entries</li> </ul>"},{"location":"OPERATIONS/#weekly-operations","title":"Weekly Operations","text":"<ul> <li>[ ] Review DLQ event patterns and root causes</li> <li>[ ] Analyze publishing latency trends</li> <li>[ ] Verify outbox cleanup job ran successfully</li> <li>[ ] Archive old backup files (if any)</li> <li>[ ] Review and rotate logs</li> </ul>"},{"location":"OPERATIONS/#incident-response","title":"Incident Response","text":"<ul> <li>[ ] Identify affected time range</li> <li>[ ] Check circuit breaker state history</li> <li>[ ] Count events in DLQ and local backup</li> <li>[ ] Determine root cause (Kafka, network, configuration)</li> <li>[ ] Execute appropriate recovery procedure</li> <li>[ ] Verify event delivery to consumers</li> <li>[ ] Document incident in post-mortem</li> </ul>"},{"location":"OPERATIONS/#monthly-operations","title":"Monthly Operations","text":"<ul> <li>[ ] Review alert thresholds and adjust if needed</li> <li>[ ] Analyze success rate trends</li> <li>[ ] Capacity planning based on event volume</li> <li>[ ] Review and update this runbook if necessary</li> </ul>"},{"location":"OPERATIONS/#additional-resources","title":"Additional Resources","text":"<ul> <li>Configuration Guide - Detailed configuration options</li> <li>DLQ Recovery Script - Automated recovery tool</li> <li>Sample Application - Working examples</li> <li>README - Project overview and quick start</li> </ul>"},{"location":"PUBLISHING/","title":"Publishing Guide","text":"<p>This guide explains how to publish Curve to Maven Central.</p> <p>Note: As of January 2024, Sonatype has migrated from the old JIRA-based system (issues.sonatype.org) to the new Central Publisher Portal.</p> <p>Important: Central Portal uses new API endpoints: - New URL: <code>https://ossrh-staging-api.central.sonatype.com/service/local/</code> - Old URL (deprecated): <code>https://s01.oss.sonatype.org/service/local/</code> - Central Portal tokens do NOT work with this URL</p>"},{"location":"PUBLISHING/#prerequisites","title":"Prerequisites","text":"<p>Before publishing, you need:</p> <ol> <li>Sonatype Central Portal Account</li> <li>Namespace (Group ID) Verification</li> <li>GPG Key for signing artifacts</li> <li>GitHub Secrets configured</li> </ol>"},{"location":"PUBLISHING/#step-1-create-sonatype-central-portal-account","title":"Step 1: Create Sonatype Central Portal Account","text":""},{"location":"PUBLISHING/#11-sign-up","title":"1.1 Sign Up","text":"<ol> <li>Go to https://central.sonatype.com</li> <li>Click \"Sign In\" (top right)</li> <li>Choose sign-up method:</li> <li>GitHub (recommended - easiest for <code>io.github.*</code> namespace)</li> <li>Google</li> <li>Username/Password</li> </ol>"},{"location":"PUBLISHING/#12-verify-email","title":"1.2 Verify Email","text":"<p>Check your email and verify your account.</p>"},{"location":"PUBLISHING/#step-2-register-namespace-group-id","title":"Step 2: Register Namespace (Group ID)","text":""},{"location":"PUBLISHING/#21-go-to-namespace-registration","title":"2.1 Go to Namespace Registration","text":"<ol> <li>Login to https://central.sonatype.com</li> <li>Click on your profile \u2192 \"View Namespaces\"</li> <li>Click \"Add Namespace\"</li> </ol>"},{"location":"PUBLISHING/#22-register-iogithubcloseup1202","title":"2.2 Register <code>io.github.closeup1202</code>","text":"<ol> <li>Enter namespace: <code>io.github.closeup1202</code></li> <li>Select verification method: GitHub</li> <li>Follow the verification steps:</li> <li>Create a temporary public repository with the specified name</li> <li>Sonatype will verify your GitHub account ownership</li> <li>After verification, you can delete the temporary repository</li> </ol>"},{"location":"PUBLISHING/#23-wait-for-verification","title":"2.3 Wait for Verification","text":"<ul> <li>GitHub-based verification is usually automatic (within minutes)</li> <li>You'll see the namespace status change to \"Verified\"</li> </ul>"},{"location":"PUBLISHING/#step-3-generate-user-token","title":"Step 3: Generate User Token","text":""},{"location":"PUBLISHING/#31-create-token-for-publishing","title":"3.1 Create Token for Publishing","text":"<ol> <li>Login to https://central.sonatype.com</li> <li>Click on your profile \u2192 \"View Account\"</li> <li>Click \"Generate User Token\"</li> <li>Save the generated credentials:</li> <li>Username: (token username)</li> <li>Password: (token password)</li> </ol> <p>Important: Save these credentials securely. You won't be able to see the password again.</p>"},{"location":"PUBLISHING/#step-4-generate-gpg-key","title":"Step 4: Generate GPG Key","text":""},{"location":"PUBLISHING/#41-install-gpg","title":"4.1 Install GPG","text":"<pre><code># macOS\nbrew install gnupg\n\n# Ubuntu/Debian\nsudo apt-get install gnupg\n\n# Windows (PowerShell)\nwinget install GnuPG.GnuPG\n# Or download from https://gpg4win.org/\n</code></pre>"},{"location":"PUBLISHING/#42-generate-key-pair","title":"4.2 Generate Key Pair","text":"<pre><code>gpg --full-generate-key\n</code></pre> <p>Select: - Key type: <code>RSA and RSA</code> - Key size: <code>4096</code> - Expiration: <code>0</code> (does not expire) or your preference - Real name: <code>closeup1202</code> - Email: <code>closeup1202@gmail.com</code> - Passphrase: (remember this!)</p>"},{"location":"PUBLISHING/#43-get-key-id","title":"4.3 Get Key ID","text":"<pre><code>gpg --list-secret-keys --keyid-format LONG\n\n# Output example:\n# sec   rsa4096/ABCDEF1234567890 2024-01-01 [SC]\n#       1234567890ABCDEF1234567890ABCDEF12345678\n# uid                 [ultimate] closeup1202 &lt;closeup1202@gmail.com&gt;\n\n# Key ID: ABCDEF1234567890 (16 characters after rsa4096/)\n# Or short form: last 8 characters\n</code></pre>"},{"location":"PUBLISHING/#44-upload-public-key-to-keyserver","title":"4.4 Upload Public Key to Keyserver","text":"<pre><code>gpg --keyserver keyserver.ubuntu.com --send-keys YOUR_KEY_ID\n\n# Also upload to other keyservers for redundancy\ngpg --keyserver keys.openpgp.org --send-keys YOUR_KEY_ID\n</code></pre>"},{"location":"PUBLISHING/#45-export-private-key-for-github-actions","title":"4.5 Export Private Key for GitHub Actions","text":"<pre><code># Export private key\ngpg --armor --export-secret-keys YOUR_KEY_ID &gt; private-key.asc\n\n# View content (copy this for GitHub Secret)\ncat private-key.asc\n</code></pre>"},{"location":"PUBLISHING/#step-5-configure-github-secrets","title":"Step 5: Configure GitHub Secrets","text":"<p>Go to your repository \u2192 Settings \u2192 Secrets and variables \u2192 Actions</p> <p>Add these secrets:</p> Secret Name Value Description <code>OSSRH_USERNAME</code> Token username from Step 3 Central Portal token username <code>OSSRH_PASSWORD</code> Token password from Step 3 Central Portal token password <code>GPG_KEY_ID</code> <code>ABCDEF1234567890</code> Your GPG key ID <code>GPG_PRIVATE_KEY</code> Content of <code>private-key.asc</code> Entire file including headers <code>GPG_PASSPHRASE</code> Your GPG passphrase The password you set for GPG key"},{"location":"PUBLISHING/#step-6-test-locally-optional","title":"Step 6: Test Locally (Optional)","text":""},{"location":"PUBLISHING/#61-configure-local-credentials","title":"6.1 Configure Local Credentials","text":"<p>Create or edit <code>~/.gradle/gradle.properties</code>:</p> <pre><code>ossrhUsername=your-token-username\nossrhPassword=your-token-password\nsigning.keyId=ABCDEF1234567890\nsigning.password=your-gpg-passphrase\nsigning.secretKeyRingFile=C:/Users/YourName/.gnupg/secring.gpg\n</code></pre>"},{"location":"PUBLISHING/#62-publish-snapshot","title":"6.2 Publish SNAPSHOT","text":"<pre><code>./gradlew publish\n</code></pre> <p>Check your artifacts at: https://central.sonatype.com (Deployments tab)</p>"},{"location":"PUBLISHING/#step-7-release","title":"Step 7: Release","text":""},{"location":"PUBLISHING/#71-update-version","title":"7.1 Update Version","text":"<p>Edit <code>gradle.properties</code>: <pre><code># Change from SNAPSHOT to release version\nversion=0.0.1\n</code></pre></p>"},{"location":"PUBLISHING/#72-commit-and-tag","title":"7.2 Commit and Tag","text":"<pre><code>git add .\ngit commit -m \"Release v0.0.1\"\ngit tag v0.0.1\ngit push origin main --tags\n</code></pre>"},{"location":"PUBLISHING/#73-automatic-release","title":"7.3 Automatic Release","text":"<p>The GitHub Actions workflow will automatically: 1. Build and test 2. Sign artifacts with GPG 3. Publish to Central Portal 4. Create GitHub Release</p>"},{"location":"PUBLISHING/#74-manual-release-via-portal-if-needed","title":"7.4 Manual Release via Portal (if needed)","text":"<ol> <li>Go to https://central.sonatype.com</li> <li>Click \"Deployments\" tab</li> <li>Find your deployment</li> <li>Click \"Publish\" to release to Maven Central</li> </ol>"},{"location":"PUBLISHING/#step-8-verify-publication","title":"Step 8: Verify Publication","text":"<p>After release, your artifacts will be available at:</p> <ul> <li>Maven Central Search: https://search.maven.org/search?q=g:io.github.closeup1202</li> <li>Direct URL: https://repo1.maven.org/maven2/io/github/closeup1202/</li> </ul> <p>Note: It may take 10-30 minutes for artifacts to sync to Maven Central after publishing.</p>"},{"location":"PUBLISHING/#usage-after-publication","title":"Usage After Publication","text":"<p>Users can add your library:</p> <p>Gradle (Kotlin DSL): <pre><code>dependencies {\n    implementation(\"io.github.closeup1202:curve:0.0.2\")\n}\n</code></pre></p> <p>Gradle (Groovy): <pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.0.2'\n}\n</code></pre></p> <p>Maven: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p>"},{"location":"PUBLISHING/#troubleshooting","title":"Troubleshooting","text":""},{"location":"PUBLISHING/#gpg-key-not-found-on-keyserver","title":"GPG Key Not Found on Keyserver","text":"<pre><code># Re-upload to multiple keyservers\ngpg --keyserver keyserver.ubuntu.com --send-keys YOUR_KEY_ID\ngpg --keyserver keys.openpgp.org --send-keys YOUR_KEY_ID\ngpg --keyserver pgp.mit.edu --send-keys YOUR_KEY_ID\n</code></pre>"},{"location":"PUBLISHING/#namespace-verification-failed","title":"Namespace Verification Failed","text":"<ul> <li>Ensure the temporary repository is public</li> <li>Repository name must match exactly what Sonatype specifies</li> <li>Try verification again after a few minutes</li> </ul>"},{"location":"PUBLISHING/#publication-failed","title":"Publication Failed","text":"<p>Check the Deployments tab in Central Portal for specific errors: - Missing POM information - Invalid GPG signatures - Missing Javadoc/Sources JARs</p>"},{"location":"PUBLISHING/#401-unauthorized-error","title":"\"401 Unauthorized\" Error","text":"<ul> <li>Regenerate your User Token in Central Portal</li> <li>Update GitHub Secrets with new credentials</li> </ul>"},{"location":"PUBLISHING/#quick-reference","title":"Quick Reference","text":"Resource URL Central Portal https://central.sonatype.com Maven Central Search https://search.maven.org GPG Keyserver https://keyserver.ubuntu.com Support Email central-support@sonatype.com"},{"location":"PUBLISHING/#summary-checklist","title":"Summary Checklist","text":"<ul> <li>[ ] Create Central Portal account (https://central.sonatype.com)</li> <li>[ ] Register and verify namespace <code>io.github.closeup1202</code></li> <li>[ ] Generate User Token</li> <li>[ ] Generate GPG key and upload to keyserver</li> <li>[ ] Configure GitHub Secrets</li> <li>[ ] Update version in <code>gradle.properties</code></li> <li>[ ] Create git tag and push</li> <li>[ ] Verify publication on Maven Central</li> </ul>"},{"location":"TROUBLESHOOTING/","title":"Troubleshooting Guide","text":"<p>This guide helps you diagnose and resolve common issues with Curve.</p>"},{"location":"TROUBLESHOOTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Event Publishing Issues</li> <li>Kafka Connection Issues</li> <li>Outbox Pattern Issues</li> <li>PII Processing Issues</li> <li>ID Generation Issues</li> <li>Performance Issues</li> <li>Health Check Failures</li> </ul>"},{"location":"TROUBLESHOOTING/#event-publishing-issues","title":"Event Publishing Issues","text":""},{"location":"TROUBLESHOOTING/#events-not-being-published","title":"Events Not Being Published","text":"<p>Symptoms: - <code>@PublishEvent</code> annotated methods execute but no events appear in Kafka - No errors in logs</p> <p>Possible Causes &amp; Solutions:</p> <ol> <li> <p>AOP not enabled <pre><code>curve:\n  aop:\n    enabled: true  # Ensure this is true\n</code></pre></p> </li> <li> <p>Method not proxied (Spring AOP limitation)    <pre><code>// BAD: Internal call bypasses AOP\npublic void methodA() {\n    methodB();  // @PublishEvent on methodB won't trigger\n}\n\n// GOOD: Use self-injection or refactor\n@Autowired\nprivate MyService self;\n\npublic void methodA() {\n    self.methodB();  // AOP will intercept\n}\n</code></pre></p> </li> <li> <p>Exception thrown before event creation</p> </li> <li>Check if method throws exception before returning</li> <li>Events are only published on successful method completion</li> </ol>"},{"location":"TROUBLESHOOTING/#events-published-but-not-in-kafka","title":"Events Published But Not in Kafka","text":"<p>Symptoms: - Logs show event creation but Kafka topic is empty - DLQ topic has events</p> <p>Diagnosis: <pre><code># Check DLQ topic\nkafka-console-consumer --bootstrap-server localhost:9094 \\\n  --topic event.audit.dlq.v1 --from-beginning\n</code></pre></p> <p>Solutions: 1. Check Kafka connectivity (see Kafka Connection Issues) 2. Verify topic exists and has correct permissions 3. Check for serialization errors in logs</p>"},{"location":"TROUBLESHOOTING/#duplicate-events","title":"Duplicate Events","text":"<p>Symptoms: - Same event appears multiple times in Kafka</p> <p>Possible Causes: 1. Retry mechanism triggering    - Normal behavior when initial send fails    - Check <code>curve.retry.max-attempts</code> setting</p> <ol> <li>Application restart during async send</li> <li>Use Outbox pattern for exactly-once semantics    <pre><code>curve:\n  outbox:\n    enabled: true\n</code></pre></li> </ol>"},{"location":"TROUBLESHOOTING/#kafka-connection-issues","title":"Kafka Connection Issues","text":""},{"location":"TROUBLESHOOTING/#connection-refused","title":"Connection Refused","text":"<p>Error: <pre><code>org.apache.kafka.common.errors.TimeoutException:\nFailed to update metadata after 60000 ms\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify Kafka is running <pre><code>docker ps | grep kafka\n# or\nnc -zv localhost 9094\n</code></pre></p> </li> <li> <p>Check bootstrap servers configuration <pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9094  # Correct address?\n</code></pre></p> </li> <li> <p>Network/Firewall issues</p> </li> <li>Ensure port 9094 is accessible</li> <li>Check Docker network configuration</li> </ol>"},{"location":"TROUBLESHOOTING/#ssltls-handshake-failure","title":"SSL/TLS Handshake Failure","text":"<p>Error: <pre><code>javax.net.ssl.SSLHandshakeException: PKIX path building failed\n</code></pre></p> <p>Solutions: <pre><code>spring:\n  kafka:\n    ssl:\n      trust-store-location: classpath:kafka.truststore.jks\n      trust-store-password: ${KAFKA_TRUSTSTORE_PASSWORD}\n    properties:\n      security.protocol: SSL\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#authentication-failure","title":"Authentication Failure","text":"<p>Error: <pre><code>org.apache.kafka.common.errors.SaslAuthenticationException\n</code></pre></p> <p>Solutions: <pre><code>spring:\n  kafka:\n    properties:\n      security.protocol: SASL_SSL\n      sasl.mechanism: PLAIN\n      sasl.jaas.config: &gt;\n        org.apache.kafka.common.security.plain.PlainLoginModule required\n        username=\"${KAFKA_USERNAME}\"\n        password=\"${KAFKA_PASSWORD}\";\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#outbox-pattern-issues","title":"Outbox Pattern Issues","text":""},{"location":"TROUBLESHOOTING/#events-stuck-in-pending-status","title":"Events Stuck in PENDING Status","text":"<p>Symptoms: - Events in outbox table remain in PENDING status - No events being published to Kafka</p> <p>Diagnosis: <pre><code>SELECT status, COUNT(*) FROM curve_outbox_events\nGROUP BY status;\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Publisher not enabled <pre><code>curve:\n  outbox:\n    enabled: true\n    publisher-enabled: true  # Must be true\n</code></pre></p> </li> <li> <p>Circuit breaker is open</p> </li> <li>Check logs for: <code>Circuit breaker is OPEN</code></li> <li> <p>Wait for recovery or fix Kafka connection    <pre><code>-- Check failed events\nSELECT * FROM curve_outbox_events\nWHERE status = 'PENDING' AND retry_count &gt; 0;\n</code></pre></p> </li> <li> <p>Database lock contention</p> </li> <li>Reduce batch size    <pre><code>curve:\n  outbox:\n    batch-size: 50  # Reduce from default 100\n</code></pre></li> </ol>"},{"location":"TROUBLESHOOTING/#outbox-table-not-created","title":"Outbox Table Not Created","text":"<p>Error: <pre><code>Table 'curve_outbox_events' doesn't exist\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Set initialization mode <pre><code>curve:\n  outbox:\n    initialize-schema: always  # Create if not exists\n</code></pre></p> </li> <li> <p>Create manually with migration tool <pre><code>CREATE TABLE curve_outbox_events (\n    id VARCHAR(36) PRIMARY KEY,\n    event_type VARCHAR(255) NOT NULL,\n    payload TEXT NOT NULL,\n    status VARCHAR(20) NOT NULL DEFAULT 'PENDING',\n    retry_count INT NOT NULL DEFAULT 0,\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    published_at TIMESTAMP,\n    error_message TEXT,\n    INDEX idx_status_created (status, created_at)\n);\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#events-processed-multiple-times","title":"Events Processed Multiple Times","text":"<p>Symptoms: - Duplicate processing after restart - Events published more than once</p> <p>Cause: Multiple publisher instances running</p> <p>Solutions: 1. Use distributed lock (recommended for clustered environments) 2. Disable publisher on some instances <pre><code># On secondary instances\ncurve:\n  outbox:\n    publisher-enabled: false  # Let CDC handle publishing\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#pii-processing-issues","title":"PII Processing Issues","text":""},{"location":"TROUBLESHOOTING/#pii-fields-not-masked","title":"PII Fields Not Masked","text":"<p>Symptoms: - Sensitive data appears in plain text in events</p> <p>Possible Causes:</p> <ol> <li> <p>Missing <code>@PiiField</code> annotation <pre><code>public class UserPayload {\n    @PiiField(type = PiiType.EMAIL)  // Required!\n    private String email;\n}\n</code></pre></p> </li> <li> <p>PII processor not configured <pre><code>curve:\n  pii:\n    enabled: true\n</code></pre></p> </li> <li> <p>Field is null or empty</p> </li> <li>Null/empty fields are not processed</li> </ol>"},{"location":"TROUBLESHOOTING/#encryption-key-not-found","title":"Encryption Key Not Found","text":"<p>Error: <pre><code>PiiEncryptionException: Encryption key not configured\n</code></pre></p> <p>Solution: <pre><code># Set environment variable\nexport CURVE_PII_ENCRYPTION_KEY=\"your-32-byte-base64-encoded-key\"\n</code></pre></p> <p>Generate a key: <pre><code>SecureRandom random = new SecureRandom();\nbyte[] key = new byte[32];\nrandom.nextBytes(key);\nString base64Key = Base64.getEncoder().encodeToString(key);\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#decryption-failure","title":"Decryption Failure","text":"<p>Error: <pre><code>javax.crypto.AEADBadTagException: Tag mismatch!\n</code></pre></p> <p>Possible Causes: 1. Wrong encryption key 2. Corrupted encrypted data 3. Key rotation without re-encryption</p> <p>Solution: Verify key consistency across environments</p>"},{"location":"TROUBLESHOOTING/#id-generation-issues","title":"ID Generation Issues","text":""},{"location":"TROUBLESHOOTING/#duplicate-ids-generated","title":"Duplicate IDs Generated","text":"<p>Symptoms: - <code>DuplicateKeyException</code> or constraint violations - Same ID appearing for different events</p> <p>Cause: Multiple instances using same worker ID</p> <p>Solutions:</p> <ol> <li> <p>Assign unique worker IDs <pre><code># Instance 1\ncurve:\n  id-generator:\n    worker-id: 1\n\n# Instance 2\ncurve:\n  id-generator:\n    worker-id: 2\n</code></pre></p> </li> <li> <p>Use environment-based configuration <pre><code>curve:\n  id-generator:\n    worker-id: ${WORKER_ID:1}\n</code></pre></p> </li> <li> <p>Kubernetes StatefulSet <pre><code>curve:\n  id-generator:\n    worker-id: ${POD_ORDINAL:1}\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#worker-id-out-of-range","title":"Worker ID Out of Range","text":"<p>Error: <pre><code>IllegalArgumentException: Worker ID must be between 0 and 1023\n</code></pre></p> <p>Solution: Ensure worker ID is in valid range (0-1023)</p>"},{"location":"TROUBLESHOOTING/#clock-moved-backwards","title":"Clock Moved Backwards","text":"<p>Error: <pre><code>ClockMovedBackwardsException: Clock moved backwards\n</code></pre></p> <p>Cause: System clock adjustment (NTP sync, VM migration)</p> <p>Solutions: 1. Use NTP with slew mode instead of step mode 2. Implement clock skew tolerance (built-in: 5ms) 3. Restart application if clock difference is large</p>"},{"location":"TROUBLESHOOTING/#performance-issues","title":"Performance Issues","text":""},{"location":"TROUBLESHOOTING/#high-latency-in-event-publishing","title":"High Latency in Event Publishing","text":"<p>Diagnosis: <pre><code># Check metrics endpoint\ncurl http://localhost:8080/actuator/curve-metrics\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Enable async mode <pre><code>curve:\n  kafka:\n    async-mode: true\n    async-timeout-ms: 5000\n</code></pre></p> </li> <li> <p>Tune Kafka producer <pre><code>spring:\n  kafka:\n    producer:\n      batch-size: 16384\n      linger-ms: 5\n      buffer-memory: 33554432\n</code></pre></p> </li> <li> <p>Reduce retry attempts <pre><code>curve:\n  retry:\n    max-attempts: 2\n    initial-interval: 500\n</code></pre></p> </li> </ol>"},{"location":"TROUBLESHOOTING/#memory-issues-with-large-events","title":"Memory Issues with Large Events","text":"<p>Symptoms: - OutOfMemoryError - GC pressure</p> <p>Solutions: 1. Limit payload size 2. Use compression    <pre><code>spring:\n  kafka:\n    producer:\n      compression-type: lz4\n</code></pre> 3. Stream large data separately, reference by ID in events</p>"},{"location":"TROUBLESHOOTING/#outbox-table-growing-too-large","title":"Outbox Table Growing Too Large","text":"<p>Diagnosis: <pre><code>SELECT COUNT(*) FROM curve_outbox_events;\nSELECT status, COUNT(*) FROM curve_outbox_events GROUP BY status;\n</code></pre></p> <p>Solutions: <pre><code>curve:\n  outbox:\n    cleanup-enabled: true\n    retention-days: 3        # Reduce retention\n    cleanup-cron: \"0 0 * * * *\"  # Run every hour\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#health-check-failures","title":"Health Check Failures","text":""},{"location":"TROUBLESHOOTING/#curve-health-indicator-down","title":"Curve Health Indicator DOWN","text":"<p>Check health endpoint: <pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre></p> <p>Possible causes: 1. Kafka connection lost 2. Outbox publisher stopped 3. Too many failed events</p> <p>Diagnosis: <pre><code># Full health details\ncurl http://localhost:8080/actuator/health/curve | jq\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#actuator-endpoint-not-available","title":"Actuator Endpoint Not Available","text":"<p>Error: 404 on <code>/actuator/curve-metrics</code></p> <p>Solution: <pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,curve-metrics\n</code></pre></p>"},{"location":"TROUBLESHOOTING/#getting-help","title":"Getting Help","text":"<p>If you can't resolve your issue:</p> <ol> <li> <p>Check logs with DEBUG level:    <pre><code>logging:\n  level:\n    com.project.curve: DEBUG\n</code></pre></p> </li> <li> <p>Gather diagnostics:</p> </li> <li>Application logs</li> <li>Health endpoint output</li> <li>Metrics endpoint output</li> <li> <p>Kafka topic state</p> </li> <li> <p>Open an issue at https://github.com/closeup1202/curve/issues with:</p> </li> <li>Curve version</li> <li>Spring Boot version</li> <li>Java version</li> <li>Configuration (sanitized)</li> <li>Error messages and stack traces</li> <li>Steps to reproduce</li> </ol>"},{"location":"api/annotations/","title":"Annotation Reference","text":"<p>Complete reference for all Curve annotations.</p>"},{"location":"api/annotations/#publishevent","title":"@PublishEvent","text":"<p>Marks a method to automatically publish events after execution.</p>"},{"location":"api/annotations/#package","title":"Package","text":"<pre><code>io.github.closeup1202.curve.spring.audit.annotation.PublishEvent\n</code></pre>"},{"location":"api/annotations/#parameters","title":"Parameters","text":"Parameter Type Required Default Description <code>eventType</code> String Yes - Unique event type identifier <code>severity</code> EventSeverity No INFO Event severity level <code>payload</code> String (SpEL) No \"#result\" Payload extraction expression <code>tags</code> Tag[] No {} Custom metadata tags <code>outbox</code> boolean No false Enable transactional outbox <code>aggregateType</code> String No \"\" Entity type for outbox <code>aggregateId</code> String (SpEL) No \"\" Entity ID for outbox"},{"location":"api/annotations/#example","title":"Example","text":"<pre><code>@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    severity = EventSeverity.INFO,\n    payload = \"#result.toDto()\",\n    tags = {\n        @Tag(key = \"region\", value = \"US\"),\n        @Tag(key = \"channel\", value = \"web\")\n    },\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre>"},{"location":"api/annotations/#piifield","title":"@PiiField","text":"<p>Marks a field for automatic PII protection.</p>"},{"location":"api/annotations/#package_1","title":"Package","text":"<pre><code>io.github.closeup1202.curve.spring.pii.annotation.PiiField\n</code></pre>"},{"location":"api/annotations/#parameters_1","title":"Parameters","text":"Parameter Type Required Default Description <code>type</code> PiiType Yes - Type of PII data <code>strategy</code> PiiStrategy Yes - Protection strategy <code>condition</code> String (SpEL) No \"\" Conditional protection"},{"location":"api/annotations/#piitype-values","title":"PiiType Values","text":"<ul> <li><code>EMAIL</code> - Email addresses</li> <li><code>PHONE</code> - Phone numbers</li> <li><code>SSN</code> - Social Security Numbers</li> <li><code>NAME</code> - Person names</li> <li><code>ADDRESS</code> - Physical addresses</li> <li><code>CREDIT_CARD</code> - Credit card numbers</li> <li><code>IP_ADDRESS</code> - IP addresses</li> <li><code>GENERIC</code> - Custom sensitive data</li> </ul>"},{"location":"api/annotations/#piistrategy-values","title":"PiiStrategy Values","text":"<ul> <li><code>MASK</code> - Pattern-based masking</li> <li><code>ENCRYPT</code> - AES-256-GCM encryption</li> <li><code>HASH</code> - SHA-256 hashing</li> </ul>"},{"location":"api/annotations/#example_1","title":"Example","text":"<pre><code>public class UserPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;\n}\n</code></pre>"},{"location":"api/annotations/#tag","title":"@Tag","text":"<p>Adds custom metadata tag to events (used within @PublishEvent).</p>"},{"location":"api/annotations/#package_2","title":"Package","text":"<pre><code>io.github.closeup1202.curve.spring.audit.annotation.Tag\n</code></pre>"},{"location":"api/annotations/#parameters_2","title":"Parameters","text":"Parameter Type Required Description <code>key</code> String Yes Tag key <code>value</code> String Yes Tag value"},{"location":"api/annotations/#example_2","title":"Example","text":"<pre><code>@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    tags = {\n        @Tag(key = \"region\", value = \"US-WEST\"),\n        @Tag(key = \"channel\", value = \"mobile\"),\n        @Tag(key = \"version\", value = \"v2\")\n    }\n)\n</code></pre>"},{"location":"api/annotations/#enums","title":"Enums","text":""},{"location":"api/annotations/#eventseverity","title":"EventSeverity","text":"<pre><code>public enum EventSeverity {\n    DEBUG,   // Development/debugging\n    INFO,    // Normal operations\n    WARN,    // Warnings\n    ERROR,   // Errors\n    FATAL    // Critical failures\n}\n</code></pre>"},{"location":"api/annotations/#spel-context-variables","title":"SpEL Context Variables","text":"<p>Available in SpEL expressions:</p> Variable Description Example <code>#result</code> Method return value <code>#result</code> <code>#args[n]</code> Method arguments (0-indexed) <code>#args[0]</code> <code>#root</code> Root evaluation context <code>#root.methodName</code> <code>#this</code> Current object <code>#this.getId()</code>"},{"location":"api/annotations/#example_3","title":"Example","text":"<pre><code>// Use return value\n@PublishEvent(payload = \"#result\")\n\n// Use method argument\n@PublishEvent(payload = \"#args[0].toDto()\")\n\n// Call method on return value\n@PublishEvent(payload = \"#result.getId()\")\n\n// Complex expression\n@PublishEvent(\n    payload = \"new PayloadDto(#args[0], #result)\"\n)\n</code></pre>"},{"location":"api/annotations/#best-practices","title":"Best Practices","text":"<ol> <li>Event Type Naming: Use SCREAMING_SNAKE_CASE (e.g., <code>ORDER_CREATED</code>)</li> <li>Severity Levels: Choose appropriate severity for filtering</li> <li>SpEL Expressions: Keep simple for maintainability</li> <li>PII Protection: Apply to all sensitive fields</li> <li>Tags: Use for filtering and routing downstream</li> </ol>"},{"location":"api/annotations/#see-also","title":"See Also","text":"<ul> <li>Declarative Publishing Guide</li> <li>PII Protection Guide</li> <li>Configuration Properties</li> </ul>"},{"location":"api/custom-implementation/","title":"Custom Implementation","text":"<p>Curve's hexagonal architecture makes it easy to extend and customize.</p>"},{"location":"api/custom-implementation/#custom-event-producer","title":"Custom Event Producer","text":"<p>Implement the <code>EventProducer</code> interface to support non-Kafka brokers.</p>"},{"location":"api/custom-implementation/#example-rabbitmq-producer","title":"Example: RabbitMQ Producer","text":"<pre><code>import io.github.closeup1202.curve.core.port.EventProducer;\nimport io.github.closeup1202.curve.core.envelope.EventEnvelope;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class RabbitMqEventProducer extends AbstractEventPublisher {\n\n    private final RabbitTemplate rabbitTemplate;\n    private final ObjectMapper objectMapper;\n\n    public RabbitMqEventProducer(\n        RabbitTemplate rabbitTemplate,\n        ObjectMapper objectMapper\n    ) {\n        this.rabbitTemplate = rabbitTemplate;\n        this.objectMapper = objectMapper;\n    }\n\n    @Override\n    protected &lt;T extends DomainEventPayload&gt; void send(EventEnvelope&lt;T&gt; envelope) {\n        try {\n            String json = objectMapper.writeValueAsString(envelope);\n            rabbitTemplate.convertAndSend(\n                \"events.exchange\",\n                envelope.getEventType(),\n                json\n            );\n        } catch (Exception e) {\n            throw new EventPublishException(\"Failed to publish to RabbitMQ\", e);\n        }\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#custom-context-provider","title":"Custom Context Provider","text":"<p>Add custom metadata to events.</p>"},{"location":"api/custom-implementation/#example-custom-tag-provider","title":"Example: Custom Tag Provider","text":"<pre><code>import io.github.closeup1202.curve.core.context.ContextProvider;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class FeatureFlagContextProvider implements ContextProvider {\n\n    private final FeatureFlagService featureFlagService;\n\n    @Override\n    public Map&lt;String, String&gt; provide() {\n        return Map.of(\n            \"experiment_id\", featureFlagService.getCurrentExperiment(),\n            \"feature_flags\", featureFlagService.getActiveFlags()\n        );\n    }\n}\n</code></pre> <p>Context providers are automatically discovered and added to event metadata.</p>"},{"location":"api/custom-implementation/#custom-serializer","title":"Custom Serializer","text":"<p>Implement custom serialization logic.</p>"},{"location":"api/custom-implementation/#example-protobuf-serializer","title":"Example: Protobuf Serializer","text":"<pre><code>import io.github.closeup1202.curve.core.serde.EventSerializer;\nimport com.google.protobuf.Message;\n\n@Component\npublic class ProtobufEventSerializer implements EventSerializer {\n\n    @Override\n    public byte[] serialize(EventEnvelope&lt;?&gt; envelope) {\n        EventProto.Event proto = EventProto.Event.newBuilder()\n            .setEventId(envelope.getEventId())\n            .setEventType(envelope.getEventType())\n            .setPayload(serializePayload(envelope.getPayload()))\n            .build();\n\n        return proto.toByteArray();\n    }\n\n    private ByteString serializePayload(DomainEventPayload payload) {\n        // Custom protobuf serialization\n        return ByteString.copyFrom(/* ... */);\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#custom-pii-strategy","title":"Custom PII Strategy","text":"<p>Implement custom PII protection logic.</p>"},{"location":"api/custom-implementation/#example-tokenization-strategy","title":"Example: Tokenization Strategy","text":"<pre><code>import io.github.closeup1202.curve.spring.pii.PiiProcessor;\n\n@Component\npublic class TokenizationPiiProcessor implements PiiProcessor {\n\n    private final TokenVault tokenVault;\n\n    @Override\n    public String process(String value, PiiType type, PiiStrategy strategy) {\n        if (strategy == PiiStrategy.TOKENIZE) {\n            return tokenVault.tokenize(value);\n        }\n        // Delegate to default processor\n        return defaultProcessor.process(value, type, strategy);\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#complete-example-aws-sns-producer","title":"Complete Example: AWS SNS Producer","text":"<pre><code>@Component\n@ConditionalOnProperty(name = \"curve.producer.type\", havingValue = \"sns\")\npublic class SnsEventProducer extends AbstractEventPublisher {\n\n    private final AmazonSNS snsClient;\n    private final ObjectMapper objectMapper;\n\n    @Value(\"${curve.sns.topic-arn}\")\n    private String topicArn;\n\n    public SnsEventProducer(AmazonSNS snsClient, ObjectMapper objectMapper) {\n        this.snsClient = snsClient;\n        this.objectMapper = objectMapper;\n    }\n\n    @Override\n    protected &lt;T extends DomainEventPayload&gt; void send(EventEnvelope&lt;T&gt; envelope) {\n        try {\n            String message = objectMapper.writeValueAsString(envelope);\n\n            PublishRequest request = new PublishRequest()\n                .withTopicArn(topicArn)\n                .withMessage(message)\n                .withMessageAttributes(buildAttributes(envelope));\n\n            snsClient.publish(request);\n\n        } catch (Exception e) {\n            throw new EventPublishException(\"Failed to publish to SNS\", e);\n        }\n    }\n\n    private Map&lt;String, MessageAttributeValue&gt; buildAttributes(EventEnvelope&lt;?&gt; envelope) {\n        return Map.of(\n            \"eventType\", new MessageAttributeValue()\n                .withDataType(\"String\")\n                .withStringValue(envelope.getEventType()),\n            \"severity\", new MessageAttributeValue()\n                .withDataType(\"String\")\n                .withStringValue(envelope.getSeverity().name())\n        );\n    }\n}\n</code></pre>"},{"location":"api/custom-implementation/#see-also","title":"See Also","text":"<ul> <li>Architecture Overview</li> <li>API Reference</li> </ul>"},{"location":"api/properties/","title":"Configuration Properties","text":"<p>Complete reference for all Curve configuration properties.</p>"},{"location":"api/properties/#core-configuration","title":"Core Configuration","text":""},{"location":"api/properties/#curveenabled","title":"curve.enabled","text":"<p>Enable or disable Curve.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  enabled: true\n</code></pre>"},{"location":"api/properties/#kafka-configuration","title":"Kafka Configuration","text":""},{"location":"api/properties/#curvekafkatopic","title":"curve.kafka.topic","text":"<p>Main Kafka topic for event publishing.</p> <ul> <li>Type: <code>string</code></li> <li>Required: Yes</li> </ul> <pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n</code></pre>"},{"location":"api/properties/#curvekafkadlq-topic","title":"curve.kafka.dlq-topic","text":"<p>Dead Letter Queue topic for failed events.</p> <ul> <li>Type: <code>string</code></li> <li>Required: No</li> </ul> <pre><code>curve:\n  kafka:\n    dlq-topic: event.audit.dlq.v1\n</code></pre>"},{"location":"api/properties/#curvekafkaasync-mode","title":"curve.kafka.async-mode","text":"<p>Enable asynchronous publishing for high throughput.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  kafka:\n    async-mode: true\n</code></pre>"},{"location":"api/properties/#curvekafkaasync-timeout-ms","title":"curve.kafka.async-timeout-ms","text":"<p>Timeout for async publishing (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>5000</code></li> </ul> <pre><code>curve:\n  kafka:\n    async-timeout-ms: 5000\n</code></pre>"},{"location":"api/properties/#curvekafkaretries","title":"curve.kafka.retries","text":"<p>Number of Kafka send retries.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>3</code></li> </ul> <pre><code>curve:\n  kafka:\n    retries: 3\n</code></pre>"},{"location":"api/properties/#curvekafkaretry-backoff-ms","title":"curve.kafka.retry-backoff-ms","text":"<p>Backoff time between retries (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1000</code></li> </ul> <pre><code>curve:\n  kafka:\n    retry-backoff-ms: 1000\n</code></pre>"},{"location":"api/properties/#curvekafkarequest-timeout-ms","title":"curve.kafka.request-timeout-ms","text":"<p>Kafka request timeout (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>30000</code></li> </ul> <pre><code>curve:\n  kafka:\n    request-timeout-ms: 30000\n</code></pre>"},{"location":"api/properties/#retry-configuration","title":"Retry Configuration","text":""},{"location":"api/properties/#curveretryenabled","title":"curve.retry.enabled","text":"<p>Enable retry mechanism for failed publishes.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  retry:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curveretrymax-attempts","title":"curve.retry.max-attempts","text":"<p>Maximum retry attempts.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>3</code></li> </ul> <pre><code>curve:\n  retry:\n    max-attempts: 3\n</code></pre>"},{"location":"api/properties/#curveretryinitial-interval","title":"curve.retry.initial-interval","text":"<p>Initial retry interval (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1000</code></li> </ul> <pre><code>curve:\n  retry:\n    initial-interval: 1000\n</code></pre>"},{"location":"api/properties/#curveretrymultiplier","title":"curve.retry.multiplier","text":"<p>Retry backoff multiplier.</p> <ul> <li>Type: <code>double</code></li> <li>Default: <code>2.0</code></li> </ul> <pre><code>curve:\n  retry:\n    multiplier: 2.0\n</code></pre>"},{"location":"api/properties/#curveretrymax-interval","title":"curve.retry.max-interval","text":"<p>Maximum retry interval (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>10000</code></li> </ul> <pre><code>curve:\n  retry:\n    max-interval: 10000\n</code></pre>"},{"location":"api/properties/#pii-configuration","title":"PII Configuration","text":""},{"location":"api/properties/#curvepiienabled","title":"curve.pii.enabled","text":"<p>Enable PII protection.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  pii:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curvepiicryptodefault-key","title":"curve.pii.crypto.default-key","text":"<p>Encryption key for PII (32 characters).</p> <ul> <li>Type: <code>string</code></li> <li>Required: For ENCRYPT strategy</li> </ul> <pre><code>curve:\n  pii:\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n</code></pre>"},{"location":"api/properties/#curvepiicryptosalt","title":"curve.pii.crypto.salt","text":"<p>Salt for hashing PII.</p> <ul> <li>Type: <code>string</code></li> <li>Required: For HASH strategy</li> </ul> <pre><code>curve:\n  pii:\n    crypto:\n      salt: ${PII_HASH_SALT}\n</code></pre>"},{"location":"api/properties/#outbox-configuration","title":"Outbox Configuration","text":""},{"location":"api/properties/#curveoutboxenabled","title":"curve.outbox.enabled","text":"<p>Enable transactional outbox pattern.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  outbox:\n    enabled: true\n</code></pre>"},{"location":"api/properties/#curveoutboxpoll-interval-ms","title":"curve.outbox.poll-interval-ms","text":"<p>Outbox poller interval (milliseconds).</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>1000</code></li> </ul> <pre><code>curve:\n  outbox:\n    poll-interval-ms: 1000\n</code></pre>"},{"location":"api/properties/#curveoutboxbatch-size","title":"curve.outbox.batch-size","text":"<p>Number of events processed per batch.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>100</code></li> </ul> <pre><code>curve:\n  outbox:\n    batch-size: 100\n</code></pre>"},{"location":"api/properties/#curveoutboxmax-retries","title":"curve.outbox.max-retries","text":"<p>Max retries for failed outbox events.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>3</code></li> </ul> <pre><code>curve:\n  outbox:\n    max-retries: 3\n</code></pre>"},{"location":"api/properties/#curveoutboxcleanup-enabled","title":"curve.outbox.cleanup-enabled","text":"<p>Enable automatic cleanup of old events.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  outbox:\n    cleanup-enabled: true\n</code></pre>"},{"location":"api/properties/#curveoutboxretention-days","title":"curve.outbox.retention-days","text":"<p>Days to retain completed events.</p> <ul> <li>Type: <code>integer</code></li> <li>Default: <code>7</code></li> </ul> <pre><code>curve:\n  outbox:\n    retention-days: 7\n</code></pre>"},{"location":"api/properties/#curveoutboxcleanup-cron","title":"curve.outbox.cleanup-cron","text":"<p>Cron expression for cleanup job.</p> <ul> <li>Type: <code>string</code></li> <li>Default: <code>\"0 0 2 * * *\"</code> (2 AM daily)</li> </ul> <pre><code>curve:\n  outbox:\n    cleanup-cron: \"0 0 2 * * *\"\n</code></pre>"},{"location":"api/properties/#serialization-configuration","title":"Serialization Configuration","text":""},{"location":"api/properties/#curveserdetype","title":"curve.serde.type","text":"<p>Serialization format.</p> <ul> <li>Type: <code>enum</code></li> <li>Values: <code>JSON</code>, <code>AVRO</code>, <code>PROTOBUF</code></li> <li>Default: <code>JSON</code></li> </ul> <pre><code>curve:\n  serde:\n    type: JSON\n</code></pre>"},{"location":"api/properties/#id-generator-configuration","title":"ID Generator Configuration","text":""},{"location":"api/properties/#curveid-generatorworker-id","title":"curve.id-generator.worker-id","text":"<p>Snowflake worker ID (0-1023).</p> <ul> <li>Type: <code>integer</code></li> <li>Range: <code>0-1023</code></li> <li>Default: Auto-generated</li> </ul> <pre><code>curve:\n  id-generator:\n    worker-id: 1\n</code></pre>"},{"location":"api/properties/#curveid-generatorauto-generate","title":"curve.id-generator.auto-generate","text":"<p>Auto-generate worker ID from hostname/IP.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>true</code></li> </ul> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre>"},{"location":"api/properties/#security-configuration","title":"Security Configuration","text":""},{"location":"api/properties/#curvesecurityuse-forwarded-headers","title":"curve.security.use-forwarded-headers","text":"<p>Use X-Forwarded-* headers for IP extraction.</p> <ul> <li>Type: <code>boolean</code></li> <li>Default: <code>false</code></li> </ul> <pre><code>curve:\n  security:\n    use-forwarded-headers: true  # When behind proxy\n</code></pre>"},{"location":"api/properties/#complete-example","title":"Complete Example","text":"application.yml<pre><code>spring:\n  application:\n    name: my-service\n  kafka:\n    bootstrap-servers: localhost:9094\n\ncurve:\n  enabled: true\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false\n    async-timeout-ms: 5000\n    retries: 3\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n      salt: ${PII_HASH_SALT}\n\n  outbox:\n    enabled: true\n    poll-interval-ms: 1000\n    batch-size: 100\n    max-retries: 3\n    cleanup-enabled: true\n    retention-days: 7\n    cleanup-cron: \"0 0 2 * * *\"\n\n  serde:\n    type: JSON\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  security:\n    use-forwarded-headers: false\n</code></pre>"},{"location":"api/properties/#environment-specific-profiles","title":"Environment-Specific Profiles","text":"<p>See Configuration Guide for environment-specific examples.</p>"},{"location":"community/faq/","title":"Frequently Asked Questions","text":""},{"location":"community/faq/#general-questions","title":"General Questions","text":""},{"location":"community/faq/#what-is-curve","title":"What is Curve?","text":"<p>Curve is a declarative event publishing library for Spring Boot applications. It simplifies event-driven architecture by providing automatic Kafka publishing, PII protection, DLQ handling, and observability with minimal code.</p>"},{"location":"community/faq/#why-use-curve-instead-of-spring-kafka-directly","title":"Why use Curve instead of Spring Kafka directly?","text":"<p>Curve reduces boilerplate by 90% while providing:</p> <ul> <li>Declarative annotations (<code>@PublishEvent</code>)</li> <li>Automatic PII protection</li> <li>Built-in DLQ and backup</li> <li>Standardized event structure</li> <li>Production-ready observability</li> </ul>"},{"location":"community/faq/#is-curve-production-ready","title":"Is Curve production-ready?","text":"<p>Yes! Curve is designed for production use with:</p> <ul> <li>Comprehensive testing (&gt;80% coverage)</li> <li>Battle-tested patterns (outbox, DLQ, retry)</li> <li>Observability and monitoring</li> <li>Active maintenance</li> </ul>"},{"location":"community/faq/#compatibility","title":"Compatibility","text":""},{"location":"community/faq/#what-versions-of-spring-boot-are-supported","title":"What versions of Spring Boot are supported?","text":"<p>Curve supports Spring Boot 3.0+. For specific version compatibility, see the Installation Guide.</p>"},{"location":"community/faq/#what-kafka-versions-are-supported","title":"What Kafka versions are supported?","text":"<p>Kafka 2.8+ is supported. Kafka 3.0+ is recommended for best performance.</p>"},{"location":"community/faq/#can-i-use-curve-with-spring-boot-2x","title":"Can I use Curve with Spring Boot 2.x?","text":"<p>Not currently. Curve requires Spring Boot 3.0+ due to Jakarta EE dependencies.</p>"},{"location":"community/faq/#configuration","title":"Configuration","text":""},{"location":"community/faq/#how-do-i-enable-async-publishing","title":"How do I enable async publishing?","text":"<pre><code>curve:\n  kafka:\n    async-mode: true\n    async-timeout-ms: 5000\n</code></pre> <p>See Configuration Guide for details.</p>"},{"location":"community/faq/#how-do-i-configure-multiple-kafka-topics","title":"How do I configure multiple Kafka topics?","text":"<p>Currently, Curve uses a single main topic. For multiple topics, you can:</p> <ol> <li>Use different event types and route downstream</li> <li>Implement custom <code>EventProducer</code> with routing logic</li> </ol>"},{"location":"community/faq/#can-i-disable-curve-conditionally","title":"Can I disable Curve conditionally?","text":"<p>Yes, use Spring profiles:</p> <pre><code>spring:\n  profiles: prod\n\ncurve:\n  enabled: true\n</code></pre>"},{"location":"community/faq/#features","title":"Features","text":""},{"location":"community/faq/#does-curve-support-transactional-publishing","title":"Does Curve support transactional publishing?","text":"<p>Yes! Use the Transactional Outbox Pattern:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true\n)\n</code></pre>"},{"location":"community/faq/#can-i-publish-events-without-kafka","title":"Can I publish events without Kafka?","text":"<p>Yes, Curve's hexagonal architecture allows custom implementations. See Custom Implementation Guide.</p>"},{"location":"community/faq/#does-curve-support-event-replay","title":"Does Curve support event replay?","text":"<p>Not built-in, but you can:</p> <ol> <li>Republish from DLQ topic</li> <li>Republish from outbox table</li> <li>Use Kafka's consumer group reset</li> </ol>"},{"location":"community/faq/#performance","title":"Performance","text":""},{"location":"community/faq/#whats-the-throughput","title":"What's the throughput?","text":"<ul> <li>Sync mode: ~500 TPS</li> <li>Async mode: ~10,000+ TPS</li> <li>Transactional outbox: ~1,000 TPS</li> </ul>"},{"location":"community/faq/#how-can-i-improve-performance","title":"How can I improve performance?","text":"<ol> <li>Enable async mode</li> <li>Increase Kafka batch size</li> <li>Use connection pooling</li> <li>Scale Kafka brokers</li> </ol>"},{"location":"community/faq/#does-curve-add-latency","title":"Does Curve add latency?","text":"<p>Minimal overhead (~5-10ms) for:</p> <ul> <li>Annotation processing</li> <li>Metadata extraction</li> <li>PII protection</li> </ul>"},{"location":"community/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"community/faq/#events-not-publishing","title":"Events not publishing?","text":"<p>Check:</p> <ol> <li><code>curve.enabled=true</code></li> <li>Kafka connection is healthy</li> <li>Method is called through Spring proxy (not <code>this.method()</code>)</li> <li>No exceptions before method completes</li> </ol> <p>See Troubleshooting Guide.</p>"},{"location":"community/faq/#pii-not-being-masked","title":"PII not being masked?","text":"<p>Verify:</p> <ol> <li><code>curve.pii.enabled=true</code></li> <li><code>@PiiField</code> annotation is present</li> <li>Payload class implements <code>DomainEventPayload</code></li> </ol>"},{"location":"community/faq/#outbox-events-stuck-in-pending","title":"Outbox events stuck in PENDING?","text":"<p>Check:</p> <ol> <li>Outbox poller is running (enable DEBUG logging)</li> <li>Kafka is accessible</li> <li>No database connection issues</li> </ol>"},{"location":"community/faq/#best-practices","title":"Best Practices","text":""},{"location":"community/faq/#should-i-use-outbox-for-all-events","title":"Should I use outbox for all events?","text":"<p>No. Use outbox for:</p> <ul> <li>Critical events (payments, orders)</li> <li>Events requiring atomicity</li> </ul> <p>Use async for:</p> <ul> <li>High-volume events</li> <li>Non-critical events</li> </ul>"},{"location":"community/faq/#what-should-i-include-in-event-payload","title":"What should I include in event payload?","text":"<p>Include:</p> <ul> <li>Essential data for consumers</li> <li>Identifiers (IDs)</li> <li>Timestamps</li> </ul> <p>Exclude:</p> <ul> <li>Large objects (&gt;1MB)</li> <li>Binary data</li> <li>Entire entity graphs</li> </ul>"},{"location":"community/faq/#how-should-i-name-event-types","title":"How should I name event types?","text":"<p>Use SCREAMING_SNAKE_CASE with entity and action:</p> <ul> <li>\u2705 <code>ORDER_CREATED</code>, <code>PAYMENT_COMPLETED</code></li> <li>\u274c <code>created</code>, <code>update</code>, <code>event</code></li> </ul>"},{"location":"community/faq/#advanced","title":"Advanced","text":""},{"location":"community/faq/#can-i-customize-event-metadata","title":"Can I customize event metadata?","text":"<p>Yes, implement <code>ContextProvider</code>:</p> <pre><code>@Component\npublic class CustomContextProvider implements ContextProvider {\n    @Override\n    public Map&lt;String, String&gt; provide() {\n        return Map.of(\"custom_key\", \"custom_value\");\n    }\n}\n</code></pre>"},{"location":"community/faq/#can-i-use-curve-with-kotlin","title":"Can I use Curve with Kotlin?","text":"<p>Yes! Curve works with Kotlin:</p> <pre><code>@PublishEvent(eventType = \"ORDER_CREATED\")\nfun createOrder(request: OrderRequest): Order {\n    return orderRepository.save(Order(request))\n}\n</code></pre>"},{"location":"community/faq/#can-i-publish-events-manually","title":"Can I publish events manually?","text":"<p>Yes, inject <code>EventProducer</code>:</p> <pre><code>@Autowired\nprivate EventProducer eventProducer;\n\npublic void manualPublish() {\n    EventEnvelope&lt;MyPayload&gt; envelope = EventEnvelope.builder()\n        .eventType(\"MANUAL_EVENT\")\n        .payload(new MyPayload())\n        .build();\n\n    eventProducer.publish(envelope);\n}\n</code></pre>"},{"location":"community/faq/#contributing","title":"Contributing","text":""},{"location":"community/faq/#how-can-i-contribute","title":"How can I contribute?","text":"<p>See our Contributing Guide for:</p> <ul> <li>Code contributions</li> <li>Bug reports</li> <li>Feature requests</li> <li>Documentation improvements</li> </ul>"},{"location":"community/faq/#where-can-i-ask-questions","title":"Where can I ask questions?","text":"<ul> <li>GitHub Issues</li> <li>GitHub Discussions</li> <li>Email: closeup1202@gmail.com</li> </ul>"},{"location":"community/faq/#still-have-questions","title":"Still have questions?","text":"<p>Check our Documentation or open an issue.</p>"},{"location":"configuration/basic-setup/","title":"Basic Setup Guide","text":"<p>This guide covers the fundamental configuration options for Curve.</p>"},{"location":"configuration/basic-setup/#basic-configuration","title":"Basic Configuration","text":""},{"location":"configuration/basic-setup/#applicationyml","title":"application.yml","text":"<pre><code>curve:\n  enabled: true  # Enable Curve (default: true)\n\n  kafka:\n    topic: event.audit.v1  # Main topic name\n    dlq-topic: event.audit.dlq.v1  # DLQ topic (optional)\n\n  id-generator:\n    worker-id: 1  # Snowflake Worker ID (0~1023)\n    auto-generate: false  # Auto-generate based on MAC address\n</code></pre>"},{"location":"configuration/basic-setup/#configuration-validation","title":"Configuration Validation","text":"<p>Curve automatically validates configuration values at application startup using <code>@Validated</code>.</p>"},{"location":"configuration/basic-setup/#validation-rules","title":"Validation Rules","text":"Configuration Item Validation Rule Error Message <code>curve.kafka.topic</code> Required (non-empty string) \"Kafka topic is required\" <code>curve.kafka.retries</code> 0 or greater \"retries must be 0 or greater\" <code>curve.kafka.retry-backoff-ms</code> Positive number \"retryBackoffMs must be positive\" <code>curve.kafka.request-timeout-ms</code> Positive number \"requestTimeoutMs must be positive\" <code>curve.kafka.async-timeout-ms</code> Positive number \"asyncTimeoutMs must be positive\" <code>curve.kafka.sync-timeout-seconds</code> Positive number \"syncTimeoutSeconds must be positive\" <code>curve.kafka.dlq-executor-threads</code> 1 or greater \"dlqExecutorThreads must be 1 or greater\" <code>curve.id-generator.worker-id</code> 0 ~ 1023 \"workerId must be between 0 and 1023\" <code>curve.retry.max-attempts</code> 1 or greater \"maxAttempts must be 1 or greater\" <code>curve.retry.initial-interval</code> Positive number \"initialInterval must be positive\" <code>curve.retry.multiplier</code> 1 or greater \"multiplier must be 1 or greater\" <code>curve.retry.max-interval</code> Positive number \"maxInterval must be positive\" <code>curve.outbox.poll-interval-ms</code> Positive number \"pollIntervalMs must be positive\" <code>curve.outbox.batch-size</code> 1 ~ 1000 \"batchSize must be between 1 and 1000\" <code>curve.outbox.max-retries</code> 1 or greater \"maxRetries must be 1 or greater\" <code>curve.outbox.send-timeout-seconds</code> Positive number \"sendTimeoutSeconds must be positive\" <code>curve.outbox.retention-days</code> 1 or greater \"retentionDays must be 1 or greater\""},{"location":"configuration/basic-setup/#worker-id-configuration","title":"Worker ID Configuration","text":"<p>The Snowflake ID Generator uses a Worker ID to generate unique IDs in a distributed environment.</p>"},{"location":"configuration/basic-setup/#method-1-explicit-worker-id-configuration-recommended","title":"Method 1: Explicit Worker ID Configuration (Recommended)","text":"<p>Assign a unique Worker ID to each instance.</p> <pre><code>curve:\n  id-generator:\n    worker-id: 1  # Instance 1\n    auto-generate: false\n</code></pre>"},{"location":"configuration/basic-setup/#method-2-auto-generation-caution","title":"Method 2: Auto-Generation (Caution)","text":"<p>Auto-generate Worker ID based on MAC address.</p> <pre><code>curve:\n  id-generator:\n    auto-generate: true\n</code></pre>"},{"location":"configuration/basic-setup/#kafka-transmission-mode-configuration","title":"Kafka Transmission Mode Configuration","text":"<p>Curve supports both synchronous and asynchronous transmission modes.</p>"},{"location":"configuration/basic-setup/#synchronous-transmission-default","title":"Synchronous Transmission (Default)","text":"<pre><code>curve:\n  kafka:\n    async-mode: false  # Synchronous transmission\n    request-timeout-ms: 30000  # 30 seconds\n</code></pre>"},{"location":"configuration/basic-setup/#asynchronous-transmission","title":"Asynchronous Transmission","text":"<pre><code>curve:\n  kafka:\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000  # 5 seconds timeout\n</code></pre>"},{"location":"configuration/basic-setup/#dlq-configuration","title":"DLQ Configuration","text":"<p>The Dead Letter Queue stores events that fail to be transmitted.</p> <pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # Enable DLQ\n</code></pre>"},{"location":"configuration/basic-setup/#retry-configuration","title":"Retry Configuration","text":"<p>Automatic retry configuration in case of transmission failure.</p> <pre><code>curve:\n  retry:\n    enabled: true  # Enable retry\n    max-attempts: 3  # Maximum 3 attempts\n    initial-interval: 1000  # Initial 1 second wait\n    multiplier: 2.0  # Increase by 2x (1s -&gt; 2s -&gt; 4s)\n    max-interval: 10000  # Maximum 10 seconds\n</code></pre>"},{"location":"configuration/basic-setup/#pii-protection-configuration","title":"PII Protection Configuration","text":"<p>Through PII (Personally Identifiable Information) protection features, sensitive data can be automatically masked, encrypted, or hashed.</p> <pre><code>curve:\n  pii:\n    enabled: true  # Enable PII protection (default: true)\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Encryption key (environment variable required)\n      salt: ${PII_HASH_SALT}              # Hashing salt (environment variable recommended)\n</code></pre>"},{"location":"configuration/basic-setup/#outbox-configuration","title":"Outbox Configuration","text":"<p>Use the Transactional Outbox Pattern to ensure atomicity between DB transactions and event publishing.</p> <pre><code>curve:\n  outbox:\n    enabled: true  # Enable Outbox\n    poll-interval-ms: 1000  # Polling interval (1 second)\n    batch-size: 100  # Batch size\n    max-retries: 3  # Maximum retry count\n    send-timeout-seconds: 10  # Send timeout\n    cleanup-enabled: true  # Enable old event cleanup\n    retention-days: 7  # Retention period (7 days)\n    cleanup-cron: \"0 0 2 * * *\"  # Cleanup job execution time (2 AM daily)\n    initialize-schema: embedded  # Schema initialization mode (embedded, always, never)\n</code></pre>"},{"location":"configuration/basic-setup/#serialization-configuration","title":"Serialization Configuration","text":"<p>Configure the event payload serialization method.</p> <pre><code>curve:\n  serde:\n    type: JSON  # JSON (default), AVRO, PROTOBUF\n</code></pre>"},{"location":"configuration/basic-setup/#logging-configuration","title":"Logging Configuration","text":"<p>By default, Curve outputs minimal logs. To see detailed configuration information or internal operations, enable the DEBUG level.</p> <pre><code>logging:\n  level:\n    com.project.curve: DEBUG\n</code></pre>"},{"location":"configuration/profiles/","title":"Environment Profiles","text":"<p>This guide provides configuration examples and recommendations for different environments.</p>"},{"location":"configuration/profiles/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"configuration/profiles/#production-environment-stability-focused","title":"Production Environment (Stability-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${INSTANCE_ID}  # Injected from environment variable\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # Synchronous transmission\n    retries: 5\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n\n  retry:\n    enabled: true\n    max-attempts: 5\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  aop:\n    enabled: true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # Environment variable required\n      salt: ${PII_HASH_SALT}\n\n  outbox:\n    enabled: true\n    initialize-schema: never  # Use Flyway\n    cleanup-enabled: true\n    retention-days: 14\n</code></pre>"},{"location":"configuration/profiles/#developmenttest-environment-performance-focused","title":"Development/Test Environment (Performance-focused)","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.dev.v1\n    dlq-topic: event.audit.dlq.dev.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 3000\n    retries: 3\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 500\n    multiplier: 1.5\n\n  aop:\n    enabled: true\n\n  outbox:\n    enabled: true\n    initialize-schema: always\n</code></pre>"},{"location":"configuration/profiles/#high-performance-environment","title":"High-Performance Environment","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: ${WORKER_ID}\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: true  # Asynchronous transmission\n    async-timeout-ms: 5000\n    retries: 1  # Minimum retry\n\n  retry:\n    enabled: false  # Disable retry (performance priority)\n\n  aop:\n    enabled: true\n</code></pre>"},{"location":"configuration/profiles/#environment-specific-configuration-recommendations","title":"Environment-specific Configuration Recommendations","text":""},{"location":"configuration/profiles/#local-development","title":"Local Development","text":"<ul> <li>Worker ID: 1 (fixed)</li> <li>Transmission Mode: Synchronous (debugging convenience)</li> <li>DLQ: Enabled</li> <li>Retry: Minimum (fast failure)</li> <li>Outbox: Enabled (auto schema generation)</li> </ul>"},{"location":"configuration/profiles/#staging","title":"Staging","text":"<ul> <li>Worker ID: Environment variable</li> <li>Transmission Mode: Asynchronous</li> <li>DLQ: Enabled</li> <li>Retry: Medium level</li> <li>Outbox: Enabled</li> </ul>"},{"location":"configuration/profiles/#production","title":"Production","text":"<ul> <li>Worker ID: Centrally managed (Consul/etcd)</li> <li>Transmission Mode: Based on business requirements</li> <li>DLQ: Mandatory enabled</li> <li>Retry: High level</li> <li>Outbox: Mandatory enabled (data consistency)</li> </ul>"},{"location":"features/declarative-publishing/","title":"Declarative Event Publishing","text":"<p>The <code>@PublishEvent</code> annotation is the core feature of Curve, enabling declarative event publishing with minimal code.</p>"},{"location":"features/declarative-publishing/#basic-usage","title":"Basic Usage","text":"<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(eventType = \"ORDER_CREATED\")\n    public Order createOrder(OrderRequest request) {\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre> <p>When <code>createOrder()</code> is called, Curve automatically:</p> <ol> <li>Captures the method return value (<code>Order</code>)</li> <li>Extracts metadata (trace ID, user, etc.)</li> <li>Wraps it in <code>EventEnvelope</code></li> <li>Publishes to Kafka</li> </ol>"},{"location":"features/declarative-publishing/#annotation-parameters","title":"Annotation Parameters","text":""},{"location":"features/declarative-publishing/#required-parameters","title":"Required Parameters","text":""},{"location":"features/declarative-publishing/#eventtype-string","title":"<code>eventType</code> (String)","text":"<p>Unique identifier for this event type.</p> <pre><code>@PublishEvent(eventType = \"USER_REGISTERED\")\n</code></pre> <p>Naming conventions:</p> <ul> <li>Use SCREAMING_SNAKE_CASE</li> <li>Be specific: <code>ORDER_CREATED</code> not just <code>CREATED</code></li> <li>Include entity name: <code>USER_DELETED</code>, <code>PAYMENT_COMPLETED</code></li> </ul>"},{"location":"features/declarative-publishing/#optional-parameters","title":"Optional Parameters","text":""},{"location":"features/declarative-publishing/#severity-eventseverity","title":"<code>severity</code> (EventSeverity)","text":"<p>Event severity level for filtering and alerting.</p> <pre><code>@PublishEvent(\n    eventType = \"PAYMENT_FAILED\",\n    severity = EventSeverity.ERROR\n)\n</code></pre> <p>Available values:</p> <ul> <li><code>DEBUG</code> - Development/debugging</li> <li><code>INFO</code> - Normal operations (default)</li> <li><code>WARN</code> - Warnings</li> <li><code>ERROR</code> - Errors requiring attention</li> <li><code>FATAL</code> - Critical failures</li> </ul>"},{"location":"features/declarative-publishing/#payload-spel-expression","title":"<code>payload</code> (SpEL Expression)","text":"<p>Extract specific data for the event payload using Spring Expression Language.</p> <pre><code>@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#args[0].toEventDto()\"  // Transform request\n)\npublic User updateUser(UserUpdateRequest request) {\n    return userRepository.save(request.toEntity());\n}\n</code></pre> <p>SpEL Variables:</p> Variable Description Example <code>#result</code> Method return value <code>#result</code> <code>#args[n]</code> Method arguments <code>#args[0]</code>, <code>#args[1]</code> <code>#root</code> Root evaluation context <code>#root.methodName</code> <p>Examples:</p> <pre><code>// Use entire return value (default)\n@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest req) { ... }\n\n// Use specific field\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    payload = \"#result.id\"\n)\npublic Order createOrder(OrderRequest req) { ... }\n\n// Transform with custom method\n@PublishEvent(\n    eventType = \"USER_CREATED\",\n    payload = \"#result.toPublicDto()\"\n)\npublic User createUser(UserRequest req) { ... }\n\n// Use method argument\n@PublishEvent(\n    eventType = \"ORDER_SUBMITTED\",\n    payload = \"#args[0]\"\n)\npublic Order submitOrder(OrderSubmission submission) { ... }\n</code></pre>"},{"location":"features/declarative-publishing/#tags-map","title":"<code>tags</code> (Map) <p>Add custom metadata tags to events.</p> <pre><code>@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    tags = {\n        @Tag(key = \"region\", value = \"US-WEST\"),\n        @Tag(key = \"channel\", value = \"mobile\")\n    }\n)\n</code></pre> <p>Tags are useful for:</p> <ul> <li>Filtering events downstream</li> <li>Regional routing</li> <li>A/B testing markers</li> <li>Feature flags</li> </ul>","text":""},{"location":"features/declarative-publishing/#transactional-outbox-parameters","title":"Transactional Outbox Parameters <p>For guaranteed delivery with transactional outbox pattern:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,                      // Enable outbox\n    aggregateType = \"Order\",            // Entity type\n    aggregateId = \"#result.id\"          // Entity ID\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>Parameters:</p>    Parameter Type Description     <code>outbox</code> boolean Enable transactional outbox   <code>aggregateType</code> String Entity type name   <code>aggregateId</code> SpEL Entity unique identifier    <p> Transactional Outbox Guide</p>","text":""},{"location":"features/declarative-publishing/#advanced-examples","title":"Advanced Examples","text":""},{"location":"features/declarative-publishing/#1-multi-parameter-method","title":"1. Multi-Parameter Method","text":"<pre><code>@PublishEvent(\n    eventType = \"ORDER_SHIPPED\",\n    payload = \"new ShipmentPayload(#args[0], #args[1], #result)\"\n)\npublic Shipment shipOrder(Long orderId, Address address) {\n    // ...\n    return shipment;\n}\n</code></pre>"},{"location":"features/declarative-publishing/#2-conditional-publishing","title":"2. Conditional Publishing","text":"<p>Use Spring's conditional annotations:</p> <pre><code>@ConditionalOnProperty(name = \"features.audit\", havingValue = \"true\")\n@PublishEvent(eventType = \"ADMIN_ACTION\")\npublic void performAdminAction(AdminRequest request) {\n    // ...\n}\n</code></pre>"},{"location":"features/declarative-publishing/#3-method-level-configuration","title":"3. Method-Level Configuration","text":"<p>Override global settings per method:</p> <pre><code>@Service\npublic class CriticalService {\n\n    // High-priority event with custom severity\n    @PublishEvent(\n        eventType = \"FRAUD_DETECTED\",\n        severity = EventSeverity.FATAL,\n        tags = {@Tag(key = \"priority\", value = \"critical\")}\n    )\n    public FraudAlert detectFraud(Transaction tx) {\n        // ...\n    }\n}\n</code></pre>"},{"location":"features/declarative-publishing/#4-async-method-publishing","title":"4. Async Method Publishing","text":"<p>Works with <code>@Async</code> methods:</p> <pre><code>@Async\n@PublishEvent(eventType = \"REPORT_GENERATED\")\npublic CompletableFuture&lt;Report&gt; generateReport(ReportRequest req) {\n    Report report = reportGenerator.generate(req);\n    return CompletableFuture.completedFuture(report);\n}\n</code></pre> <p>MDC Context Propagation</p> <p>Curve automatically propagates MDC context (trace ID, etc.) to async threads.</p>"},{"location":"features/declarative-publishing/#best-practices","title":"Best Practices","text":""},{"location":"features/declarative-publishing/#do","title":"DO","text":"<ul> <li>Use descriptive event types: <code>USER_REGISTERED</code>, <code>ORDER_COMPLETED</code></li> <li>Apply on service layer methods (not controllers or repositories)</li> <li>Keep payload minimal - only essential data</li> <li>Use <code>@PiiField</code> for sensitive data</li> <li>Set appropriate severity levels</li> </ul>"},{"location":"features/declarative-publishing/#dont","title":"DON'T","text":"<ul> <li>Publish high-volume events in sync mode (use async)</li> <li>Include entire entities as payload (extract DTOs)</li> <li>Publish from controllers (breaks separation of concerns)</li> <li>Use generic event types like <code>CREATED</code> or <code>UPDATED</code></li> </ul>"},{"location":"features/declarative-publishing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/declarative-publishing/#events-not-publishing","title":"Events Not Publishing","text":"<p>Events not appearing in Kafka</p> <p>Check:</p> <ol> <li><code>curve.enabled=true</code> in application.yml</li> <li>Method is called through Spring proxy (not <code>this.method()</code>)</li> <li>No exceptions thrown before method completes</li> <li>Kafka connection is healthy</li> </ol> <p>Debug:</p> <pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n</code></pre>"},{"location":"features/declarative-publishing/#payload-extraction-fails","title":"Payload Extraction Fails","text":"<p>SpEL evaluation error</p> <p>Common issues:</p> <ul> <li>Typo in SpEL expression</li> <li>Accessing null fields</li> <li>Wrong argument index</li> </ul> <p>Solution:</p> <pre><code>// Add null check\n@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#result != null ? #result.toDto() : null\"\n)\n</code></pre>"},{"location":"features/declarative-publishing/#whats-next","title":"What's Next?","text":"<ul> <li> <p> PII Protection</p> <p>Automatically protect sensitive data</p> <p> PII Guide</p> </li> <li> <p> Transactional Outbox</p> <p>Guarantee exactly-once delivery</p> <p> Outbox Pattern</p> </li> <li> <p> API Reference</p> <p>Complete annotation reference</p> <p> API Docs</p> </li> </ul>"},{"location":"features/failure-recovery/","title":"Failure Recovery","text":"<p>Curve provides 3-tier failure recovery to ensure zero event loss, even when Kafka is down.</p>"},{"location":"features/failure-recovery/#overview","title":"Overview","text":"<pre><code>graph LR\n    A[Event] --&gt; B{Publish to Main Topic}\n    B --&gt;|Success| C[Done \u2713]\n    B --&gt;|Failure| D{Publish to DLQ}\n    D --&gt;|Success| E[DLQ \u2713]\n    D --&gt;|Failure| F[Local File Backup \ud83d\udcbe]\n\n    style C fill:#00897b\n    style E fill:#ff9800\n    style F fill:#f44336\n</code></pre>"},{"location":"features/failure-recovery/#tiers","title":"Tiers","text":"<ol> <li>Main Topic - Primary Kafka topic for events</li> <li>DLQ (Dead Letter Queue) - Fallback topic for failed events</li> <li>Local File Backup - Last resort when Kafka is unavailable</li> </ol>"},{"location":"features/failure-recovery/#configuration","title":"Configuration","text":"application.yml<pre><code>curve:\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1  # DLQ topic\n\n  retry:\n    enabled: true\n    max-attempts: 3           # Retry 3 times\n    initial-interval: 1000    # 1 second\n    multiplier: 2.0           # Exponential backoff\n    max-interval: 10000       # Max 10 seconds\n</code></pre>"},{"location":"features/failure-recovery/#tier-1-main-topic","title":"Tier 1: Main Topic","text":"<p>Normal event publishing to the primary Kafka topic.</p> <pre><code>@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>Retry behavior:</p> <ul> <li>Attempt 1: Immediate</li> <li>Attempt 2: Wait 1 second</li> <li>Attempt 3: Wait 2 seconds (1s \u00d7 2.0)</li> <li>Attempt 4: Wait 4 seconds (2s \u00d7 2.0)</li> </ul> <p>If all attempts fail \u2192 Move to Tier 2 (DLQ)</p>"},{"location":"features/failure-recovery/#tier-2-dead-letter-queue-dlq","title":"Tier 2: Dead Letter Queue (DLQ)","text":"<p>Failed events are sent to a separate DLQ topic for analysis and reprocessing.</p>"},{"location":"features/failure-recovery/#dlq-event-structure","title":"DLQ Event Structure","text":"<pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"originalTopic\": \"event.audit.v1\",\n  \"failureReason\": \"Kafka broker not available\",\n  \"failureTimestamp\": \"2025-02-03T10:30:00Z\",\n  \"retryCount\": 3,\n  \"originalEvent\": {\n    \"eventType\": \"ORDER_CREATED\",\n    \"payload\": { ... }\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#monitoring-dlq","title":"Monitoring DLQ","text":""},{"location":"features/failure-recovery/#1-kafka-console-consumer","title":"1. Kafka Console Consumer","text":"<pre><code>kafka-console-consumer --bootstrap-server localhost:9094 \\\n    --topic event.audit.dlq.v1 --from-beginning\n</code></pre>"},{"location":"features/failure-recovery/#2-kafka-ui","title":"2. Kafka UI","text":"<p>Access Kafka UI at http://localhost:8080 and navigate to the DLQ topic.</p>"},{"location":"features/failure-recovery/#3-spring-boot-actuator","title":"3. Spring Boot Actuator","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"dlq\": {\n    \"totalDlqEvents\": 5,\n    \"recentDlqEvents\": [\n      {\n        \"eventType\": \"ORDER_CREATED\",\n        \"failureReason\": \"Timeout\",\n        \"timestamp\": \"2025-02-03T10:30:00Z\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#tier-3-local-file-backup","title":"Tier 3: Local File Backup","text":"<p>If Kafka is completely unavailable (broker down, network issue), events are saved to local disk.</p>"},{"location":"features/failure-recovery/#backup-location","title":"Backup Location","text":"<pre><code>/tmp/curve-backup/\n  \u2514\u2500\u2500 failed-events/\n      \u251c\u2500\u2500 1738587000000.json\n      \u251c\u2500\u2500 1738587001000.json\n      \u2514\u2500\u2500 1738587002000.json\n</code></pre>"},{"location":"features/failure-recovery/#backup-file-format","title":"Backup File Format","text":"1738587000000.json<pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"ORDER_CREATED\",\n  \"occurredAt\": \"2025-02-03T10:30:00Z\",\n  \"backupReason\": \"Kafka broker unavailable\",\n  \"backupTimestamp\": \"2025-02-03T10:30:00.500Z\",\n  \"payload\": { ... }\n}\n</code></pre>"},{"location":"features/failure-recovery/#configuration_1","title":"Configuration","text":"<pre><code>curve:\n  backup:\n    enabled: true\n    directory: /var/lib/curve/backup  # Custom location\n    max-file-size-mb: 10\n    max-files: 1000\n</code></pre>"},{"location":"features/failure-recovery/#recovery-process","title":"Recovery Process","text":""},{"location":"features/failure-recovery/#1-manual-recovery-with-script","title":"1. Manual Recovery with Script","text":"<p>Curve provides a recovery script for republishing backed-up events:</p> scripts/dlq-recovery.sh<pre><code>#!/bin/bash\n\n# List backup files\n./scripts/dlq-recovery.sh --list\n\n# Recover all files\n./scripts/dlq-recovery.sh \\\n    --topic event.audit.v1 \\\n    --broker localhost:9094\n\n# Recover specific file\n./scripts/dlq-recovery.sh \\\n    --file /tmp/curve-backup/failed-events/1738587000000.json \\\n    --topic event.audit.v1 \\\n    --broker localhost:9094\n</code></pre>"},{"location":"features/failure-recovery/#2-automated-recovery-future-feature","title":"2. Automated Recovery (Future Feature)","text":"<p>Planned for v0.1.0:</p> <ul> <li>Automatic retry from local backup when Kafka recovers</li> <li>Configurable recovery schedule</li> <li>Recovery metrics and alerts</li> </ul>"},{"location":"features/failure-recovery/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"features/failure-recovery/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"dlqEnabled\": true,\n    \"backupEnabled\": true,\n    \"backupDirectory\": \"/tmp/curve-backup\",\n    \"backupFileCount\": 0\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#metrics","title":"Metrics","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\",\n    \"totalDlqEvents\": 3,\n    \"totalBackupFiles\": 0\n  }\n}\n</code></pre>"},{"location":"features/failure-recovery/#alerts","title":"Alerts","text":"<p>Set up alerts for:</p> <ul> <li>DLQ event count &gt; threshold</li> <li>Backup file count &gt; 0</li> <li>Success rate &lt; 99%</li> </ul> <p>Example with Prometheus:</p> <pre><code>- alert: HighDLQEventCount\n  expr: curve_dlq_events_total &gt; 10\n  for: 5m\n  annotations:\n    summary: \"High DLQ event count detected\"\n</code></pre>"},{"location":"features/failure-recovery/#best-practices","title":"Best Practices","text":""},{"location":"features/failure-recovery/#do","title":"DO","text":"<ul> <li>Monitor DLQ regularly - Set up alerts for DLQ events</li> <li>Investigate failures - Analyze failure reasons</li> <li>Test recovery - Practice recovery procedures</li> <li>Set up alerts - Notify on backup file creation</li> <li>Regular cleanup - Archive old backup files</li> </ul>"},{"location":"features/failure-recovery/#dont","title":"DON'T","text":"<ul> <li>Ignore DLQ events - they indicate issues</li> <li>Disable backup in production</li> <li>Store backups on ephemeral storage (e.g., /tmp in containers)</li> <li>Delete backup files without analysis</li> </ul>"},{"location":"features/failure-recovery/#production-recommendations","title":"Production Recommendations","text":""},{"location":"features/failure-recovery/#1-persistent-backup-storage","title":"1. Persistent Backup Storage","text":"<p>Use persistent volumes for backups in Kubernetes:</p> deployment.yaml<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: curve-backup\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n\n---\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      volumes:\n        - name: backup\n          persistentVolumeClaim:\n            claimName: curve-backup\n      containers:\n        - name: app\n          volumeMounts:\n            - name: backup\n              mountPath: /var/lib/curve/backup\n</code></pre>"},{"location":"features/failure-recovery/#2-separate-dlq-consumer","title":"2. Separate DLQ Consumer","text":"<p>Create a dedicated consumer for DLQ analysis:</p> <pre><code>@KafkaListener(topics = \"event.audit.dlq.v1\")\npublic void handleDlqEvent(DlqEvent event) {\n    log.error(\"DLQ Event: {} - Reason: {}\",\n        event.getEventType(),\n        event.getFailureReason()\n    );\n\n    // Send alert\n    alertService.sendAlert(event);\n\n    // Store for analysis\n    dlqRepository.save(event);\n}\n</code></pre>"},{"location":"features/failure-recovery/#3-automated-recovery-job","title":"3. Automated Recovery Job","text":"<p>Run periodic recovery job:</p> <pre><code>@Scheduled(fixedDelay = 3600000) // Every hour\npublic void recoverBackupFiles() {\n    List&lt;File&gt; backups = backupService.listBackupFiles();\n\n    for (File backup : backups) {\n        try {\n            eventProducer.republish(backup);\n            backup.delete();\n        } catch (Exception e) {\n            log.error(\"Recovery failed for {}\", backup, e);\n        }\n    }\n}\n</code></pre>"},{"location":"features/failure-recovery/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/failure-recovery/#dlq-events-not-created","title":"DLQ Events Not Created","text":"<p>Events failing but no DLQ events</p> <p>Check:</p> <ol> <li><code>curve.kafka.dlq-topic</code> is configured</li> <li>DLQ topic exists in Kafka</li> <li>Kafka is accessible</li> </ol>"},{"location":"features/failure-recovery/#backup-files-accumulating","title":"Backup Files Accumulating","text":"<p>Many backup files created</p> <p>Possible causes:</p> <ul> <li>Kafka broker down</li> <li>Network issues</li> <li>Authentication failure</li> </ul> <p>Solution:</p> <ol> <li>Check Kafka health: <code>docker-compose ps</code></li> <li>Verify bootstrap servers</li> <li>Check Kafka logs</li> </ol>"},{"location":"features/failure-recovery/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Transactional Outbox</p> <p>Guarantee atomicity</p> <p> Outbox Pattern</p> </li> <li> <p> Observability</p> <p>Monitor your events</p> <p> Observability</p> </li> </ul>"},{"location":"features/observability/","title":"Observability","text":"<p>Curve provides built-in observability through Spring Boot Actuator, custom metrics, and health checks.</p>"},{"location":"features/observability/#health-checks","title":"Health Checks","text":""},{"location":"features/observability/#curve-health-indicator","title":"Curve Health Indicator","text":"<p>Check Curve's operational status:</p> <pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"producerMetrics\": 42,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\",\n    \"outboxEnabled\": true,\n    \"backupEnabled\": true\n  }\n}\n</code></pre>"},{"location":"features/observability/#configuration","title":"Configuration","text":"application.yml<pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,metrics,curve-metrics\n  endpoint:\n    health:\n      show-details: always\n</code></pre>"},{"location":"features/observability/#custom-metrics-endpoint","title":"Custom Metrics Endpoint","text":"<p>Curve exposes a dedicated metrics endpoint:</p> <pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <p>Response:</p> <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\",\n    \"totalDlqEvents\": 3,\n    \"totalKafkaErrors\": 0\n  },\n  \"events\": {\n    \"published\": [\n      {\n        \"name\": \"events.published.total\",\n        \"description\": \"Total published events\",\n        \"baseUnit\": \"events\",\n        \"measurements\": [\n          { \"statistic\": \"COUNT\", \"value\": 1523.0 }\n        ]\n      }\n    ],\n    \"publishDuration\": [\n      {\n        \"name\": \"events.publish.duration\",\n        \"description\": \"Event publish duration\",\n        \"baseUnit\": \"milliseconds\",\n        \"measurements\": [\n          { \"statistic\": \"MEAN\", \"value\": 45.2 },\n          { \"statistic\": \"MAX\", \"value\": 150.0 }\n        ]\n      }\n    ]\n  },\n  \"dlq\": {\n    \"totalDlqEvents\": 3,\n    \"recentDlqEvents\": [\n      {\n        \"eventType\": \"ORDER_CREATED\",\n        \"failureReason\": \"Kafka timeout\",\n        \"timestamp\": \"2025-02-03T10:30:00Z\"\n      }\n    ]\n  },\n  \"kafka\": {\n    \"connectionCount\": 1,\n    \"inFlightRequests\": 0,\n    \"requestLatencyAvg\": 25.5\n  }\n}\n</code></pre>"},{"location":"features/observability/#micrometer-metrics","title":"Micrometer Metrics","text":"<p>Curve integrates with Micrometer for standard metrics:</p>"},{"location":"features/observability/#available-metrics","title":"Available Metrics","text":"Metric Type Description <code>curve.events.published.total</code> Counter Total events published <code>curve.events.failed.total</code> Counter Total failed events <code>curve.events.publish.duration</code> Timer Event publish duration <code>curve.dlq.events.total</code> Counter Total DLQ events <code>curve.outbox.pending</code> Gauge Pending outbox events <code>curve.kafka.errors.total</code> Counter Kafka errors"},{"location":"features/observability/#prometheus-integration","title":"Prometheus Integration","text":"application.yml<pre><code>management:\n  metrics:\n    export:\n      prometheus:\n        enabled: true\n  endpoints:\n    web:\n      exposure:\n        include: prometheus\n</code></pre> <p>Scrape metrics:</p> <pre><code>curl http://localhost:8080/actuator/prometheus | grep curve\n</code></pre> <p>Output:</p> <pre><code># TYPE curve_events_published_total counter\ncurve_events_published_total{eventType=\"ORDER_CREATED\",} 856.0\ncurve_events_published_total{eventType=\"USER_REGISTERED\",} 667.0\n\n# TYPE curve_events_publish_duration_seconds summary\ncurve_events_publish_duration_seconds_count 1523.0\ncurve_events_publish_duration_seconds_sum 68.8\n</code></pre>"},{"location":"features/observability/#logging","title":"Logging","text":""},{"location":"features/observability/#enable-debug-logging","title":"Enable Debug Logging","text":"application.yml<pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n    io.github.closeup1202.curve.kafka: TRACE  # Kafka-specific\n</code></pre>"},{"location":"features/observability/#log-output","title":"Log Output","text":"<pre><code>2025-02-03 10:30:00.123 DEBUG [curve] Publishing event: ORDER_CREATED\n2025-02-03 10:30:00.125 DEBUG [curve.kafka] Sending to topic: event.audit.v1\n2025-02-03 10:30:00.150 INFO  [curve] Event published successfully: eventId=7355889748156289024\n</code></pre>"},{"location":"features/observability/#structured-logging-json","title":"Structured Logging (JSON)","text":"<pre><code>logging:\n  pattern:\n    console: '{\"time\":\"%d\",\"level\":\"%p\",\"logger\":\"%c\",\"message\":\"%m\"}%n'\n</code></pre>"},{"location":"features/observability/#distributed-tracing","title":"Distributed Tracing","text":"<p>Curve automatically propagates trace context:</p>"},{"location":"features/observability/#spring-cloud-sleuth-integration","title":"Spring Cloud Sleuth Integration","text":"<pre><code>dependencies {\n    implementation 'org.springframework.cloud:spring-cloud-starter-sleuth'\n}\n</code></pre> <p>Trace context in events:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"metadata\": {\n    \"trace\": {\n      \"traceId\": \"abc123\",       // \u2190 Propagated\n      \"spanId\": \"def456\",         // \u2190 Propagated\n      \"parentSpanId\": \"ghi789\"\n    }\n  }\n}\n</code></pre>"},{"location":"features/observability/#mdc-context-propagation","title":"MDC Context Propagation","text":"<p>Even in async mode, MDC context is preserved:</p> <pre><code>@Async\n@PublishEvent(eventType = \"REPORT_GENERATED\")\npublic CompletableFuture&lt;Report&gt; generateReport() {\n    // Trace ID available in logs\n    log.info(\"Generating report\");\n    return CompletableFuture.completedFuture(new Report());\n}\n</code></pre>"},{"location":"features/observability/#dashboards","title":"Dashboards","text":""},{"location":"features/observability/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Import the Curve Grafana dashboard:</p> curve-dashboard.json<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Curve Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Event Throughput\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(curve_events_published_total[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Success Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"curve_events_published_total / (curve_events_published_total + curve_events_failed_total) * 100\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"features/observability/#key-panels","title":"Key Panels","text":"<ol> <li>Event Throughput - Events/sec over time</li> <li>Success Rate - Percentage of successful publishes</li> <li>DLQ Events - Failed events count</li> <li>Publish Latency - P50, P95, P99 latencies</li> <li>Outbox Queue - Pending events in outbox</li> </ol>"},{"location":"features/observability/#alerts","title":"Alerts","text":""},{"location":"features/observability/#prometheus-alerting-rules","title":"Prometheus Alerting Rules","text":"alerts.yml<pre><code>groups:\n  - name: curve\n    interval: 30s\n    rules:\n      - alert: HighEventFailureRate\n        expr: |\n          (\n            rate(curve_events_failed_total[5m])\n            /\n            rate(curve_events_published_total[5m])\n          ) &gt; 0.01\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High event failure rate ({{ $value }}%)\"\n\n      - alert: DLQEventsDetected\n        expr: curve_dlq_events_total &gt; 10\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"{{ $value }} events in DLQ\"\n\n      - alert: OutboxQueueGrowing\n        expr: curve_outbox_pending &gt; 1000\n        for: 10m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Outbox queue has {{ $value }} pending events\"\n\n      - alert: KafkaConnectionLost\n        expr: curve_kafka_connection_count == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Kafka connection lost\"\n</code></pre>"},{"location":"features/observability/#best-practices","title":"Best Practices","text":""},{"location":"features/observability/#do","title":"DO","text":"<ul> <li>Enable health checks - Monitor Curve status</li> <li>Set up alerts - Notify on failures</li> <li>Monitor DLQ - Investigate failed events</li> <li>Track success rate - Aim for &gt;99.9%</li> <li>Use distributed tracing - Debug issues across services</li> <li>Dashboard key metrics - Visualize trends</li> </ul>"},{"location":"features/observability/#dont","title":"DON'T","text":"<ul> <li>Ignore DLQ events</li> <li>Disable metrics in production</li> <li>Skip alerting setup</li> <li>Log at TRACE level in production</li> </ul>"},{"location":"features/observability/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/observability/#metrics-not-appearing","title":"Metrics Not Appearing","text":"<p>Metrics endpoint returns empty</p> <p>Check:</p> <ol> <li>Actuator is enabled: <code>management.endpoints.web.exposure.include=curve-metrics</code></li> <li>Curve is enabled: <code>curve.enabled=true</code></li> <li>Events have been published</li> </ol>"},{"location":"features/observability/#high-latency","title":"High Latency","text":"<p>Publish duration &gt; 1 second</p> <p>Possible causes:</p> <ul> <li>Network latency to Kafka</li> <li>Large payloads</li> <li>Kafka broker overload</li> </ul> <p>Solutions:</p> <ol> <li>Enable async mode: <code>curve.kafka.async-mode=true</code></li> <li>Reduce payload size</li> <li>Scale Kafka brokers</li> </ol>"},{"location":"features/observability/#production-checklist","title":"Production Checklist","text":"<ul> <li>[ ] Enable health checks</li> <li>[ ] Set up Prometheus scraping</li> <li>[ ] Create Grafana dashboards</li> <li>[ ] Configure alerting rules</li> <li>[ ] Enable distributed tracing</li> <li>[ ] Set up log aggregation</li> <li>[ ] Monitor DLQ topic</li> <li>[ ] Test failover scenarios</li> </ul>"},{"location":"features/observability/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Operations Guide</p> <p>Production deployment best practices</p> <p> Operations</p> </li> <li> <p> Troubleshooting</p> <p>Common issues and solutions</p> <p> Troubleshooting</p> </li> </ul>"},{"location":"features/overview/","title":"Features Overview","text":"<p>Curve provides production-ready features for event-driven microservices out of the box.</p>"},{"location":"features/overview/#core-features","title":"Core Features","text":""},{"location":"features/overview/#declarative-event-publishing","title":"Declarative Event Publishing","text":"<p>Publish events with a single annotation - no boilerplate code required.</p> <pre><code>@PublishEvent(eventType = \"ORDER_CREATED\")\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>Benefits:</p> <ul> <li>90% less code compared to manual Kafka usage</li> <li>Type-safe with compile-time validation</li> <li>SpEL support for flexible payload extraction</li> </ul> <p> Learn more</p>"},{"location":"features/overview/#standardized-event-structure","title":"Standardized Event Structure","text":"<p>All events follow CloudEvents-inspired schema:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"ORDER_CREATED\",\n  \"occurredAt\": \"2025-02-03T10:30:00Z\",\n  \"publishedAt\": \"2025-02-03T10:30:00.123Z\",\n  \"severity\": \"INFO\",\n  \"metadata\": {\n    \"source\": { ... },\n    \"actor\": { ... },\n    \"trace\": { ... },\n    \"tags\": { ... }\n  },\n  \"payload\": { ... }\n}\n</code></pre> <p>Metadata includes:</p> <ul> <li>Source: Service name, version, hostname</li> <li>Actor: User ID, session ID, roles</li> <li>Trace: Distributed tracing (trace ID, span ID)</li> <li>Tags: Custom key-value pairs</li> </ul>"},{"location":"features/overview/#3-tier-failure-recovery","title":"3-Tier Failure Recovery","text":"<p>Main Topic \u2192 DLQ \u2192 Local File Backup</p> <p>Zero event loss even when Kafka is completely down.</p> <ol> <li>Primary: Publish to main Kafka topic</li> <li>DLQ: Failed events sent to Dead Letter Queue</li> <li>Backup: If Kafka unavailable, save to local disk</li> </ol> <p> Failure Recovery Guide</p>"},{"location":"features/overview/#automatic-pii-protection","title":"Automatic PII Protection","text":"<p>Annotate sensitive fields and Curve handles the rest:</p> <pre><code>public class UserPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;  // \u2192 \"j***@ex***.com\"\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;  // \u2192 Encrypted with AES-256-GCM\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;   // \u2192 SHA-256 hashed\n}\n</code></pre> <p> PII Protection Guide</p>"},{"location":"features/overview/#high-performance","title":"High Performance","text":"Mode Throughput Use Case Sync ~500 TPS Strong consistency Async ~10,000+ TPS High throughput Transactional Outbox ~1,000 TPS Atomicity guarantee <p>Async Mode with MDC context propagation:</p> <pre><code>curve:\n  kafka:\n    async-mode: true\n    async-timeout-ms: 5000\n</code></pre>"},{"location":"features/overview/#transactional-outbox-pattern","title":"Transactional Outbox Pattern","text":"<p>Guarantee atomicity between database and event publishing:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre> <p>How it works:</p> <ol> <li>Event saved to DB in same transaction</li> <li>Background poller publishes to Kafka</li> <li>Exponential backoff for retries</li> <li><code>SKIP LOCKED</code> prevents duplicate processing</li> </ol> <p> Outbox Pattern Guide</p>"},{"location":"features/overview/#built-in-observability","title":"Built-in Observability","text":""},{"location":"features/overview/#health-checks","title":"Health Checks","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"producerMetrics\": 42,\n    \"topic\": \"event.audit.v1\"\n  }\n}\n</code></pre>"},{"location":"features/overview/#custom-metrics","title":"Custom Metrics","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\"\n  }\n}\n</code></pre> <p> Observability Guide</p>"},{"location":"features/overview/#architecture","title":"Architecture","text":""},{"location":"features/overview/#hexagonal-architecture-ports-adapters","title":"Hexagonal Architecture (Ports &amp; Adapters)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Domain Layer (Core)         \u2502\n\u2502  \u2022 EventEnvelope, EventMetadata     \u2502\n\u2502  \u2022 Framework-independent            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                \u2502\n        \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Spring   \u2502      \u2502   Kafka    \u2502\n\u2502 (Adapter) \u2502      \u2502 (Adapter)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits:</p> <ul> <li>Framework-independent core</li> <li>Easy to test</li> <li>Extensible (can swap Kafka for RabbitMQ, etc.)</li> </ul>"},{"location":"features/overview/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Quick Start</p> <p>Get up and running in 5 minutes</p> <p> Quick Start</p> </li> <li> <p> PII Protection</p> <p>Protect sensitive data automatically</p> <p> PII Guide</p> </li> <li> <p> Failure Recovery</p> <p>Handle failures gracefully</p> <p> Failure Recovery</p> </li> <li> <p> Configuration</p> <p>Production-ready settings</p> <p> Configuration</p> </li> </ul>"},{"location":"features/pii-protection/","title":"PII Protection","text":"<p>Curve provides automatic PII (Personally Identifiable Information) protection with declarative annotations.</p>"},{"location":"features/pii-protection/#quick-start","title":"Quick Start","text":"<pre><code>import io.github.closeup1202.curve.spring.pii.annotation.PiiField;\nimport io.github.closeup1202.curve.spring.pii.type.PiiType;\nimport io.github.closeup1202.curve.spring.pii.strategy.PiiStrategy;\n\npublic class UserPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;  // \"user@example.com\" \u2192 \"u***@ex***.com\"\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;  // \"+1234567890\" \u2192 \"AES-encrypted\"\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;   // \"John Doe\" \u2192 \"5a4b3c2d...\"\n}\n</code></pre>"},{"location":"features/pii-protection/#protection-strategies","title":"Protection Strategies","text":""},{"location":"features/pii-protection/#1-mask-pattern-based-masking","title":"1. MASK - Pattern-Based Masking","text":"<p>Partially hides data while keeping it recognizable.</p> <pre><code>@PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\nprivate String email;\n</code></pre> <p>Examples:</p> PII Type Original Masked EMAIL <code>john.doe@example.com</code> <code>j***@ex***.com</code> PHONE <code>+1-555-123-4567</code> <code>+1-***-***-4567</code> SSN <code>123-45-6789</code> <code>***-**-6789</code> NAME <code>John Michael Doe</code> <code>J*** M*** D***</code> ADDRESS <code>123 Main St, City</code> <code>*** Main St, ***</code> CREDIT_CARD <code>1234-5678-9012-3456</code> <code>****-****-****-3456</code> <p>When to use:</p> <ul> <li>Logs and audit trails</li> <li>Customer support dashboards</li> <li>Non-production environments</li> </ul>"},{"location":"features/pii-protection/#2-encrypt-reversible-encryption","title":"2. ENCRYPT - Reversible Encryption","text":"<p>AES-256-GCM encryption for reversible protection.</p> <pre><code>@PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\nprivate String phone;\n</code></pre> <p>Output:</p> <pre><code>Original: +1-555-123-4567\nEncrypted: AQIDAHj8...9f3a2b1c0 (Base64-encoded)\n</code></pre> <p>When to use:</p> <ul> <li>Data that needs to be decrypted later</li> <li>Cross-service communication</li> <li>Secure storage</li> </ul> <p>Configuration:</p> <pre><code>curve:\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # 32-character key\n</code></pre> <p>Key Management</p> <p>Store encryption keys in secure vaults (AWS Secrets Manager, HashiCorp Vault, etc.)</p>"},{"location":"features/pii-protection/#3-hash-irreversible-hashing","title":"3. HASH - Irreversible Hashing","text":"<p>SHA-256 hashing for one-way protection.</p> <pre><code>@PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\nprivate String name;\n</code></pre> <p>Output:</p> <pre><code>Original: John Doe\nHashed: 5a4b3c2d1e0f9a8b7c6d5e4f3a2b1c0d...\n</code></pre> <p>When to use:</p> <ul> <li>Analytics and aggregation</li> <li>Deduplication</li> <li>Data that should never be reversed</li> </ul> <p>Configuration:</p> <pre><code>curve:\n  pii:\n    crypto:\n      salt: ${PII_HASH_SALT}  # Add salt for security\n</code></pre>"},{"location":"features/pii-protection/#supported-pii-types","title":"Supported PII Types","text":"PII Type Description Example <code>EMAIL</code> Email addresses john@example.com <code>PHONE</code> Phone numbers +1-555-123-4567 <code>SSN</code> Social Security Numbers 123-45-6789 <code>NAME</code> Full names John Doe <code>ADDRESS</code> Physical addresses 123 Main St <code>CREDIT_CARD</code> Credit card numbers 1234-5678-9012-3456 <code>IP_ADDRESS</code> IP addresses 192.168.1.1 <code>GENERIC</code> Custom sensitive data Any string"},{"location":"features/pii-protection/#configuration","title":"Configuration","text":""},{"location":"features/pii-protection/#enable-pii-protection","title":"Enable PII Protection","text":"application.yml<pre><code>curve:\n  pii:\n    enabled: true  # Default: true\n\n    crypto:\n      # AES-256 encryption key (32 characters)\n      default-key: ${PII_ENCRYPTION_KEY}\n\n      # Salt for hashing (recommended)\n      salt: ${PII_HASH_SALT}\n</code></pre>"},{"location":"features/pii-protection/#environment-variables","title":"Environment Variables","text":".env<pre><code>PII_ENCRYPTION_KEY=your-32-character-secret-key!!\nPII_HASH_SALT=random-salt-for-hashing-123\n</code></pre>"},{"location":"features/pii-protection/#advanced-usage","title":"Advanced Usage","text":""},{"location":"features/pii-protection/#custom-masking-patterns","title":"Custom Masking Patterns","text":"<p>Create custom masking logic:</p> <pre><code>public class CustomMaskingStrategy implements PiiMaskingStrategy {\n\n    @Override\n    public String mask(String value, PiiType type) {\n        // Custom masking logic\n        return maskCustom(value);\n    }\n}\n</code></pre> <p>Register as Spring bean:</p> <pre><code>@Configuration\npublic class PiiConfig {\n\n    @Bean\n    public PiiMaskingStrategy customMaskingStrategy() {\n        return new CustomMaskingStrategy();\n    }\n}\n</code></pre>"},{"location":"features/pii-protection/#conditional-protection","title":"Conditional Protection","text":"<p>Protect fields conditionally based on environment:</p> <pre><code>public class UserPayload {\n\n    @PiiField(\n        type = PiiType.EMAIL,\n        strategy = PiiStrategy.MASK,\n        condition = \"#{environment.getProperty('app.environment') == 'prod'}\"\n    )\n    private String email;\n}\n</code></pre>"},{"location":"features/pii-protection/#best-practices","title":"Best Practices","text":""},{"location":"features/pii-protection/#do","title":"DO","text":"<ul> <li>Use MASK for logs - Keeps data recognizable for debugging</li> <li>Use ENCRYPT for storage - Allows decryption when needed</li> <li>Use HASH for analytics - Irreversible for aggregation</li> <li>Rotate keys regularly - Update encryption keys periodically</li> <li>Store keys securely - Use secret management services</li> </ul>"},{"location":"features/pii-protection/#dont","title":"DON'T","text":"<ul> <li>Store encryption keys in source code</li> <li>Use HASH when you need to decrypt later</li> <li>Over-mask data (e.g., masking non-sensitive fields)</li> <li>Use weak keys (less than 32 characters)</li> </ul>"},{"location":"features/pii-protection/#compliance","title":"Compliance","text":"<p>Curve's PII protection helps with:</p> <ul> <li>GDPR (General Data Protection Regulation)</li> <li>CCPA (California Consumer Privacy Act)</li> <li>HIPAA (Health Insurance Portability and Accountability Act)</li> <li>PCI DSS (Payment Card Industry Data Security Standard)</li> </ul> <p>Legal Disclaimer</p> <p>Curve provides tools for PII protection, but compliance is the responsibility of the application owner.</p>"},{"location":"features/pii-protection/#examples","title":"Examples","text":""},{"location":"features/pii-protection/#complete-user-event","title":"Complete User Event","text":"<pre><code>public class UserRegisteredPayload implements DomainEventPayload {\n\n    private Long userId;\n    private String username;  // Not sensitive\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String firstName;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String lastName;\n\n    @PiiField(type = PiiType.ADDRESS, strategy = PiiStrategy.MASK)\n    private String address;\n\n    @PiiField(type = PiiType.IP_ADDRESS, strategy = PiiStrategy.HASH)\n    private String lastLoginIp;\n\n    private Instant createdAt;\n}\n</code></pre> <p>Published Event:</p> <pre><code>{\n  \"userId\": 12345,\n  \"username\": \"john_doe\",\n  \"email\": \"j***@ex***.com\",\n  \"phone\": \"AQIDAHj8...9f3a2b1c0\",\n  \"firstName\": \"5a4b3c2d...\",\n  \"lastName\": \"7f8e9d1a...\",\n  \"address\": \"*** Main St, ***\",\n  \"lastLoginIp\": \"8f7e6d5c...\",\n  \"createdAt\": \"2025-02-03T10:30:00Z\"\n}\n</code></pre>"},{"location":"features/pii-protection/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Failure Recovery</p> <p>Handle failures with DLQ</p> <p> Failure Recovery</p> </li> <li> <p> Transactional Outbox</p> <p>Guarantee event delivery</p> <p> Outbox Pattern</p> </li> </ul>"},{"location":"features/transactional-outbox/","title":"Transactional Outbox Pattern","text":"<p>Guarantee atomicity between database transactions and event publishing with Curve's transactional outbox pattern.</p>"},{"location":"features/transactional-outbox/#the-problem","title":"The Problem","text":"<p>Without transactional outbox:</p> <pre><code>@Transactional\npublic Order createOrder(OrderRequest request) {\n    // 1. Save to database\n    Order order = orderRepository.save(new Order(request));\n\n    // 2. Publish to Kafka\n    kafkaProducer.send(\"orders\", orderEvent);  // \u274c What if this fails?\n\n    return order;\n}\n</code></pre> <p>Issues:</p> <ul> <li>Order saved but event not published \u2192 Lost event</li> <li>Event published but transaction rolled back \u2192 Ghost event</li> <li>No atomicity between DB and Kafka</li> </ul>"},{"location":"features/transactional-outbox/#the-solution","title":"The Solution","text":"<p>Transactional outbox saves events to the database in the same transaction:</p> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,                    // \u2713 Enable outbox\n    aggregateType = \"Order\",          // Entity type\n    aggregateId = \"#result.id\"        // Entity ID\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre>"},{"location":"features/transactional-outbox/#how-it-works","title":"How It Works","text":"<pre><code>sequenceDiagram\n    participant App\n    participant DB\n    participant Outbox\n    participant Kafka\n\n    App-&gt;&gt;DB: 1. Save Order\n    App-&gt;&gt;Outbox: 2. Save Event (same TX)\n    DB--&gt;&gt;App: TX Committed \u2713\n\n    Note over Outbox: Background Poller\n\n    Outbox-&gt;&gt;Kafka: 3. Publish Event\n    Kafka--&gt;&gt;Outbox: Success\n    Outbox-&gt;&gt;Outbox: 4. Mark as Sent\n</code></pre> <p>Steps:</p> <ol> <li>Save entity and event in same transaction - Atomicity guaranteed</li> <li>Background poller - Periodically checks for unsent events</li> <li>Publish to Kafka - Events sent asynchronously</li> <li>Mark as sent - Successful events marked complete</li> </ol>"},{"location":"features/transactional-outbox/#configuration","title":"Configuration","text":""},{"location":"features/transactional-outbox/#enable-outbox","title":"Enable Outbox","text":"application.yml<pre><code>spring:\n  datasource:\n    url: jdbc:postgresql://localhost:5432/mydb\n    username: user\n    password: pass\n\n  jpa:\n    hibernate:\n      ddl-auto: update  # Or use Flyway/Liquibase\n\ncurve:\n  outbox:\n    enabled: true\n    poll-interval-ms: 1000      # Poll every 1 second\n    batch-size: 100             # Process 100 events per batch\n    max-retries: 3              # Retry failed events 3 times\n    cleanup-enabled: true       # Auto-cleanup old events\n    retention-days: 7           # Keep events for 7 days\n    cleanup-cron: \"0 0 2 * * *\" # Cleanup at 2 AM daily\n</code></pre>"},{"location":"features/transactional-outbox/#database-schema","title":"Database Schema","text":"<p>Curve auto-creates the outbox table:</p> <pre><code>CREATE TABLE curve_outbox_events (\n    id BIGINT PRIMARY KEY,\n    event_id VARCHAR(255) NOT NULL,\n    event_type VARCHAR(255) NOT NULL,\n    aggregate_type VARCHAR(255) NOT NULL,\n    aggregate_id VARCHAR(255) NOT NULL,\n    payload TEXT NOT NULL,\n    metadata TEXT,\n    status VARCHAR(50) NOT NULL,  -- PENDING, SENT, FAILED\n    retry_count INT DEFAULT 0,\n    last_retry_at TIMESTAMP,\n    created_at TIMESTAMP NOT NULL,\n    sent_at TIMESTAMP,\n    error_message TEXT\n);\n\nCREATE INDEX idx_status ON curve_outbox_events(status);\nCREATE INDEX idx_created_at ON curve_outbox_events(created_at);\n</code></pre>"},{"location":"features/transactional-outbox/#usage-examples","title":"Usage Examples","text":""},{"location":"features/transactional-outbox/#basic-outbox","title":"Basic Outbox","text":"<pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order createOrder(OrderRequest request) {\n    return orderRepository.save(new Order(request));\n}\n</code></pre>"},{"location":"features/transactional-outbox/#with-custom-payload","title":"With Custom Payload","text":"<pre><code>@Transactional\n@PublishEvent(\n    eventType = \"USER_REGISTERED\",\n    outbox = true,\n    aggregateType = \"User\",\n    aggregateId = \"#result.userId\",\n    payload = \"new UserRegisteredPayload(#result)\"\n)\npublic User registerUser(UserRequest request) {\n    User user = userRepository.save(new User(request));\n\n    // Other operations in same transaction\n    auditRepository.save(new AuditLog(\"User registered\"));\n\n    return user;\n}\n</code></pre>"},{"location":"features/transactional-outbox/#complex-transaction","title":"Complex Transaction","text":"<pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_COMPLETED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.id\"\n)\npublic Order completeOrder(Long orderId) {\n    // 1. Update order\n    Order order = orderRepository.findById(orderId)\n        .orElseThrow();\n    order.setStatus(OrderStatus.COMPLETED);\n    order.setCompletedAt(Instant.now());\n\n    // 2. Update inventory\n    inventoryService.decrementStock(order.getItems());\n\n    // 3. Create invoice\n    Invoice invoice = invoiceService.create(order);\n\n    // All operations atomic - event published after TX commits\n    return orderRepository.save(order);\n}\n</code></pre>"},{"location":"features/transactional-outbox/#advanced-features","title":"Advanced Features","text":""},{"location":"features/transactional-outbox/#exponential-backoff","title":"Exponential Backoff","text":"<p>Failed events are retried with exponential backoff:</p> <pre><code>Retry 1: Immediate\nRetry 2: 2 seconds later\nRetry 3: 4 seconds later  (2s \u00d7 2)\nRetry 4: 8 seconds later  (4s \u00d7 2)\n</code></pre>"},{"location":"features/transactional-outbox/#skip-locked-for-multi-instance","title":"SKIP LOCKED for Multi-Instance","text":"<p>Prevents duplicate processing in multi-instance deployments:</p> <pre><code>SELECT * FROM curve_outbox_events\nWHERE status = 'PENDING'\nORDER BY created_at\nLIMIT 100\nFOR UPDATE SKIP LOCKED;  -- Prevents duplicates\n</code></pre>"},{"location":"features/transactional-outbox/#automatic-cleanup","title":"Automatic Cleanup","text":"<p>Old events are automatically cleaned up:</p> <pre><code>curve:\n  outbox:\n    cleanup-enabled: true\n    retention-days: 7           # Delete events older than 7 days\n    cleanup-cron: \"0 0 2 * * *\" # Daily at 2 AM\n</code></pre>"},{"location":"features/transactional-outbox/#monitoring","title":"Monitoring","text":""},{"location":"features/transactional-outbox/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8080/actuator/health/curve-outbox\n</code></pre> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"pendingEvents\": 5,\n    \"failedEvents\": 2,\n    \"totalEvents\": 1523\n  }\n}\n</code></pre>"},{"location":"features/transactional-outbox/#metrics","title":"Metrics","text":"<pre><code>curl http://localhost:8080/actuator/curve-metrics\n</code></pre> <pre><code>{\n  \"outbox\": {\n    \"pendingEvents\": 5,\n    \"sentEvents\": 1518,\n    \"failedEvents\": 2,\n    \"avgProcessingTimeMs\": 45\n  }\n}\n</code></pre>"},{"location":"features/transactional-outbox/#query-outbox-table","title":"Query Outbox Table","text":"<pre><code>-- Pending events\nSELECT * FROM curve_outbox_events\nWHERE status = 'PENDING'\nORDER BY created_at DESC;\n\n-- Failed events\nSELECT event_type, error_message, retry_count\nFROM curve_outbox_events\nWHERE status = 'FAILED'\nORDER BY created_at DESC;\n\n-- Event throughput\nSELECT DATE(created_at) as date, COUNT(*)\nFROM curve_outbox_events\nWHERE status = 'SENT'\nGROUP BY DATE(created_at)\nORDER BY date DESC;\n</code></pre>"},{"location":"features/transactional-outbox/#best-practices","title":"Best Practices","text":""},{"location":"features/transactional-outbox/#do","title":"DO","text":"<ul> <li>Use outbox for critical events - Order creation, payments, etc.</li> <li>Monitor pending events - Alert if queue grows</li> <li>Set appropriate retention - Balance storage and auditability</li> <li>Use database indexes - Optimize poller queries</li> <li>Test failure scenarios - Ensure recovery works</li> </ul>"},{"location":"features/transactional-outbox/#dont","title":"DON'T","text":"<ul> <li>Use outbox for high-volume events (&gt;10,000/sec)</li> <li>Set poll interval too low (&lt;500ms)</li> <li>Disable cleanup in production</li> <li>Ignore failed events</li> </ul>"},{"location":"features/transactional-outbox/#performance-considerations","title":"Performance Considerations","text":"Factor Impact Recommendation Poll Interval Lower = faster, higher DB load 1000ms for most cases Batch Size Larger = more throughput 100-500 events Retention Longer = more storage 7-30 days Indexes Essential for performance On status, created_at"},{"location":"features/transactional-outbox/#throughput-estimates","title":"Throughput Estimates","text":"Configuration Throughput Poll: 1s, Batch: 100 ~100 events/sec Poll: 500ms, Batch: 200 ~400 events/sec Poll: 1s, Batch: 500 ~500 events/sec <p>High Throughput</p> <p>For &gt;1,000 events/sec, use async mode without outbox:</p> <pre><code>curve:\n  kafka:\n    async-mode: true\n</code></pre>"},{"location":"features/transactional-outbox/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/transactional-outbox/#events-stuck-in-pending","title":"Events Stuck in PENDING","text":"<p>Events not being published</p> <p>Check:</p> <ol> <li>Outbox poller is running: <code>logging.level.io.github.closeup1202.curve.outbox=DEBUG</code></li> <li>Kafka is accessible</li> <li>No DB connection pool exhaustion</li> </ol>"},{"location":"features/transactional-outbox/#high-failed-event-count","title":"High Failed Event Count","text":"<p>Many events in FAILED status</p> <p>Solutions:</p> <ol> <li>Check Kafka connectivity</li> <li>Increase <code>max-retries</code></li> <li>Analyze <code>error_message</code> column</li> <li>Manual republish:</li> </ol> <pre><code>UPDATE curve_outbox_events\nSET status = 'PENDING', retry_count = 0\nWHERE status = 'FAILED'\n  AND created_at &gt; NOW() - INTERVAL '1 hour';\n</code></pre>"},{"location":"features/transactional-outbox/#comparison-outbox-vs-async","title":"Comparison: Outbox vs Async","text":"Feature Outbox Async Atomicity \u2705 Guaranteed \u274c Best-effort Throughput ~1,000 TPS ~10,000+ TPS Latency ~1-2 seconds &lt;100ms Storage DB required No extra storage Complexity Medium Low <p>Use outbox when:</p> <ul> <li>Atomicity is critical (payments, orders)</li> <li>Events must not be lost</li> <li>Moderate throughput (&lt;1,000 TPS)</li> </ul> <p>Use async when:</p> <ul> <li>High throughput needed</li> <li>Best-effort delivery acceptable</li> <li>Low latency required</li> </ul>"},{"location":"features/transactional-outbox/#whats-next","title":"What's Next?","text":"<ul> <li> <p> Observability</p> <p>Monitor your events</p> <p> Observability</p> </li> <li> <p> Configuration</p> <p>Advanced configuration options</p> <p> Configuration</p> </li> </ul>"},{"location":"getting-started/first-event/","title":"Your First Event","text":"<p>This tutorial walks you through creating a complete event publishing setup with Curve.</p>"},{"location":"getting-started/first-event/#scenario","title":"Scenario","text":"<p>We'll build a user registration system that publishes a <code>USER_REGISTERED</code> event to Kafka.</p>"},{"location":"getting-started/first-event/#step-1-define-your-domain-model","title":"Step 1: Define Your Domain Model","text":"User.java<pre><code>public class User {\n    private Long id;\n    private String username;\n    private String email;\n    private String firstName;\n    private String lastName;\n    private Instant createdAt;\n\n    // getters, setters, constructors\n}\n</code></pre> UserRequest.java<pre><code>public record UserRequest(\n    String username,\n    String email,\n    String firstName,\n    String lastName\n) {}\n</code></pre>"},{"location":"getting-started/first-event/#step-2-create-event-payload","title":"Step 2: Create Event Payload","text":"<p>Create a payload class that implements <code>DomainEventPayload</code>:</p> UserRegisteredPayload.java<pre><code>import io.github.closeup1202.curve.core.envelope.DomainEventPayload;\nimport io.github.closeup1202.curve.spring.pii.annotation.PiiField;\nimport io.github.closeup1202.curve.spring.pii.type.PiiType;\nimport io.github.closeup1202.curve.spring.pii.strategy.PiiStrategy;\n\npublic class UserRegisteredPayload implements DomainEventPayload {\n\n    private Long userId;\n    private String username;\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String firstName;\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String lastName;\n\n    private Instant registeredAt;\n\n    // Constructor\n    public UserRegisteredPayload(User user) {\n        this.userId = user.getId();\n        this.username = user.getUsername();\n        this.email = user.getEmail();\n        this.firstName = user.getFirstName();\n        this.lastName = user.getLastName();\n        this.registeredAt = user.getCreatedAt();\n    }\n\n    // Getters\n    // ...\n}\n</code></pre> <p>PII Protection</p> <p>The <code>@PiiField</code> annotation automatically masks/hashes sensitive data before publishing.</p>"},{"location":"getting-started/first-event/#step-3-implement-service-with-publishevent","title":"Step 3: Implement Service with @PublishEvent","text":"UserService.java<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\nimport io.github.closeup1202.curve.core.type.EventSeverity;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\n@Service\npublic class UserService {\n\n    private final UserRepository userRepository;\n\n    public UserService(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n\n    @Transactional\n    @PublishEvent(\n        eventType = \"USER_REGISTERED\",\n        severity = EventSeverity.INFO,\n        payload = \"new io.example.UserRegisteredPayload(#result)\"\n    )\n    public User registerUser(UserRequest request) {\n        // Business logic\n        User user = new User();\n        user.setUsername(request.username());\n        user.setEmail(request.email());\n        user.setFirstName(request.firstName());\n        user.setLastName(request.lastName());\n        user.setCreatedAt(Instant.now());\n\n        return userRepository.save(user);\n    }\n}\n</code></pre>"},{"location":"getting-started/first-event/#annotation-breakdown","title":"Annotation Breakdown","text":"Parameter Value Description <code>eventType</code> <code>\"USER_REGISTERED\"</code> Unique identifier for this event type <code>severity</code> <code>EventSeverity.INFO</code> Event severity level <code>payload</code> SpEL expression Extracts data from method result <p>SpEL Expressions</p> <ul> <li><code>#result</code> - Method return value</li> <li><code>#args[0]</code> - First method argument</li> <li><code>#args[0].toEventDto()</code> - Custom transformation</li> </ul>"},{"location":"getting-started/first-event/#step-4-configure-application","title":"Step 4: Configure Application","text":"application.yml<pre><code>spring:\n  application:\n    name: user-service\n    version: 1.0.0\n\n  kafka:\n    bootstrap-servers: localhost:9094\n\n  jpa:\n    hibernate:\n      ddl-auto: update\n\ncurve:\n  enabled: true\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    async-mode: false  # Synchronous for reliability\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY:your-32-char-secret-key-here}\n</code></pre>"},{"location":"getting-started/first-event/#step-5-test-your-event","title":"Step 5: Test Your Event","text":""},{"location":"getting-started/first-event/#unit-test-with-mockeventproducer","title":"Unit Test with MockEventProducer","text":"UserServiceTest.java<pre><code>import io.github.closeup1202.curve.spring.test.MockEventProducer;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context;\n\n@SpringBootTest\nclass UserServiceTest {\n\n    @Autowired\n    private UserService userService;\n\n    @Autowired\n    private MockEventProducer mockEventProducer;\n\n    @Test\n    void shouldPublishEventWhenUserRegisters() {\n        // Given\n        UserRequest request = new UserRequest(\n            \"john_doe\",\n            \"john@example.com\",\n            \"John\",\n            \"Doe\"\n        );\n\n        // When\n        User user = userService.registerUser(request);\n\n        // Then\n        assertThat(user.getId()).isNotNull();\n\n        // Verify event was published\n        var events = mockEventProducer.getPublishedEvents();\n        assertThat(events).hasSize(1);\n\n        var event = events.get(0);\n        assertThat(event.getEventType()).isEqualTo(\"USER_REGISTERED\");\n        assertThat(event.getSeverity()).isEqualTo(EventSeverity.INFO);\n    }\n}\n</code></pre>"},{"location":"getting-started/first-event/#integration-test-with-kafka","title":"Integration Test with Kafka","text":"UserServiceIntegrationTest.java<pre><code>import org.springframework.kafka.test.context.EmbeddedKafka;\nimport org.springframework.test.context.TestPropertySource;\n\n@SpringBootTest\n@EmbeddedKafka(partitions = 1, topics = {\"event.audit.v1\"})\n@TestPropertySource(properties = {\n    \"spring.kafka.bootstrap-servers=${spring.embedded.kafka.brokers}\",\n    \"curve.enabled=true\"\n})\nclass UserServiceIntegrationTest {\n\n    @Autowired\n    private UserService userService;\n\n    @Autowired\n    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;\n\n    @Test\n    void shouldPublishToKafkaWhenUserRegisters() throws Exception {\n        // Setup consumer\n        CountDownLatch latch = new CountDownLatch(1);\n        AtomicReference&lt;String&gt; receivedEvent = new AtomicReference&lt;&gt;();\n\n        // Consume from Kafka\n        // ... (consumer setup)\n\n        // When\n        userService.registerUser(new UserRequest(\n            \"test_user\", \"test@example.com\", \"Test\", \"User\"\n        ));\n\n        // Then\n        assertThat(latch.await(5, TimeUnit.SECONDS)).isTrue();\n        assertThat(receivedEvent.get()).contains(\"USER_REGISTERED\");\n    }\n}\n</code></pre>"},{"location":"getting-started/first-event/#step-6-verify-in-kafka","title":"Step 6: Verify in Kafka","text":"<p>Start your application and register a user:</p> <pre><code>curl -X POST http://localhost:8080/api/users \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"john_doe\",\n    \"email\": \"john@example.com\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Doe\"\n  }'\n</code></pre> <p>Check the Kafka topic:</p> <pre><code>kafka-console-consumer --bootstrap-server localhost:9094 \\\n    --topic event.audit.v1 --from-beginning\n</code></pre> <p>Published event:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"USER_REGISTERED\",\n  \"occurredAt\": \"2025-02-03T10:30:00Z\",\n  \"publishedAt\": \"2025-02-03T10:30:00.123Z\",\n  \"severity\": \"INFO\",\n  \"metadata\": {\n    \"source\": {\n      \"serviceName\": \"user-service\",\n      \"serviceVersion\": \"1.0.0\"\n    },\n    \"trace\": {\n      \"traceId\": \"abc123\"\n    }\n  },\n  \"payload\": {\n    \"userId\": 1,\n    \"username\": \"john_doe\",\n    \"email\": \"j***@ex***.com\",  // \u2190 Masked!\n    \"firstName\": \"5a4b3c...\",    // \u2190 Hashed!\n    \"lastName\": \"7f8e9d...\",     // \u2190 Hashed!\n    \"registeredAt\": \"2025-02-03T10:30:00Z\"\n  }\n}\n</code></pre> <p>Notice</p> <p>PII fields are automatically protected based on <code>@PiiField</code> annotations!</p>"},{"location":"getting-started/first-event/#next-steps","title":"Next Steps","text":"<ul> <li> <p> PII Protection</p> <p>Learn more about data masking strategies</p> <p> PII Guide</p> </li> <li> <p> Transactional Outbox</p> <p>Guarantee atomicity between DB and events</p> <p> Outbox Pattern</p> </li> <li> <p> Failure Recovery</p> <p>Handle failures with DLQ and backups</p> <p> Failure Recovery</p> </li> <li> <p> Monitoring</p> <p>Set up metrics and health checks</p> <p> Observability</p> </li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"Component Version Java 17 or higher Spring Boot 3.0+ Apache Kafka 2.8+ (3.0+ recommended) Build Tool Gradle 7+ or Maven 3.6+"},{"location":"getting-started/installation/#dependency-installation","title":"Dependency Installation","text":""},{"location":"getting-started/installation/#gradle","title":"Gradle","text":"<p>Add to your <code>build.gradle</code>:</p> build.gradle<pre><code>repositories {\n    mavenCentral()\n}\n\ndependencies {\n    implementation 'io.github.closeup1202:curve:0.0.2'\n}\n</code></pre>"},{"location":"getting-started/installation/#maven","title":"Maven","text":"<p>Add to your <code>pom.xml</code>:</p> pom.xml<pre><code>&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n        &lt;artifactId&gt;curve&lt;/artifactId&gt;\n        &lt;version&gt;0.0.2&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"getting-started/installation/#avro-serialization","title":"Avro Serialization","text":"<p>If you want to use Avro serialization (<code>serde.type: AVRO</code>), add:</p> GradleMaven build.gradle<pre><code>repositories {\n    mavenCentral()\n    maven { url 'https://packages.confluent.io/maven/' }\n}\n\ndependencies {\n    implementation 'org.apache.avro:avro:1.11.4'\n    implementation 'io.confluent:kafka-avro-serializer:7.5.0'\n}\n</code></pre> pom.xml<pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;confluent&lt;/id&gt;\n        &lt;url&gt;https://packages.confluent.io/maven/&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;\n        &lt;artifactId&gt;avro&lt;/artifactId&gt;\n        &lt;version&gt;1.11.4&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.confluent&lt;/groupId&gt;\n        &lt;artifactId&gt;kafka-avro-serializer&lt;/artifactId&gt;\n        &lt;version&gt;7.5.0&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n</code></pre> <p>JSON by Default</p> <p>Curve uses JSON serialization by default, which requires no additional dependencies.</p>"},{"location":"getting-started/installation/#database-for-transactional-outbox","title":"Database for Transactional Outbox","text":"<p>If using the transactional outbox pattern, ensure you have a JPA-compatible database:</p> <pre><code>// Example: PostgreSQL\nimplementation 'org.springframework.boot:spring-boot-starter-data-jpa'\nruntimeOnly 'org.postgresql:postgresql'\n</code></pre>"},{"location":"getting-started/installation/#version-compatibility","title":"Version Compatibility","text":"Curve Version Spring Boot Kafka Client Java 0.0.2 3.5.x 3.8.x 17+ 0.0.1 3.4.x 3.7.x 17+"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After adding the dependency, verify Curve is correctly installed:</p>"},{"location":"getting-started/installation/#1-build-your-project","title":"1. Build Your Project","text":"GradleMaven <pre><code>./gradlew clean build\n</code></pre> <pre><code>./mvnw clean install\n</code></pre>"},{"location":"getting-started/installation/#2-check-auto-configuration","title":"2. Check Auto-Configuration","text":"<p>Enable debug logging to see if Curve auto-configuration is loaded:</p> application.yml<pre><code>logging:\n  level:\n    io.github.closeup1202.curve: DEBUG\n</code></pre> <p>Start your application and look for:</p> <pre><code>CurveAutoConfiguration matched:\n   - @ConditionalOnProperty (curve.enabled=true) matched\n</code></pre>"},{"location":"getting-started/installation/#3-test-health-endpoint","title":"3. Test Health Endpoint","text":"<pre><code>curl http://localhost:8080/actuator/health/curve\n</code></pre> <p>Expected response:</p> <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true\n  }\n}\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#dependency-resolution-fails","title":"Dependency Resolution Fails","text":"<p>Error: Could not find io.github.closeup1202:curve:0.0.2</p> <p>Solution: Ensure Maven Central is in your repositories:</p> GradleMaven <pre><code>repositories {\n    mavenCentral()\n}\n</code></pre> <p>Maven includes Central by default. Try:</p> <pre><code>./mvnw dependency:purge-local-repository\n</code></pre>"},{"location":"getting-started/installation/#auto-configuration-not-loading","title":"Auto-Configuration Not Loading","text":"<p>Curve features not working</p> <p>Check:</p> <ol> <li>Spring Boot version is 3.0+</li> <li><code>curve.enabled=true</code> in application.yml</li> <li>No conflicting auto-configurations</li> </ol>"},{"location":"getting-started/installation/#kafka-client-version-conflict","title":"Kafka Client Version Conflict","text":"<p>ClassNotFoundException or MethodNotFoundException</p> <p>Solution: Align Kafka client versions:</p> <pre><code>dependencies {\n    implementation('io.github.closeup1202:curve:0.0.2') {\n        exclude group: 'org.apache.kafka'\n    }\n    implementation 'org.apache.kafka:kafka-clients:3.8.0'\n}\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, proceed to:</p> <ol> <li>Quick Start Guide - Create your first event</li> <li>Configuration - Set up production settings</li> <li>First Event Tutorial - Detailed walkthrough</li> </ol> <p>Need Help?</p> <p>If you encounter issues, check the Troubleshooting Guide or open an issue.</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get Curve up and running in your Spring Boot application in under 5 minutes.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Java 17 or higher</li> <li>Spring Boot 3.x</li> <li>Apache Kafka (or Docker)</li> </ul>"},{"location":"getting-started/quick-start/#step-1-add-dependency","title":"Step 1: Add Dependency","text":"<p>Add Curve to your project:</p> GradleMaven build.gradle<pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.0.2'\n}\n</code></pre> pom.xml<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.0.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"getting-started/quick-start/#step-2-configure-kafka","title":"Step 2: Configure Kafka","text":"<p>Add Kafka configuration to your <code>application.yml</code>:</p> application.yml<pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9094\n\ncurve:\n  enabled: true\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n</code></pre> <p>Local Kafka Setup</p> <p>Don't have Kafka running? Use Docker Compose:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"getting-started/quick-start/#step-3-publish-your-first-event","title":"Step 3: Publish Your First Event","text":"<p>Add the <code>@PublishEvent</code> annotation to any service method:</p> OrderService.java<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\nimport io.github.closeup1202.curve.core.type.EventSeverity;\nimport org.springframework.stereotype.Service;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(\n        eventType = \"ORDER_CREATED\",\n        severity = EventSeverity.INFO\n    )\n    public Order createOrder(OrderRequest request) {\n        // Your business logic\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre>"},{"location":"getting-started/quick-start/#step-4-verify","title":"Step 4: Verify","text":"<p>Start your application and create an order. Check the Kafka topic:</p> <pre><code># View events in Kafka\nkafka-console-consumer --bootstrap-server localhost:9094 \\\n    --topic event.audit.v1 --from-beginning\n</code></pre> <p>Expected output:</p> <pre><code>{\n  \"eventId\": \"7355889748156289024\",\n  \"eventType\": \"ORDER_CREATED\",\n  \"occurredAt\": \"2025-02-03T10:30:00Z\",\n  \"publishedAt\": \"2025-02-03T10:30:00.123Z\",\n  \"severity\": \"INFO\",\n  \"metadata\": {\n    \"source\": {\n      \"serviceName\": \"order-service\",\n      \"serviceVersion\": \"1.0.0\",\n      \"hostname\": \"localhost\"\n    },\n    \"actor\": {\n      \"userId\": \"user123\",\n      \"sessionId\": \"session-abc\"\n    },\n    \"trace\": {\n      \"traceId\": \"trace-xyz\",\n      \"spanId\": \"span-123\"\n    }\n  },\n  \"payload\": {\n    \"orderId\": 12345,\n    \"customerId\": \"CUST-001\",\n    \"amount\": 99.99\n  }\n}\n</code></pre>"},{"location":"getting-started/quick-start/#step-5-monitor-optional","title":"Step 5: Monitor (Optional)","text":"<p>Check health and metrics:</p> <pre><code># Health check\ncurl http://localhost:8080/actuator/health/curve\n\n# Metrics\ncurl http://localhost:8080/actuator/curve-metrics\n</code></pre>"},{"location":"getting-started/quick-start/#success","title":"Success!","text":"<p>You've successfully published your first event with Curve!</p>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Learn Features</p> <p>Explore PII protection, DLQ, and observability</p> <p> Features</p> </li> <li> <p> Advanced Configuration</p> <p>Production-ready settings and optimization</p> <p> Configuration</p> </li> <li> <p> API Reference</p> <p>Detailed annotation and property reference</p> <p> API Docs</p> </li> <li> <p> Need Help?</p> <p>Troubleshooting and FAQ</p> <p> Troubleshooting</p> </li> </ul>"},{"location":"getting-started/quick-start/#common-issues","title":"Common Issues","text":"<p>Kafka Connection Failed</p> <p>If you see <code>Connection to node -1 could not be established</code>, ensure Kafka is running:</p> <pre><code>docker-compose ps\n</code></pre> <p>Events Not Publishing</p> <ol> <li>Check <code>curve.enabled=true</code> in application.yml</li> <li>Verify Kafka bootstrap servers</li> <li>Check logs for errors</li> </ol> <p>See Troubleshooting Guide for more solutions.</p>"},{"location":"ko/","title":"Home","text":"# Curve  **Spring Boot \ub9c8\uc774\ud06c\ub85c\uc11c\ube44\uc2a4\ub97c \uc704\ud55c \uc120\uc5b8\uc801 \uc774\ubca4\ud2b8 \ubc1c\ud589 \ub77c\uc774\ube0c\ub7ec\ub9ac**  [![Java](https://img.shields.io/badge/Java-17-orange.svg)](https://openjdk.java.net/) [![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.5.9-brightgreen.svg)](https://spring.io/projects/spring-boot) [![Kafka](https://img.shields.io/badge/Apache%20Kafka-3.0+-red.svg)](https://kafka.apache.org/) [![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE) [![CI](https://github.com/closeup1202/curve/actions/workflows/ci.yml/badge.svg)](https://github.com/closeup1202/curve/actions) [![codecov](https://codecov.io/gh/closeup1202/curve/branch/main/graph/badge.svg)](https://codecov.io/gh/closeup1202/curve) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=curve&amp;metric=alert_status)](https://sonarcloud.io/dashboard?id=curve)  [English](index.md) | [\ud55c\uad6d\uc5b4](index.ko.md)"},{"location":"ko/#_1","title":"\ud83c\udfac \ube60\ub978 \ub370\ubaa8","text":"<pre><code>// \uc5b4\ub178\ud14c\uc774\uc158 \ud558\ub098\ub9cc \ucd94\uac00\ud558\uba74 \ub05d!\n@PublishEvent(eventType = \"USER_CREATED\")\npublic User createUser(CreateUserRequest request) {\n    return userRepository.save(new User(request));\n}\n</code></pre> <p>\u2192 Kafka \uc790\ub3d9 \ubc1c\ud589 + PII \ub9c8\uc2a4\ud0b9 + \uc2e4\ud328 \uc2dc DLQ + \uba54\ud2b8\ub9ad \uc218\uc9d1 \u2728</p>"},{"location":"ko/#curve","title":"\ud83d\udd25 \uc65c Curve\uc778\uac00?","text":"### Before (\uae30\uc874 \ubc29\uc2dd) <pre><code>// 50\uc904 \uc774\uc0c1\uc758 \ubcf4\uc77c\ub7ec\ud50c\ub808\uc774\ud2b8 \ucf54\ub4dc\n@Service\npublic class UserService {\n\n    @Autowired\n    private KafkaTemplate&lt;String, Object&gt; kafka;\n\n    @Autowired\n    private ObjectMapper objectMapper;\n\n    public User createUser(UserRequest request) {\n        User user = userRepository.save(\n            new User(request)\n        );\n\n        try {\n            // \uc218\ub3d9\uc73c\ub85c \uc774\ubca4\ud2b8 \uc0dd\uc131\n            EventEnvelope event = EventEnvelope.builder()\n                .eventId(UUID.randomUUID().toString())\n                .eventType(\"USER_CREATED\")\n                .occurredAt(Instant.now())\n                .publishedAt(Instant.now())\n                .metadata(/* ... */)\n                .payload(/* ... */)\n                .build();\n\n            // \uc218\ub3d9\uc73c\ub85c PII \ub9c8\uc2a4\ud0b9\n            String json = maskPii(\n                objectMapper.writeValueAsString(event)\n            );\n\n            // \uc218\ub3d9\uc73c\ub85c Kafka \uc804\uc1a1 \ubc0f \uc7ac\uc2dc\ub3c4\n            kafka.send(\"user-events\", json)\n                .get(30, TimeUnit.SECONDS);\n\n        } catch (Exception e) {\n            // \uc218\ub3d9\uc73c\ub85c \uc5d0\ub7ec \ucc98\ub9ac\n            log.error(\"Failed to publish event\", e);\n            sendToDlq(event);\n        }\n\n        return user;\n    }\n}\n</code></pre>   ### After (Curve) <pre><code>// \uc5b4\ub178\ud14c\uc774\uc158 \ud558\ub098\ub9cc!\n@Service\npublic class UserService {\n\n    @PublishEvent(eventType = \"USER_CREATED\")\n    public User createUser(UserRequest request) {\n        return userRepository.save(\n            new User(request)\n        );\n    }\n}\n</code></pre>  **\ucf54\ub4dc 90% \uac10\uc18c** \u2728  \ubaa8\ub4e0 \uac83\uc774 \uc790\ub3d9\uc73c\ub85c \ucc98\ub9ac\ub429\ub2c8\ub2e4: - \u2705 \uc774\ubca4\ud2b8 ID \uc0dd\uc131 - \u2705 \uba54\ud0c0\ub370\uc774\ud130 \ucd94\ucd9c - \u2705 PII \ub9c8\uc2a4\ud0b9 - \u2705 Kafka \ubc1c\ud589 - \u2705 \uc7ac\uc2dc\ub3c4 &amp; DLQ - \u2705 \uba54\ud2b8\ub9ad \uc218\uc9d1"},{"location":"ko/#_2","title":"\u2728 \uc8fc\uc694 \uae30\ub2a5","text":""},{"location":"ko/#_3","title":"\ud83c\udfaf \uc120\uc5b8\uc801 \uc774\ubca4\ud2b8 \ubc1c\ud589","text":"<p>Kafka \ubcf4\uc77c\ub7ec\ud50c\ub808\uc774\ud2b8 \ucf54\ub4dc \ubd88\ud544\uc694 - <code>@PublishEvent</code> \uc5b4\ub178\ud14c\uc774\uc158\ub9cc \ucd94\uac00. SpEL\uc744 \ud1b5\ud55c \uc720\uc5f0\ud55c \ud398\uc774\ub85c\ub4dc \ucd94\ucd9c \uc9c0\uc6d0.</p>"},{"location":"ko/#_4","title":"\ud83d\udce6 \ud45c\uc900\ud654\ub41c \uc774\ubca4\ud2b8 \uad6c\uc870","text":"<p>\ubaa8\ub4e0 \uc774\ubca4\ud2b8\uac00 \uba54\ud0c0\ub370\uc774\ud130(source, actor, trace, tags)\ub97c \ud3ec\ud568\ud55c \ud1b5\uc77c\ub41c \uc2a4\ud0a4\ub9c8 \uc0ac\uc6a9</p>"},{"location":"ko/#3","title":"\ud83d\udee1\ufe0f 3\ub2e8\uacc4 \uc7a5\uc560 \ubcf5\uad6c","text":"<p>Main Topic \u2192 DLQ \u2192 \ub85c\uceec \ud30c\uc77c \ubc31\uc5c5 Kafka\uac00 24\uc2dc\uac04 \uc7a5\uc560\uc5ec\ub3c4 \uc774\ubca4\ud2b8 \uc190\uc2e4 \uc81c\ub85c</p>"},{"location":"ko/#pii","title":"\ud83d\udd10 \uc790\ub3d9 PII \ubcf4\ud638","text":"<p><code>@PiiField</code> \uc5b4\ub178\ud14c\uc774\uc158\uc73c\ub85c \ubbfc\uac10 \ub370\uc774\ud130 \uc790\ub3d9 \ub9c8\uc2a4\ud0b9/\uc554\ud638\ud654</p>"},{"location":"ko/#_5","title":"\u26a1 \uace0\uc131\ub2a5","text":"<ul> <li>\ub3d9\uae30 \ubaa8\ub4dc: ~500 TPS</li> <li>\ube44\ub3d9\uae30 \ubaa8\ub4dc: ~10,000+ TPS (MDC \ucee8\ud14d\uc2a4\ud2b8 \uc804\ud30c \ud3ec\ud568)</li> <li>Transactional Outbox: \uc6d0\uc790\uc131 \ubc0f \uc77c\uad00\uc131 \ubcf4\uc7a5</li> </ul>"},{"location":"ko/#hexagonal-architecture","title":"\ud83c\udfd7\ufe0f Hexagonal Architecture","text":"<p>\ucd5c\ub300 \uc720\uc5f0\uc131\uc744 \uc704\ud55c \ud504\ub808\uc784\uc6cc\ud06c \ub3c5\ub9bd\uc801 \ucf54\uc5b4</p>"},{"location":"ko/#_6","title":"\ud83d\udcca \ub0b4\uc7a5 \uad00\ucc30\uc131","text":"<ul> <li>Spring Actuator Health Indicator</li> <li>\ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc5d4\ub4dc\ud3ec\uc778\ud2b8 (<code>/actuator/curve-metrics</code>)</li> <li>\uc0c1\uc138\ud55c \uc774\ubca4\ud2b8 \ucd94\uc801</li> <li>\ube44\ub3d9\uae30 \ucee8\ud14d\uc2a4\ud2b8 \uc804\ud30c: \ube44\ub3d9\uae30 \uc2a4\ub808\ub4dc\uc5d0\uc11c\ub3c4 MDC(Trace ID)\uac00 \uc720\uc9c0\ub429\ub2c8\ub2e4.</li> </ul>"},{"location":"ko/#_7","title":"\ud83e\uddea \ud14c\uc2a4\ud2b8 \uc6a9\uc774\uc131","text":"<ul> <li>Kafka \uc5c6\uc774 \ub2e8\uc704/\ud1b5\ud569 \ud14c\uc2a4\ud2b8\ub97c \ud560 \uc218 \uc788\ub294 <code>MockEventProducer</code> \uc81c\uacf5.</li> </ul>"},{"location":"ko/#_8","title":"\ud83d\ude80 \ube60\ub978 \uc2dc\uc791","text":""},{"location":"ko/#1","title":"1. \uc758\uc874\uc131 \ucd94\uac00","text":"<p>Gradle (build.gradle) <pre><code>dependencies {\n    implementation 'io.github.closeup1202:curve:0.0.2'\n}\n</code></pre></p> <p>Maven (pom.xml) <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.github.closeup1202&lt;/groupId&gt;\n    &lt;artifactId&gt;curve&lt;/artifactId&gt;\n    &lt;version&gt;0.0.2&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p>"},{"location":"ko/#2","title":"2. \uc124\uc815","text":"<p>application.yml <pre><code>spring:\n  kafka:\n    bootstrap-servers: localhost:9094\n\ncurve:\n  enabled: true\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n</code></pre></p>"},{"location":"ko/#3_1","title":"3. \uc0ac\uc6a9","text":"<pre><code>import io.github.closeup1202.curve.spring.audit.annotation.PublishEvent;\nimport io.github.closeup1202.curve.core.type.EventSeverity;\n\n@Service\npublic class OrderService {\n\n    @PublishEvent(\n        eventType = \"ORDER_CREATED\",\n        severity = EventSeverity.INFO\n    )\n    public Order createOrder(OrderRequest request) {\n        // \ube44\uc988\ub2c8\uc2a4 \ub85c\uc9c1\n        return orderRepository.save(new Order(request));\n    }\n}\n</code></pre>"},{"location":"ko/#4-kafka","title":"4. \ub85c\uceec Kafka \uc2e4\ud589","text":"<pre><code>docker-compose up -d\n</code></pre>"},{"location":"ko/#5","title":"5. \ud655\uc778","text":"<ul> <li>Kafka UI: http://localhost:8080</li> <li>Health Check: http://localhost:8081/actuator/health/curve</li> <li>\uba54\ud2b8\ub9ad: http://localhost:8081/actuator/curve-metrics</li> </ul> <p>\uc644\ub8cc! \ud83c\udf89</p>"},{"location":"ko/#_9","title":"\ud83d\udcca \ube44\uad50","text":"\uae30\ub2a5 Spring Events Spring Cloud Stream Curve Kafka \uc5f0\ub3d9 \u274c \u2705 \u2705 \uc120\uc5b8\uc801 \uc0ac\uc6a9 \u2705 \u25b3 \u2705 \ud45c\uc900\ud654\ub41c \uc2a4\ud0a4\ub9c8 \u274c \u274c \u2705 PII \ubcf4\ud638 \u274c \u274c \u2705 DLQ \uc9c0\uc6d0 \u274c \u2705 \u2705 \ub85c\uceec \ud30c\uc77c \ubc31\uc5c5 \u274c \u274c \u2705 Health Check \u274c \u274c \u2705 \ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \u274c \u274c \u2705 Snowflake ID \u274c \u274c \u2705 Transactional Outbox \u274c \u274c \u2705 \ubcf4\uc77c\ub7ec\ud50c\ub808\uc774\ud2b8 \uc911\uac04 \ub9ce\uc74c \ucd5c\uc18c"},{"location":"ko/#_10","title":"\ud83c\udfd7\ufe0f \uc544\ud0a4\ud14d\ucc98","text":""},{"location":"ko/#hexagonal-architecture-ports-adapters","title":"Hexagonal Architecture (Ports &amp; Adapters)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      \ub3c4\uba54\uc778 \uacc4\uce35 (Core)              \u2502\n\u2502  \u2022 EventEnvelope, EventMetadata     \u2502\n\u2502  \u2022 Validation, Exception            \u2502\n\u2502  \u2022 \ud504\ub808\uc784\uc6cc\ud06c \ub3c5\ub9bd\uc801                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                \u2502\n        \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Spring   \u2502      \u2502   Kafka    \u2502\n\u2502 (\uc5b4\ub311\ud130)   \u2502      \u2502  (\uc5b4\ub311\ud130)   \u2502\n\u2502  \u2022 AOP    \u2502      \u2502 \u2022 Producer \u2502\n\u2502  \u2022 Context\u2502      \u2502 \u2022 DLQ      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ko/#_11","title":"\ubaa8\ub4c8 \uad6c\uc870","text":"<pre><code>curve/\n\u251c\u2500\u2500 core/                          # \uc21c\uc218 \ub3c4\uba54\uc778 \ubaa8\ub378 (\ud504\ub808\uc784\uc6cc\ud06c \ub3c5\ub9bd)\n\u2502   \u251c\u2500\u2500 envelope/                  # EventEnvelope, EventMetadata\n\u2502   \u251c\u2500\u2500 port/                      # EventProducer, IdGenerator (\uc778\ud130\ud398\uc774\uc2a4)\n\u2502   \u251c\u2500\u2500 context/                   # ContextProvider (\uc778\ud130\ud398\uc774\uc2a4)\n\u2502   \u251c\u2500\u2500 validation/                # EventValidator\n\u2502   \u2514\u2500\u2500 exception/                 # \ub3c4\uba54\uc778 \uc608\uc678\n\u2502\n\u251c\u2500\u2500 spring/                        # Spring Framework \uc5b4\ub311\ud130\n\u2502   \u251c\u2500\u2500 aop/                       # @PublishEvent Aspect\n\u2502   \u251c\u2500\u2500 context/                   # Spring \uae30\ubc18 Context Provider \uad6c\ud604\n\u2502   \u251c\u2500\u2500 factory/                   # EventEnvelopeFactory\n\u2502   \u251c\u2500\u2500 infrastructure/            # SnowflakeIdGenerator, UtcClockProvider\n\u2502   \u251c\u2500\u2500 publisher/                 # AbstractEventPublisher\n\u2502   \u2514\u2500\u2500 test/                      # \ud14c\uc2a4\ud2b8 \uc720\ud2f8\ub9ac\ud2f0 (MockEventProducer)\n\u2502\n\u251c\u2500\u2500 kafka/                         # Kafka \uc5b4\ub311\ud130\n\u2502   \u251c\u2500\u2500 producer/                  # KafkaEventProducer\n\u2502   \u2514\u2500\u2500 dlq/                       # FailedEventRecord\n\u2502\n\u2514\u2500\u2500 spring-boot-autoconfigure/     # Spring Boot \uc790\ub3d9 \uc124\uc815\n    \u251c\u2500\u2500 CurveAutoConfiguration     # \uba54\uc778 \uc124\uc815\n    \u251c\u2500\u2500 CurveProperties            # \uc124\uc815 \uc18d\uc131\n    \u2514\u2500\u2500 health/                    # Health indicator &amp; \uba54\ud2b8\ub9ad\n</code></pre>"},{"location":"ko/#_12","title":"\ud575\uc2ec \uc124\uacc4 \uc6d0\uce59","text":"<ol> <li>\uc758\uc874\uc131 \uc5ed\uc804 \uc6d0\uce59 (DIP)</li> <li>Core \ubaa8\ub4c8\uc740 \ud504\ub808\uc784\uc6cc\ud06c \uc758\uc874\uc131 \uc81c\ub85c</li> <li> <p>Port \uc778\ud130\ud398\uc774\uc2a4\ub97c \ud1b5\ud574 \uc678\ubd80 \uc758\uc874\uc131 \uaca9\ub9ac</p> </li> <li> <p>\ub2e8\uc77c \ucc45\uc784 \uc6d0\uce59 (SRP)</p> </li> <li>\uac01 ContextProvider\ub294 \ud558\ub098\uc758 \ucc45\uc784\ub9cc \ucc98\ub9ac</li> <li> <p>EventValidator\ub294 \uac80\uc99d\ub9cc, EventProducer\ub294 \ubc1c\ud589\ub9cc</p> </li> <li> <p>\uac1c\ubc29-\ud3d0\uc1c4 \uc6d0\uce59 (OCP)</p> </li> <li>EventProducer \uc778\ud130\ud398\uc774\uc2a4\ub85c Kafka \uc678 \ub2e4\ub978 \ube0c\ub85c\ucee4 \uc0ac\uc6a9 \uac00\ub2a5</li> <li>ContextProvider \uad6c\ud604\uccb4 \uad50\uccb4 \uac00\ub2a5</li> </ol>"},{"location":"ko/#_13","title":"\ud83c\udfaf \uc0ac\uc6a9 \uc0ac\ub840","text":""},{"location":"ko/#1_1","title":"1. \uac10\uc0ac \ub85c\uae45","text":"<pre><code>@PublishEvent(eventType = \"USER_LOGIN\", severity = INFO)\npublic User login(String username, String password) {\n    return authService.authenticate(username, password);\n}\n</code></pre>"},{"location":"ko/#2_1","title":"2. \uc774\ubca4\ud2b8 \uae30\ubc18 \uc544\ud0a4\ud14d\ucc98","text":"<pre><code>@PublishEvent(eventType = \"ORDER_COMPLETED\")\npublic Order completeOrder(Long orderId) {\n    Order order = orderRepository.findById(orderId);\n    order.setStatus(OrderStatus.COMPLETED);\n    return orderRepository.save(order);\n}\n</code></pre>"},{"location":"ko/#3_2","title":"3. \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778","text":"<pre><code>@PublishEvent(eventType = \"CUSTOMER_REGISTERED\")\npublic Customer registerCustomer(CustomerRequest request) {\n    // \uc774\ubca4\ud2b8\uac00 \uc790\ub3d9\uc73c\ub85c \ub370\uc774\ud130 \ub808\uc774\ud06c/\uc6e8\uc5b4\ud558\uc6b0\uc2a4\ub85c \uc804\ub2ec\n    return customerRepository.save(new Customer(request));\n}\n</code></pre>"},{"location":"ko/#_14","title":"\ud83d\udee1\ufe0f \ubcf4\uc548 \uae30\ub2a5","text":""},{"location":"ko/#pii_1","title":"\uc790\ub3d9 PII \ubcf4\ud638","text":"<pre><code>public class UserEventPayload implements DomainEventPayload {\n\n    @PiiField(type = PiiType.EMAIL, strategy = PiiStrategy.MASK)\n    private String email;  // \"user@example.com\" \u2192 \"user@***.com\"\n\n    @PiiField(type = PiiType.PHONE, strategy = PiiStrategy.ENCRYPT)\n    private String phone;  // AES-256-GCM \uc554\ud638\ud654\n\n    @PiiField(type = PiiType.NAME, strategy = PiiStrategy.HASH)\n    private String name;   // SHA-256 \ud574\uc2f1\n}\n</code></pre> <p>\uc9c0\uc6d0\ub418\ub294 \uc804\ub7b5: - MASK: \ud328\ud134 \uae30\ubc18 \ub9c8\uc2a4\ud0b9 (\uc608: <code>j***@gm***.com</code>) - ENCRYPT: AES-256-GCM \uc554\ud638\ud654 (\ubcf5\uc6d0 \uac00\ub2a5) - HASH: SHA-256 \ud574\uc2f1 (\ubcf5\uc6d0 \ubd88\uac00)</p> <p>\uc124\uc815: <pre><code>curve:\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}  # \ud658\uacbd \ubcc0\uc218\n      salt: ${PII_HASH_SALT}\n</code></pre></p>"},{"location":"ko/#_15","title":"\ud83d\udcc8 \uad00\ucc30\uc131","text":""},{"location":"ko/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8081/actuator/health/curve\n</code></pre> <p>\uc751\ub2f5: <pre><code>{\n  \"status\": \"UP\",\n  \"details\": {\n    \"kafkaProducerInitialized\": true,\n    \"producerMetrics\": 42,\n    \"topic\": \"event.audit.v1\",\n    \"dlqTopic\": \"event.audit.dlq.v1\"\n  }\n}\n</code></pre></p>"},{"location":"ko/#_16","title":"\ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc5d4\ub4dc\ud3ec\uc778\ud2b8","text":"<pre><code>curl http://localhost:8081/actuator/curve-metrics\n</code></pre> <p>\uc751\ub2f5: <pre><code>{\n  \"summary\": {\n    \"totalEventsPublished\": 1523,\n    \"successfulEvents\": 1520,\n    \"failedEvents\": 3,\n    \"successRate\": \"99.80%\",\n    \"totalDlqEvents\": 3,\n    \"totalKafkaErrors\": 0\n  },\n  \"events\": {\n    \"published\": [...],\n    \"publishDuration\": [...]\n  },\n  \"dlq\": {...},\n  \"kafka\": {...}\n}\n</code></pre></p>"},{"location":"ko/#_17","title":"\u2699\ufe0f \uc124\uc815","text":""},{"location":"ko/#_18","title":"\uc804\uccb4 \uc124\uc815 \uc608\uc2dc","text":"<pre><code>curve:\n  enabled: true\n\n  id-generator:\n    worker-id: 1  # 0-1023, \uc778\uc2a4\ud134\uc2a4\ub9c8\ub2e4 \uace0\uc720\n    auto-generate: false\n\n  kafka:\n    topic: event.audit.v1\n    dlq-topic: event.audit.dlq.v1\n    retries: 3\n    retry-backoff-ms: 1000\n    request-timeout-ms: 30000\n    async-mode: false  # \ub192\uc740 \ucc98\ub9ac\ub7c9\uc744 \uc704\ud574 true\n    async-timeout-ms: 5000\n\n  retry:\n    enabled: true\n    max-attempts: 3\n    initial-interval: 1000\n    multiplier: 2.0\n    max-interval: 10000\n\n  security:\n    use-forwarded-headers: false  # \ud504\ub85d\uc2dc \ub4a4\uc5d0\uc11c\ub294 true\n\n  pii:\n    enabled: true\n    crypto:\n      default-key: ${PII_ENCRYPTION_KEY}\n      salt: ${PII_HASH_SALT}\n\n  outbox:\n    enabled: true\n    poll-interval-ms: 1000\n    batch-size: 100\n    max-retries: 3\n    cleanup-enabled: true\n    retention-days: 7\n    cleanup-cron: \"0 0 2 * * *\"\n\n  serde:\n    type: JSON # JSON, AVRO, PROTOBUF\n</code></pre>"},{"location":"ko/#avro","title":"Avro \uc9c1\ub82c\ud654 (\uc120\ud0dd)","text":"<p>Avro \uc9c1\ub82c\ud654(<code>serde.type: AVRO</code>)\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 \ub2e4\uc74c \uc758\uc874\uc131\uc744 \ucd94\uac00\ud558\uc138\uc694:</p> <p>build.gradle: <pre><code>repositories {\n    mavenCentral()\n    maven { url 'https://packages.confluent.io/maven/' }\n}\n\ndependencies {\n    implementation 'org.apache.avro:avro:1.11.4'\n    implementation 'io.confluent:kafka-avro-serializer:7.5.0'\n}\n</code></pre></p> <p>\ucc38\uace0: JSON \uc9c1\ub82c\ud654\ub294 \ucd94\uac00 \uc758\uc874\uc131 \uc5c6\uc774 \ubc14\ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud569\ub2c8\ub2e4.</p>"},{"location":"ko/#_19","title":"\ud658\uacbd\ubcc4 \ud504\ub85c\ud30c\uc77c","text":"<p>\uac1c\ubc1c: <pre><code>spring:\n  config:\n    activate:\n      on-profile: dev\n\ncurve:\n  kafka:\n    async-mode: true  # \ube60\ub978 \ubc18\ubcf5\n    topic: event.audit.dev.v1\n</code></pre></p> <p>\ud504\ub85c\ub355\uc158: <pre><code>spring:\n  config:\n    activate:\n      on-profile: prod\n\ncurve:\n  id-generator:\n    worker-id: ${POD_ORDINAL}  # Kubernetes StatefulSet\n  kafka:\n    async-mode: false  # \uc548\uc815\uc131 \uc6b0\uc120\n    retries: 5\n</code></pre></p> <p>\uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc124\uc815 \uac00\uc774\ub4dc\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"ko/#_20","title":"\ud83d\udd27 \uace0\uae09 \uae30\ub2a5","text":""},{"location":"ko/#1-snowflake-id-generator","title":"1. Snowflake ID Generator","text":"<p>\ucda9\ub3cc \uc5c6\ub294 \ubd84\uc0b0 \uace0\uc720 ID \uc0dd\uc131.</p> <p>\uad6c\uc870: <pre><code>| 42\ube44\ud2b8: \ud0c0\uc784\uc2a4\ud0ec\ud504 | 10\ube44\ud2b8: Worker ID | 12\ube44\ud2b8: Sequence |\n</code></pre></p> <p>\uc6a9\ub7c9: - \ucd5c\ub300 1,024 \uc6cc\ucee4 - \ubc00\ub9ac\ucd08\ub2f9 4,096\uac1c ID (\uc6cc\ucee4\ub2f9) - \uc2dc\uac04 \uc815\ub82c \uac00\ub2a5</p>"},{"location":"ko/#2-transactional-outbox-pattern","title":"2. Transactional Outbox Pattern","text":"<p>DB \ud2b8\ub79c\uc7ad\uc158\uacfc \uc774\ubca4\ud2b8 \ubc1c\ud589\uc758 \uc6d0\uc790\uc131\uc744 \ubcf4\uc7a5\ud569\ub2c8\ub2e4.</p> <ul> <li>\uc9c0\uc218 \ubc31\uc624\ud504(Exponential Backoff): \uc2e4\ud328\ud55c \uc774\ubca4\ud2b8\ub97c 1\ucd08, 2\ucd08, 4\ucd08... \uac04\uaca9\uc73c\ub85c \uc7ac\uc2dc\ub3c4\ud558\uc5ec DB \ubd80\ud558\ub97c \uc904\uc785\ub2c8\ub2e4.</li> <li>SKIP LOCKED: \ub2e4\uc911 \uc778\uc2a4\ud134\uc2a4 \ud658\uacbd\uc5d0\uc11c \uc911\ubcf5 \ucc98\ub9ac\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \ube44\uad00\uc801 \ub77d\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</li> </ul> <pre><code>@Transactional\n@PublishEvent(\n    eventType = \"ORDER_CREATED\",\n    outbox = true,\n    aggregateType = \"Order\",\n    aggregateId = \"#result.orderId\"\n)\npublic Order createOrder(OrderRequest req) {\n    return orderRepo.save(new Order(req));\n}\n</code></pre>"},{"location":"ko/#3-spel","title":"3. \uc720\uc5f0\ud55c \ud398\uc774\ub85c\ub4dc \ucd94\ucd9c (SpEL)","text":"<p>SpEL\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774\ubca4\ud2b8 \ud398\uc774\ub85c\ub4dc\ub85c \uc0ac\uc6a9\ud560 \ub370\uc774\ud130\ub97c \uc720\uc5f0\ud558\uac8c \ucd94\ucd9c\ud569\ub2c8\ub2e4.</p> <pre><code>@PublishEvent(\n    eventType = \"USER_UPDATED\",\n    payload = \"#args[0].toEventDto()\"\n)\npublic User updateUser(UserUpdateRequest request) {\n    // ...\n}\n</code></pre>"},{"location":"ko/#4-producer","title":"4. \ucee4\uc2a4\ud140 \uc774\ubca4\ud2b8 Producer","text":"<p>Kafka\uac00 \uc544\ub2cc \ub2e4\ub978 \ube0c\ub85c\ucee4\ub97c \uc704\ud574 <code>EventProducer</code> \uc778\ud130\ud398\uc774\uc2a4 \uad6c\ud604:</p> <pre><code>@Component\npublic class RabbitMqEventProducer extends AbstractEventPublisher {\n\n    private final RabbitTemplate rabbitTemplate;\n\n    @Override\n    protected &lt;T extends DomainEventPayload&gt; void send(EventEnvelope&lt;T&gt; envelope) {\n        String json = objectMapper.writeValueAsString(envelope);\n        rabbitTemplate.convertAndSend(exchange, routingKey, json);\n    }\n}\n</code></pre>"},{"location":"ko/#5-dlq","title":"5. DLQ \ubcf5\uad6c","text":"<pre><code># \ubc31\uc5c5 \ud30c\uc77c \ubaa9\ub85d\n./scripts/dlq-recovery.sh --list\n\n# \ubaa8\ub4e0 \ud30c\uc77c \ubcf5\uad6c\n./scripts/dlq-recovery.sh --topic event.audit.v1 --broker localhost:9094\n\n# \ud2b9\uc815 \ud30c\uc77c \ubcf5\uad6c\n./scripts/dlq-recovery.sh --file 1234567890.json --topic event.audit.v1\n</code></pre>"},{"location":"ko/#_21","title":"\ud83d\udcda \ubb38\uc11c","text":"\ubb38\uc11c \uc124\uba85 \uc124\uc815 \uac00\uc774\ub4dc \uc0c1\uc138 \uc124\uc815 \uc635\uc158 \uc6b4\uc601 \uac00\uc774\ub4dc \ud504\ub85c\ub355\uc158 \uc6b4\uc601 \ubc0f \ubaa8\ubc94 \uc0ac\ub840 \ubb38\uc81c \ud574\uacb0 \uc77c\ubc18\uc801\uc778 \ubb38\uc81c \ubc0f \ud574\uacb0 \ubc29\ubc95 \ubaa8\ub2c8\ud130\ub9c1 \uac00\uc774\ub4dc \uba54\ud2b8\ub9ad, \ub300\uc2dc\ubcf4\ub4dc, \uc54c\ub9bc \uc124\uc815 \ub9c8\uc774\uadf8\ub808\uc774\uc158 \uac00\uc774\ub4dc \ubc84\uc804 \uc5c5\uadf8\ub808\uc774\ub4dc \uc9c0\uce68 \ubcc0\uacbd \uc774\ub825 \ubc84\uc804 \ud788\uc2a4\ud1a0\ub9ac \ubc0f \ubcc0\uacbd \uc0ac\ud56d \uc608\uc2dc \uc124\uc815 \uc124\uc815 \uc608\uc2dc \uc0d8\ud50c \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \uc644\uc804\ud55c \uc791\ub3d9 \uc608\uc2dc"},{"location":"ko/#_22","title":"\ud83e\udd1d \uae30\uc5ec\ud558\uae30","text":"<p>\uae30\uc5ec\ub97c \ud658\uc601\ud569\ub2c8\ub2e4! Pull Request\ub97c \uc790\uc720\ub86d\uac8c \uc81c\ucd9c\ud574\uc8fc\uc138\uc694.</p> <p>\uac00\uc774\ub4dc\ub77c\uc778\uc740 CONTRIBUTING.md\ub97c \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"ko/#_23","title":"\ud83d\udcc4 \ub77c\uc774\uc120\uc2a4","text":"<p>\uc774 \ud504\ub85c\uc81d\ud2b8\ub294 MIT \ub77c\uc774\uc120\uc2a4\ub85c \ubc30\ud3ec\ub429\ub2c8\ub2e4 - \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 LICENSE \ud30c\uc77c\uc744 \ucc38\uace0\ud558\uc138\uc694.</p>"},{"location":"ko/#_24","title":"\ud83d\ude4f \uac10\uc0ac\uc758 \ub9d0","text":"<ul> <li>Spring Cloud Stream\uacfc Spring Kafka\uc5d0\uc11c \uc601\uac10\uc744 \ubc1b\uc558\uc2b5\ub2c8\ub2e4</li> <li>Spring Boot\uc640 Apache Kafka\ub85c \uad6c\ucd95\ub418\uc5c8\uc2b5\ub2c8\ub2e4</li> <li>Alistair Cockburn\uc758 Hexagonal Architecture \ud328\ud134 \uc801\uc6a9</li> </ul>"},{"location":"ko/#_25","title":"\ud83d\udcec \uc5f0\ub77d\ucc98","text":"<ul> <li>\uc774\uc288: GitHub Issues</li> <li>\uc774\uba54\uc77c: closeup1202@gmail.com</li> </ul>   [\u2b06 \ub9e8 \uc704\ub85c](#curve)"},{"location":"ko/CONFIGURATION/","title":"Curve \uc124\uc815 \uac00\uc774\ub4dc","text":"<p>\uc774 \ubb38\uc11c\ub294 Curve \uc774\ubca4\ud2b8 \ubc1c\ud589 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \uc0c1\uc138\ud55c \uc124\uc815 \ubc29\ubc95\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.</p> <p>CONFIGURATION.en.md \ud30c\uc77c\uc758 \ud55c\uae00 \ubc88\uc5ed \ubc84\uc804\uc785\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc601\ubb38 \ubc84\uc804(CONFIGURATION.en.md)\uc744 \ucc38\uc870\ud558\uc138\uc694.</p>"},{"location":"ko/CONFIGURATION/#curve-configuration-guide","title":"Curve Configuration Guide","text":"<p>This document describes the detailed configuration methods for the Curve event publishing library.</p>"},{"location":"ko/OPERATIONS/","title":"Curve \uc6b4\uc601 \uac00\uc774\ub4dc","text":"<p>\uc774 \ubb38\uc11c\ub294 Curve \uc774\ubca4\ud2b8 \ubc1c\ud589 \uc2dc\uc2a4\ud15c\uc758 \ubaa8\ub2c8\ud130\ub9c1, \ud2b8\ub7ec\ube14\uc288\ud305, \ubcf5\uad6c \uc808\ucc28\ub97c \uc124\uba85\ud569\ub2c8\ub2e4.</p> <p>OPERATIONS.en.md \ud30c\uc77c\uc758 \ud55c\uae00 \ubc88\uc5ed \ubc84\uc804\uc785\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc601\ubb38 \ubc84\uc804(OPERATIONS.en.md)\uc744 \ucc38\uc870\ud558\uc138\uc694.</p>"},{"location":"ko/OPERATIONS/#_1","title":"\uc8fc\uc694 \ub0b4\uc6a9","text":"<ul> <li>DLQ \ubaa8\ub2c8\ud130\ub9c1</li> <li>\uba54\ud2b8\ub9ad \ud574\uc11d</li> <li>\ud2b8\ub7ec\ube14\uc288\ud305 \ub9e4\ud2b8\ub9ad\uc2a4</li> <li>\ubcf5\uad6c \uc808\ucc28</li> <li>\uc54c\ub9bc \uc124\uc815</li> <li>Runbook \uccb4\ud06c\ub9ac\uc2a4\ud2b8</li> </ul> <p>\uc601\ubb38 \uac00\uc774\ub4dc\ub97c \ucc38\uc870\ud558\uc138\uc694: OPERATIONS.en.md</p>"}]}